<!DOCTYPE html>
<html lang="en">
<head>
  
  
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    
    
    <link rel="canonical" href="https://booiljung.github.io/hardware/gpu_design/chapter_07/0703/">
    <link rel="shortcut icon" href="../../../../img/favicon.ico">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" />
    <title>스레드 블록과 그리드 구성 - 실험 도서관</title>
    <link href="../../../../css/bootstrap-3.3.7.min.css" rel="stylesheet">
    <link href="../../../../css/font-awesome-4.7.0.css" rel="stylesheet">
    <link href="../../../../css/base.css" rel="stylesheet">
    <link rel="stylesheet" href="../../../../css/highlight.css">
    <link href="../../../../css/custom.css" rel="stylesheet">
    <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.3.0/respond.min.js"></script>
    <![endif]-->

    <script src="../../../../js/jquery-3.2.1.min.js"></script>
    <script src="../../../../js/bootstrap-3.3.7.min.js"></script>
    <script src="../../../../js/highlight.pack.js"></script>
    
    <base target="_top">
    <script>
      var base_url = '../../../..';
      var is_top_frame = false;
        
        var pageToc = [
          {title: "\uc2a4\ub808\ub4dc \ube14\ub85d", url: "#_top", children: [
          ]},
          {title: "\uadf8\ub9ac\ub4dc(Grid) \uad6c\uc131", url: "#grid", children: [
          ]},
          {title: "\uc608\uc81c: \ud589\ub82c \uacf1\uc148", url: "#_2", children: [
          ]},
          {title: "\uba54\ubaa8\ub9ac \uad00\ub9ac\uc640 \ucd5c\uc801\ud654", url: "#_3", children: [
              {title: "\uc804\uc5ed \uba54\ubaa8\ub9ac(Global Memory)", url: "#global-memory" },
              {title: "\uacf5\uc720 \uba54\ubaa8\ub9ac(Shared Memory)", url: "#shared-memory" },
              {title: "\ucf58\uc2a4\ud134\ud2b8 \uba54\ubaa8\ub9ac(Constant Memory)", url: "#constant-memory" },
              {title: "\ucd5c\uc801\ud654 \uae30\ubc95", url: "#_4" },
              {title: "\uc131\ub2a5 \ubd84\uc11d \ub3c4\uad6c", url: "#_6" },
          ]},
        ];

    </script>
    <script src="../../../../js/base.js"></script>
      <script src="../../../../js/google_analytics.js"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML"></script>
      <script src="https://www.googletagmanager.com/gtag/js?id=G-3F4LHCTF88"></script> 
</head>

<body>
<script>
if (is_top_frame) { $('body').addClass('wm-top-page'); }
</script>



<div class="container-fluid wm-page-content">
  <a name="_top"></a>
    

    
    
      
    

  <div class="row wm-article-nav-buttons" role="navigation" aria-label="navigation">
    
    <div class="wm-article-nav pull-right">
      <a href="../0704/" class="btn btn-xs btn-default pull-right">
        Next
        <i class="fa fa-chevron-right" aria-hidden="true"></i>
      </a>
      <a href="../0704/" class="btn btn-xs btn-link">
        비동기 데이터 처리
      </a>
    </div>
    
    <div class="wm-article-nav">
      <a href="../0702/" class="btn btn-xs btn-default pull-left">
        <i class="fa fa-chevron-left" aria-hidden="true"></i>
        Previous</a><a href="../0702/" class="btn btn-xs btn-link">
        SIMD와 SIMT 구조
      </a>
    </div>
    
  </div>

    

    <p>병렬 컴퓨팅의 한 중요한 개념은 작업을 효율적으로 분산 처리하기 위한 구조를 이해하는 것이다. 여기에는 NVIDIA의 CUDA(Compute Unified Device Architecture)와 같은 GPU 프로그래밍 모델이 자주 사용된다. CUDA는 작업을 병렬 방식으로 분산 처리하기 위해 스레드 블록과 그리드의 개념을 도입했다.</p>
<h4 id="_1">스레드 블록</h4>
<p>스레드 블록(Thread Block)은 CUDA 프로그래밍 모델에서 기본적인 연산 단위이다. 하나의 커널이 여러 스레드 블록으로 나뉘며, 각 블록 내에는 다수의 스레드가 존재한다. 이 스레드들은 물리적으로 같은 Streaming Multiprocessor(SM) 내에서 실행된다. </p>
<p>스레드 블록의 주요 특징은 다음과 같다:</p>
<ul>
<li><strong>자유로운 스레드 간 통신</strong>: 블록 내의 스레드들은 상호 간의 통신이 가능하다. 이를 통해 데이터 공유 및 협력 작업을 수행할 수 있다.</li>
<li><strong>동기화 가능</strong>: 블록 내의 스레드는 __syncthreads() 명령어를 통해 동기화할 수 있다.</li>
<li><strong>독립적 실행</strong>: 각 스레드 블록은 독립적으로 실행되며, 다른 스레드 블록의 상태를 알 필요가 없다.</li>
</ul>
<p>스레드 블록의 크기는 다음과 같은 형태로 지정할 수 있다:</p>
<pre><code class="language-cpp">dim3 dimBlock(16, 16);
</code></pre>
<p>여기서 \texttt{dim3}는 3차원 크기를 지정하는 CUDA 내의 자료형이다.</p>
<h4 id="grid">그리드(Grid) 구성</h4>
<p>그리드(Grid)는 다수의 스레드 블록으로 구성된 상위 구조이다. 커널 실행 시, 여러 개의 스레드 블록이 그리드 내에서 동작하며, 이는 전체 입력 데이터에 대한 병렬 처리를 가능하게 한다.</p>
<p>그리드의 주요 특징은 다음과 같다:</p>
<ul>
<li><strong>다수의 스레드 블록 포함</strong>: 그리드는 많은 스레드 블록을 포함하며, 이러한 블록들은 동일한 커널을 수행하게 된다.</li>
<li><strong>다차원 지원</strong>: 그리드는 1차원, 2차원, 3차원의 형태로 구성될 수 있다.</li>
</ul>
<p>그리드의 크기는 다음과 같은 형태로 지정할 수 있다:</p>
<pre><code class="language-cpp">dim3 dimGrid((N + dimBlock.x - 1) / dimBlock.x, (M + dimBlock.y - 1) / dimBlock.y);
</code></pre>
<p>여기서 \texttt{dimGrid}도 \texttt{dim3} 자료형으로 지정되는 3차원 벡터이다. 예를 들어, 2차원 배열을 처리하는 경우 \texttt{N}과 \texttt{M}은 해당 배열의 크기를 의미한다.</p>
<h4 id="_2">예제: 행렬 곱셈</h4>
<p>스레드 블록과 그리드 구성을 이해하기 위해 행렬 곱셈의 예제를 살펴보자. 두 개의 행렬 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{A}</span><script type="math/tex">\mathbf{A}</script></span>와 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{B}</span><script type="math/tex">\mathbf{B}</script></span>를 곱하여 행렬 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{C}</span><script type="math/tex">\mathbf{C}</script></span>를 계산하는 작업을 병렬 처리하는 방식이다.</p>
<p>행렬 곱셈은 다음과 같이 표현된다:</p>
<div class="arithmatex">
<div class="MathJax_Preview">
\mathbf{C}[i][j] = \sum_{k} \mathbf{A}[i][k] \cdot \mathbf{B}[k][j]
</div>
<script type="math/tex; mode=display">
\mathbf{C}[i][j] = \sum_{k} \mathbf{A}[i][k] \cdot \mathbf{B}[k][j]
</script>
</div>
<p>각 행렬 요소를 계산하기 위해 스레드 블록과 그리드를 어떻게 활용할 수 있는지를 여기서 기술한다. 다음은 CUDA 커널 코드의 예제이다:</p>
<pre><code class="language-cpp">__global__ void MatrixMultiplyKernel(float *A, float *B, float *C, int N) {
    int row = blockIdx.y * blockDim.y + threadIdx.y;
    int col = blockIdx.x * blockDim.x + threadIdx.x;
    float Cvalue = 0;

    if(row &lt; N &amp;&amp; col &lt; N) {
        for (int e = 0; e &lt; N; ++e)
            Cvalue += A[row * N + e] * B[e * N + col];
        C[row * N + col] = Cvalue;
    }
}
</code></pre>
<p>CUDA는 이 함수를 수천 개의 병렬 스레드에서 실행하며, 각 스레드는 자신의 인덱스를 기반으로 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{C}</span><script type="math/tex">\mathbf{C}</script></span>의 특정 요소를 계산한다.</p>
<h3 id="_3">메모리 관리와 최적화</h3>
<h4 id="global-memory">전역 메모리(Global Memory)</h4>
<p>전역 메모리는 모든 스레드에서 접근 가능하며, 대규모 데이터 집합을 저장하는 공간이다. 하지만 전역 메모리는 접근 시간이 길어, 이를 효율적으로 사용하는 것이 중요하다. 전역 메모리는 다음과 같은 방식으로 선언 및 사용된다:</p>
<pre><code class="language-cpp">__global__ void kernelFunction(float *d_array) {
    int idx = threadIdx.x + blockIdx.x * blockDim.x;
    d_array[idx] = ...;
}
</code></pre>
<p>이 코드에서 <code>d_array</code>는 전역 메모리의 배열이다.</p>
<h4 id="shared-memory">공유 메모리(Shared Memory)</h4>
<p>공유 메모리는 특정 스레드 블록 내에서만 접근 가능한 메모리 공간이다. 접근 속도가 빠르기 때문에 스레드 간 데이터 공유에 유리하다. 간단한 예제를 통해 공유 메모리를 사용하는 방법을 살펴보자:</p>
<pre><code class="language-cpp">__global__ void kernelFunction(float *d_array) {
    __shared__ float sharedArray[BLOCK_SIZE];

    int idx = threadIdx.x + blockIdx.x * blockDim.x;
    sharedArray[threadIdx.x] = d_array[idx];
    __syncthreads();

    ... // sharedArray를 이용한 연산
}
</code></pre>
<p>이 코드에서 <code>sharedArray</code>는 공유 메모리로 선언된 배열이다. 이 배열은 같은 블록 내의 모든 스레드가 공유하여 사용할 수 있다.</p>
<h4 id="constant-memory">콘스턴트 메모리(Constant Memory)</h4>
<p>콘스턴트 메모리는 읽기 전용 메모리로, 작은 크기의 데이터(최대 64KB)를 빠르게 접근할 수 있는 특징을 가진다. 주로 모든 스레드가 동일하게 접근해야 하는 상수 데이터를 저장하는 데 사용된다. 예를 들어, 다음과 같이 상수 메모리를 선언할 수 있다:</p>
<pre><code class="language-cpp">__constant__ float constArray[SIZE];
</code></pre>
<h4 id="_4">최적화 기법</h4>
<p>최적화를 통해 CUDA 프로그램의 성능을 크게 향상시킬 수 있다. 몇 가지 주요 최적화 기법은 다음과 같다:</p>
<h5 id="memory-coalescing">메모리 코어렌시(Memory Coalescing)</h5>
<p>메모리 코어렌시는 연속된 메모리 접근 패턴을 갖도록 하여 전역 메모리 접근을 최적화하는 방법이다. 예를 들어, 다음과 같은 방식으로 메모리 코어렌시를 달성할 수 있다:</p>
<pre><code class="language-cpp">int idx = threadIdx.x + blockIdx.x * blockDim.x;
int stride = blockDim.x * gridDim.x;
for (int i = idx; i &lt; N; i += stride) {
    d_array[idx] = ...;
}
</code></pre>
<h5 id="_5">은닉 및 동기화</h5>
<p>GPU는 많은 스레드를 동시에 실행하며, 이는 메모리 접근 지연을 감추는 데 유리하다. 또한, 스레드 간 동기화는 성능을 저하시키지 않도록 주의해야 한다. 예를 들어, 중요한 데이터 공유 시 필요한 동기화는 최소화해야 한다.</p>
<pre><code class="language-cpp">__syncthreads();  // 필요할 때만 사용
</code></pre>
<h4 id="_6">성능 분석 도구</h4>
<p>CUDA에는 NVidia Visual Profiler와 같은 성능 분석 도구가 있어서 병목 현상을 식별하고 최적화할 수 있다. 이러한 도구를 사용해 커널의 실행 시간을 분석하고, 메모리 접근 패턴을 확인하여 최적화를 진행할 수 있다.</p>

  <br>
    

    
    
      
    

  <div class="row wm-article-nav-buttons" role="navigation" aria-label="navigation">
    
    <div class="wm-article-nav pull-right">
      <a href="../0704/" class="btn btn-xs btn-default pull-right">
        Next
        <i class="fa fa-chevron-right" aria-hidden="true"></i>
      </a>
      <a href="../0704/" class="btn btn-xs btn-link">
        비동기 데이터 처리
      </a>
    </div>
    
    <div class="wm-article-nav">
      <a href="../0702/" class="btn btn-xs btn-default pull-left">
        <i class="fa fa-chevron-left" aria-hidden="true"></i>
        Previous</a><a href="../0702/" class="btn btn-xs btn-link">
        SIMD와 SIMT 구조
      </a>
    </div>
    
  </div>

    <br>
</div>

<footer class="container-fluid wm-page-content">
  <p>Documentation built with <a href="https://www.mkdocs.org/">MkDocs</a> using <a href="https://github.com/gristlabs/mkdocs-windmill">Windmill</a> theme by Grist Labs.</p>
</footer>

</body>
</html>