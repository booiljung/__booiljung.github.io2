<!DOCTYPE html>
<html lang="en">
<head>
  
  
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    
    
    <link rel="canonical" href="https://booiljung.github.io/hardware/gpu%20design/chapter%2012/1203/">
    <link rel="shortcut icon" href="../../../../img/favicon.ico">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" />
    <title>GPU 간 통신 기법 - 실험 도서관</title>
    <link href="../../../../css/bootstrap-3.3.7.min.css" rel="stylesheet">
    <link href="../../../../css/font-awesome-4.7.0.css" rel="stylesheet">
    <link href="../../../../css/base.css" rel="stylesheet">
    <link rel="stylesheet" href="../../../../css/highlight.css">
    <link href="../../../../css/custom.css" rel="stylesheet">
    <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.3.0/respond.min.js"></script>
    <![endif]-->

    <script src="../../../../js/jquery-3.2.1.min.js"></script>
    <script src="../../../../js/bootstrap-3.3.7.min.js"></script>
    <script src="../../../../js/highlight.pack.js"></script>
    
    <base target="_top">
    <script>
      var base_url = '../../../..';
      var is_top_frame = false;
        
        var pageToc = [
          {title: "1. GPU \uac04 \uc9c1\uc811 \uba54\ubaa8\ub9ac \uc811\uadfc (GPUDirect)", url: "#_top", children: [
              {title: "GPUDirect Memory Access (GPUDirect RDMA)", url: "#gpudirect-memory-access-gpudirect-rdma" },
              {title: "GPUDirect Peer-to-Peer", url: "#gpudirect-peer-to-peer" },
          ]},
          {title: "2. NVIDIA NVLink", url: "#2-nvidia-nvlink", children: [
          ]},
          {title: "3. Unified Memory and Managed Memory", url: "#3-unified-memory-and-managed-memory", children: [
          ]},
          {title: "4. MPI (Message Passing Interface)", url: "#4-mpi-message-passing-interface", children: [
          ]},
          {title: "5. NCCL (NVIDIA Collective Communications Library)", url: "#5-nccl-nvidia-collective-communications-library", children: [
          ]},
          {title: "6. CUDA Streams and Async Operations", url: "#6-cuda-streams-and-async-operations", children: [
          ]},
          {title: "7. Multi-GPU Programming Models", url: "#7-multi-gpu-programming-models", children: [
          ]},
        ];

    </script>
    <script src="../../../../js/base.js"></script>
      <script src="../../../../js/google_analytics.js"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML"></script>
      <script src="https://www.googletagmanager.com/gtag/js?id=G-3F4LHCTF88"></script> 
</head>

<body>
<script>
if (is_top_frame) { $('body').addClass('wm-top-page'); }
</script>



<div class="container-fluid wm-page-content">
  <a name="_top"></a>
    

    
    
      
    

  <div class="row wm-article-nav-buttons" role="navigation" aria-label="navigation">
    
    <div class="wm-article-nav pull-right">
      <a href="../1204/" class="btn btn-xs btn-default pull-right">
        Next
        <i class="fa fa-chevron-right" aria-hidden="true"></i>
      </a>
      <a href="../1204/" class="btn btn-xs btn-link">
        데이터 종속성과 해결 방법
      </a>
    </div>
    
    <div class="wm-article-nav">
      <a href="../1202/" class="btn btn-xs btn-default pull-left">
        <i class="fa fa-chevron-left" aria-hidden="true"></i>
        Previous</a><a href="../1202/" class="btn btn-xs btn-link">
        원자 연산
      </a>
    </div>
    
  </div>

    

    <p>GPU 간의 효율적인 통신은 병렬 컴퓨팅 성능을 최대한 활용하기 위한 중요한 요소이다. 이를 위해 다양한 통신 기법이 사용되며, 이러한 기법들은 여러 GPU를 사용하는 복잡한 애플리케이션에서 매우 중요하다. 여기서는 GPU 간 통신 기법에 대해 상세히 설명한다.</p>
<h3 id="1-gpu-gpudirect">1. GPU 간 직접 메모리 접근 (GPUDirect)</h3>
<h4 id="gpudirect-memory-access-gpudirect-rdma">GPUDirect Memory Access (GPUDirect RDMA)</h4>
<p>GPUDirect RDMA(Remote Direct Memory Access)는 CPU의 관여 없이 GPU와 다른 디바이스(다른 GPU 포함) 간에 직접 대용량 데이터를 전송할 수 있는 기술이다. 이 방식은 CPU의 개입을 최소화하여 지연 시간을 줄이고, 데이터 전송 속도를 증가시킨다.</p>
<pre><code class="language-cpp">// Pseudocode for GPUDirect RDMA
cudaMemcpy(DstPointer, SrcPointer, Size, cudaMemcpyDeviceToDevice);
</code></pre>
<h4 id="gpudirect-peer-to-peer">GPUDirect Peer-to-Peer</h4>
<p>같은 시스템 내에 있는 두 개 이상의 GPU 간에 직접 통신 하는 방식이다. 한 GPU의 메모리를 다른 GPU가 직접 접근할 수 있게 하여 효율적인 데이터 전송을 가능하게 한다.</p>
<pre><code class="language-cpp">// Enabling Peer-to-Peer access
cudaSetDevice(GPU0);
cudaDeviceEnablePeerAccess(GPU1, 0);

cudaSetDevice(GPU1);
cudaDeviceEnablePeerAccess(GPU0, 0);
</code></pre>
<h3 id="2-nvidia-nvlink">2. NVIDIA NVLink</h3>
<p>NVLink는 NVIDIA에서 개발한 고속 인터커넥트로, 여러 GPU 간의 대역폭 높은 통신을 지원한다. NVLink를 사용하면 PCIe보다 훨씬 빠른 속도로 데이터를 전송할 수 있다. NVLink는 CUDA 프레임워크 내에서 자동으로 관리되며, 개발자가 직접 개입할 필요가 거의 없다.</p>
<pre><code class="language-cpp">// No explicit code needed typically as NVLink is managed by CUDA framework
</code></pre>
<h3 id="3-unified-memory-and-managed-memory">3. Unified Memory and Managed Memory</h3>
<p>통합 메모리(Unified Memory) 및 관리형 메모리(Managed Memory)는 CPU와 여러 GPU 간의 메모리를 통합하여 쉽게 관리할 수 있도록 하는 기술이다. 이를 통해 메모리 복잡성을 줄이고, 성능 향상을 도모할 수 있다.</p>
<pre><code class="language-cpp">// Example code for Unified Memory
float *d_data;
cudaMallocManaged(&amp;d_data, N * sizeof(float));

// Code to utilize d_data
</code></pre>
<h3 id="4-mpi-message-passing-interface">4. MPI (Message Passing Interface)</h3>
<p>다중 GPU 클러스터 환경에서는 Message Passing Interface (MPI)를 사용하여 GPU 간 데이터를 교환하는 것이 일반적이다. 이는 특히 분산 클러스터에서 많이 사용된다.</p>
<pre><code class="language-cpp">// Pseudocode for MPI communication
MPI_Send(buffer, count, MPI_FLOAT, dest, tag, MPI_COMM_WORLD);
MPI_Recv(buffer, count, MPI_FLOAT, source, tag, MPI_COMM_WORLD, &amp;status);
</code></pre>
<h3 id="5-nccl-nvidia-collective-communications-library">5. NCCL (NVIDIA Collective Communications Library)</h3>
<p>NCCL은 NVIDIA에서 제공하는 라이브러리로, 여러 GPU 간 효율적인 데이터 공유를 위한 통신 패턴을 제공한다. 이 라이브러리는 싱글 머신에서 여러 개의 GPU가 협력하여 작업을 수행하는 경우에 특히 유용하다.</p>
<pre><code class="language-cpp">#include &lt;nccl.h&gt;

// Initialization
ncclComm_t comm;
ncclCommInitRank(&amp;comm, nRanks, ncclId, rank);

// Scatter/Gather Example
ncclGroupStart();
ncclBcast(data, count, ncclFloat, root, comm, stream);
ncclGroupEnd();
</code></pre>
<h3 id="6-cuda-streams-and-async-operations">6. CUDA Streams and Async Operations</h3>
<p>CUDA Stream과 비동기 연산을 사용하면 데이터 전송과 커널 실행을 겹쳐서 성능을 극대화할 수 있다. GPU 간 통신을 최적화하는 방법 중 하나는 이 비동기 방식의 원리를 잘 이해하고 활용하는 것이다.</p>
<pre><code class="language-cpp">cudaMemcpyAsync(dst, src, size, cudaMemcpyDeviceToDevice, stream);
kernel&lt;&lt;&lt;blocks, threads, 0, stream&gt;&gt;&gt;(parameters);
</code></pre>
<h3 id="7-multi-gpu-programming-models">7. Multi-GPU Programming Models</h3>
<p>Multi-GPU 프로그래밍 모델은 GPU 간의 통신을 효율적으로 진행하기 위해 다양한 추상화를 제공한다. 아래는 대표적인 프로그래밍 모델들이다:</p>
<ul>
<li><strong>CUDA Multi-GPU</strong>: CUDA는 다중 GPU 프로그래밍을 위해 여러 개의 GPU 메모리를 직접 관리하는 방식과 동일한 프로그래밍 모델을 제공한다.</li>
<li><strong>OpenCL</strong>: OpenCL은 병렬 프로그래밍을 위한 크로스-플랫폼 API로, 여러 GPU 간 통신을 지원한다.</li>
<li><strong>SYCL</strong>: SYCL은 C++ 기반의 병렬 프로그래밍 모델로, 여러 벤더의 디바이스 간의 통신을 지원한다.</li>
</ul>
<hr />
<p>위에서 설명한 여러 기술과 프로그래밍 모델을 결합하면 다양한 GPU와 시스템 간의 통신을 최적화할 수 있다. 결론적으로, GPU 간 통신을 효율적으로 구현하기 위해서는 각각의 기법과 기술을 적절히 이해하고, 상황에 맞는 최적의 방법을 선택하는 것이 중요하다.</p>

  <br>
    

    
    
      
    

  <div class="row wm-article-nav-buttons" role="navigation" aria-label="navigation">
    
    <div class="wm-article-nav pull-right">
      <a href="../1204/" class="btn btn-xs btn-default pull-right">
        Next
        <i class="fa fa-chevron-right" aria-hidden="true"></i>
      </a>
      <a href="../1204/" class="btn btn-xs btn-link">
        데이터 종속성과 해결 방법
      </a>
    </div>
    
    <div class="wm-article-nav">
      <a href="../1202/" class="btn btn-xs btn-default pull-left">
        <i class="fa fa-chevron-left" aria-hidden="true"></i>
        Previous</a><a href="../1202/" class="btn btn-xs btn-link">
        원자 연산
      </a>
    </div>
    
  </div>

    <br>
</div>

<footer class="container-fluid wm-page-content">
  <p>Documentation built with <a href="https://www.mkdocs.org/">MkDocs</a> using <a href="https://github.com/gristlabs/mkdocs-windmill">Windmill</a> theme by Grist Labs.</p>
</footer>

</body>
</html>