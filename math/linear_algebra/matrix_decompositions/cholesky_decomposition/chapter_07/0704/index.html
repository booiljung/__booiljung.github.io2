<!DOCTYPE html>
<html lang="en">
<head>
  
  
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    
    
    <link rel="canonical" href="https://booiljung.github.io/math/linear_algebra/matrix_decompositions/cholesky_decomposition/chapter_07/0704/">
    <link rel="shortcut icon" href="../../../../../../img/favicon.ico">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" />
    <title>Gaussian 프로세스 회귀 - 실험 도서관</title>
    <link href="../../../../../../css/bootstrap-3.3.7.min.css" rel="stylesheet">
    <link href="../../../../../../css/font-awesome-4.7.0.css" rel="stylesheet">
    <link href="../../../../../../css/base.css" rel="stylesheet">
    <link rel="stylesheet" href="../../../../../../css/highlight.css">
    <link href="../../../../../../css/custom.css" rel="stylesheet">
    <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.3.0/respond.min.js"></script>
    <![endif]-->

    <script src="../../../../../../js/jquery-3.2.1.min.js"></script>
    <script src="../../../../../../js/bootstrap-3.3.7.min.js"></script>
    <script src="../../../../../../js/highlight.pack.js"></script>
    
    <base target="_top">
    <script>
      var base_url = '../../../../../..';
      var is_top_frame = false;
        
        var pageToc = [
          {title: "\uac1c\uc694", url: "#_top", children: [
          ]},
          {title: "Gaussian \ud504\ub85c\uc138\uc2a4 \ud68c\uadc0\uc758 \uae30\ubcf8 \uac1c\ub150", url: "#gaussian", children: [
              {title: "\uae30\ubcf8 \ubaa8\ub378", url: "#_2" },
              {title: "\ucee4\ub110 \ud568\uc218", url: "#_3" },
              {title: "\ud655\ub960 \ubaa8\ub378", url: "#_4" },
          ]},
          {title: "\uc608\uce21 (Prediction)", url: "#prediction", children: [
          ]},
          {title: "Cholesky \ubd84\ud574\ub97c \uc774\uc6a9\ud55c \ud6a8\uc728\uc801\uc778 \uacc4\uc0b0", url: "#cholesky", children: [
              {title: "\uc608\uce21\uc744 \uc704\ud55c Cholesky \ubd84\ud574 \ud65c\uc6a9", url: "#cholesky_1" },
          ]},
          {title: "\uc608\uc81c \ucf54\ub4dc", url: "#_5", children: [
          ]},
          {title: "Cholesky \ubd84\ud574\uc758 \uc7a5\uc810", url: "#cholesky_2", children: [
          ]},
        ];

    </script>
    <script src="../../../../../../js/base.js"></script>
      <script src="../../../../../../js/google_analytics.js"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML"></script>
      <script src="https://www.googletagmanager.com/gtag/js?id=G-3F4LHCTF88"></script> 
</head>

<body>
<script>
if (is_top_frame) { $('body').addClass('wm-top-page'); }
</script>



<div class="container-fluid wm-page-content">
  <a name="_top"></a>
    

    
    
      
    

  <div class="row wm-article-nav-buttons" role="navigation" aria-label="navigation">
    
    <div class="wm-article-nav pull-right">
      <a href="../../chapter_08/0801/" class="btn btn-xs btn-default pull-right">
        Next
        <i class="fa fa-chevron-right" aria-hidden="true"></i>
      </a>
      <a href="../../chapter_08/0801/" class="btn btn-xs btn-link">
        Sholesky 분해의 성능 최적화
      </a>
    </div>
    
    <div class="wm-article-nav">
      <a href="../0703/" class="btn btn-xs btn-default pull-left">
        <i class="fa fa-chevron-left" aria-hidden="true"></i>
        Previous</a><a href="../0703/" class="btn btn-xs btn-link">
        Sholesky 분해의 응용
      </a>
    </div>
    
  </div>

    

    <h2 id="_1">개요</h2>
<p>Gaussian 프로세스 회귀(Gaussian Process Regression, GPR)는 비선형 회귀 문제를 푸는 데 사용되는 강력한 비모수적 방법이다. Gaussian 프로세스는 기계 학습에서 함수로부터의 랜덤 변수를 모델링하며, 학습 데이터를 통해 새로운 입력 점에 대한 예측 분포를 제공한다. 이 장에서는 Cholesky 분해를 사용하여 Gaussian 프로세스 회귀 모델의 예측을 효율적으로 수행하는 방법을 설명한다.</p>
<h2 id="gaussian">Gaussian 프로세스 회귀의 기본 개념</h2>
<p>Gaussian 프로세스는 모든 유한 집합의 점들이 다변량 정규 분포를 따른다고 가정한다. GPR 모델은 주어진 입력 데이터 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{X} = \{ \mathbf{x}_1, \mathbf{x}_2, \ldots, \mathbf{x}_n \}</span><script type="math/tex">\mathbf{X} = \{ \mathbf{x}_1, \mathbf{x}_2, \ldots, \mathbf{x}_n \}</script></span>와 출력 데이터 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{y} = \{ y_1, y_2, \ldots, y_n \}</span><script type="math/tex">\mathbf{y} = \{ y_1, y_2, \ldots, y_n \}</script></span>를 사용하여 새로운 입력점 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{x}_*</span><script type="math/tex">\mathbf{x}_*</script></span>의 출력 <span class="arithmatex"><span class="MathJax_Preview">y_*</span><script type="math/tex">y_*</script></span>를 예측한다.</p>
<h3 id="_2">기본 모델</h3>
<p>입력 데이터 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{X}</span><script type="math/tex">\mathbf{X}</script></span>에 대한 출력 데이터 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{y}</span><script type="math/tex">\mathbf{y}</script></span>는 다음과 같이 모델링된다:</p>
<div class="arithmatex">
<div class="MathJax_Preview">
\mathbf{y} = f(\mathbf{X}) + \mathbf{\epsilon}
</div>
<script type="math/tex; mode=display">
\mathbf{y} = f(\mathbf{X}) + \mathbf{\epsilon}
</script>
</div>
<p>여기서 <span class="arithmatex"><span class="MathJax_Preview">f(\mathbf{X})</span><script type="math/tex">f(\mathbf{X})</script></span>는 Gaussian 프로세스로 모델링된 실제 함수이며, <span class="arithmatex"><span class="MathJax_Preview">\mathbf{\epsilon} \sim \mathcal{N}(\mathbf{0}, \sigma_n^2 \mathbf{I})</span><script type="math/tex">\mathbf{\epsilon} \sim \mathcal{N}(\mathbf{0}, \sigma_n^2 \mathbf{I})</script></span>는 노이즈이다.</p>
<h3 id="_3">커널 함수</h3>
<p>Gaussian 프로세스는 커널 함수 <span class="arithmatex"><span class="MathJax_Preview">k(\mathbf{x}, \mathbf{x}')</span><script type="math/tex">k(\mathbf{x}, \mathbf{x}')</script></span>를 통해 입력 데이터 간의 상관성을 나타낸다. 커널 행렬 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{K}</span><script type="math/tex">\mathbf{K}</script></span>는 <span class="arithmatex"><span class="MathJax_Preview">(k(\mathbf{x}_i, \mathbf{x}_j))</span><script type="math/tex">(k(\mathbf{x}_i, \mathbf{x}_j))</script></span>로 구성되며, 여기서 각 <span class="arithmatex"><span class="MathJax_Preview">k(\mathbf{x}_i, \mathbf{x}_j)</span><script type="math/tex">k(\mathbf{x}_i, \mathbf{x}_j)</script></span>는 두 입력점 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{x}_i</span><script type="math/tex">\mathbf{x}_i</script></span>와 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{x}_j</span><script type="math/tex">\mathbf{x}_j</script></span> 간의 커널 값이다.</p>
<h3 id="_4">확률 모델</h3>
<p>Gaussian 프로세스 회귀 모델의 핵심은 주어진 데이터에 대해 새로운 입력점의 출력을 구하기 위해 다변량 정규 분포의 성질을 활용하는 것이다. 예측하려는 새로운 입력점 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{x}_*</span><script type="math/tex">\mathbf{x}_*</script></span>에 대해 다음의 결합 확률 분포를 고려한다:</p>
<div class="arithmatex">
<div class="MathJax_Preview">
\begin{bmatrix}
\mathbf{y} \\
y_*
\end{bmatrix} \sim \mathcal{N} \left( \mathbf{0}, \begin{bmatrix}
\mathbf{K} + \sigma_n^2 \mathbf{I} &amp; \mathbf{k}_* \\
\mathbf{k}_*^\top &amp; k(\mathbf{x}_*, \mathbf{x}_*)
\end{bmatrix} \right)
</div>
<script type="math/tex; mode=display">
\begin{bmatrix}
\mathbf{y} \\
y_*
\end{bmatrix} \sim \mathcal{N} \left( \mathbf{0}, \begin{bmatrix}
\mathbf{K} + \sigma_n^2 \mathbf{I} & \mathbf{k}_* \\
\mathbf{k}_*^\top & k(\mathbf{x}_*, \mathbf{x}_*)
\end{bmatrix} \right)
</script>
</div>
<p>여기서 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{k}_*</span><script type="math/tex">\mathbf{k}_*</script></span>는 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{k}_* = [k(\mathbf{x}_1, \mathbf{x}_*), \ldots, k(\mathbf{x}_n, \mathbf{x}_*)]^\top</span><script type="math/tex">\mathbf{k}_* = [k(\mathbf{x}_1, \mathbf{x}_*), \ldots, k(\mathbf{x}_n, \mathbf{x}_*)]^\top</script></span>이다.</p>
<h2 id="prediction">예측 (Prediction)</h2>
<p>주어진 새로운 입력점 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{x}_*</span><script type="math/tex">\mathbf{x}_*</script></span>에 대한 출력 <span class="arithmatex"><span class="MathJax_Preview">y_*</span><script type="math/tex">y_*</script></span>의 예측 분포는 다음과 같이 구해진다:</p>
<div class="arithmatex">
<div class="MathJax_Preview">
\mathbb{E}[y_* | \mathbf{X}, \mathbf{y}, \mathbf{x}_*] = \mathbf{k}_*^\top (\mathbf{K} + \sigma_n^2 \mathbf{I})^{-1} \mathbf{y}
</div>
<script type="math/tex; mode=display">
\mathbb{E}[y_* | \mathbf{X}, \mathbf{y}, \mathbf{x}_*] = \mathbf{k}_*^\top (\mathbf{K} + \sigma_n^2 \mathbf{I})^{-1} \mathbf{y}
</script>
</div>
<div class="arithmatex">
<div class="MathJax_Preview">
\text{Var}[y_* | \mathbf{X}, \mathbf{y}, \mathbf{x}_*] = k(\mathbf{x}_*, \mathbf{x}_*) - \mathbf{k}_*^\top (\mathbf{K} + \sigma_n^2 \mathbf{I})^{-1} \mathbf{k}_*
</div>
<script type="math/tex; mode=display">
\text{Var}[y_* | \mathbf{X}, \mathbf{y}, \mathbf{x}_*] = k(\mathbf{x}_*, \mathbf{x}_*) - \mathbf{k}_*^\top (\mathbf{K} + \sigma_n^2 \mathbf{I})^{-1} \mathbf{k}_*
</script>
</div>
<p>Cholesky 분해를 사용하여 <span class="arithmatex"><span class="MathJax_Preview">(\mathbf{K} + \sigma_n^2 \mathbf{I})</span><script type="math/tex">(\mathbf{K} + \sigma_n^2 \mathbf{I})</script></span>의 역행렬을 계산하면 계산 효율성을 높일 수 있다.</p>
<h2 id="cholesky">Cholesky 분해를 이용한 효율적인 계산</h2>
<p>Cholesky 분해는 대칭 양의 정부호 행렬 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{A}</span><script type="math/tex">\mathbf{A}</script></span>를 하삼각 행렬 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{L}</span><script type="math/tex">\mathbf{L}</script></span>과 그 전치 행렬 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{L}^\top</span><script type="math/tex">\mathbf{L}^\top</script></span>로 분해하는 방법이다:</p>
<div class="arithmatex">
<div class="MathJax_Preview">
\mathbf{A} = \mathbf{L} \mathbf{L}^\top
</div>
<script type="math/tex; mode=display">
\mathbf{A} = \mathbf{L} \mathbf{L}^\top
</script>
</div>
<p>Gaussian 프로세스 회귀에서는 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{K} + \sigma_n^2 \mathbf{I}</span><script type="math/tex">\mathbf{K} + \sigma_n^2 \mathbf{I}</script></span>의 Cholesky 분해를 수행한다:</p>
<div class="arithmatex">
<div class="MathJax_Preview">
\mathbf{K} + \sigma_n^2 \mathbf{I} = \mathbf{L} \mathbf{L}^\top
</div>
<script type="math/tex; mode=display">
\mathbf{K} + \sigma_n^2 \mathbf{I} = \mathbf{L} \mathbf{L}^\top
</script>
</div>
<p>여기서 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{L}</span><script type="math/tex">\mathbf{L}</script></span>은 하삼각 행렬이다.</p>
<h3 id="cholesky_1">예측을 위한 Cholesky 분해 활용</h3>
<p>Cholesky 분해를 사용하면 예측을 위한 계산을 효율적으로 수행할 수 있다. 다음의 단계를 따른다:</p>
<ol>
<li>
<p><span class="arithmatex"><span class="MathJax_Preview">\mathbf{L}</span><script type="math/tex">\mathbf{L}</script></span>을 구한다: <span class="arithmatex"><span class="MathJax_Preview">\mathbf{L} = \text{Cholesky}(\mathbf{K} + \sigma_n^2 \mathbf{I})</span><script type="math/tex">\mathbf{L} = \text{Cholesky}(\mathbf{K} + \sigma_n^2 \mathbf{I})</script></span>.</p>
</li>
<li>
<p>하삼각 행렬 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{L}</span><script type="math/tex">\mathbf{L}</script></span>을 이용하여 <span class="arithmatex"><span class="MathJax_Preview">(\mathbf{K} + \sigma_n^2 \mathbf{I})^{-1} \mathbf{y}</span><script type="math/tex">(\mathbf{K} + \sigma_n^2 \mathbf{I})^{-1} \mathbf{y}</script></span>를 다음과 같이 계산한다:</p>
</li>
</ol>
<p>$$
   \mathbf{L} \mathbf{b} = \mathbf{y} \quad \text{(앞 방향 대입)}</p>
<p>$$</p>
<p>$$
   \mathbf{L}^\top \mathbf{c} = \mathbf{b} \quad \text{(뒤 방향 대입)}</p>
<p>$$</p>
<p>그렇게 해서 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{c} = (\mathbf{K} + \sigma_n^2 \mathbf{I})^{-1} \mathbf{y}</span><script type="math/tex">\mathbf{c} = (\mathbf{K} + \sigma_n^2 \mathbf{I})^{-1} \mathbf{y}</script></span>를 얻는다.</p>
<ol>
<li>예측 값을 계산한다:</li>
</ol>
<p>$$
   \mathbb{E}[y_<em> | \mathbf{X}, \mathbf{y}, \mathbf{x}_</em>] = \mathbf{k}_*^\top \mathbf{c}</p>
<p>$$</p>
<ol>
<li>예측 분산을 계산한다:</li>
</ol>
<p>$$
   \text{Var}[y_<em> | \mathbf{X}, \mathbf{y}, \mathbf{x}_</em>] = k(\mathbf{x}_<em>, \mathbf{x}_</em>) - \mathbf{v}^\top \mathbf{v}</p>
<p>$$</p>
<p>여기서 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{v}</span><script type="math/tex">\mathbf{v}</script></span>는 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{L} \mathbf{v} = \mathbf{k}_*</span><script type="math/tex">\mathbf{L} \mathbf{v} = \mathbf{k}_*</script></span>를 통해 구한다.</p>
<p>이렇게 함으로써 예측 계산이 효율적으로 수행되며, 수치적으로도 안정적이다.</p>
<h2 id="_5">예제 코드</h2>
<p>이제 Python을 사용하여 Gaussian 프로세스 회귀를 구현하는 예제를 소개하겠다. numpy 및 scipy 패키지를 사용하여 Cholesky 분해를 통합하는 방법을 설명한다.</p>
<pre><code class="language-python">import numpy as np
from scipy.linalg import cholesky, cho_solve

def kernel(X1, X2, length_scale=1.0, variance=1.0):
    sqdist = np.sum(X1**2, 1).reshape(-1, 1) + np.sum(X2**2, 1) - 2 * np.dot(X1, X2.T)
    return variance * np.exp(-0.5 / length_scale**2 * sqdist)

X_train = np.array([[-4], [-3], [-1], [0], [2], [3]])
y_train = np.sin(X_train).ravel()

length_scale = 1.0
variance = 1.0
noise = 1e-2

K = kernel(X_train, X_train, length_scale, variance) + noise**2 * np.eye(len(X_train))

L = cholesky(K, lower=True)

X_test = np.array([[-5], [-2], [1], [4]])

K_s = kernel(X_train, X_test, length_scale, variance)

alpha = cho_solve((L, True), y_train)

mean = np.dot(K_s.T, alpha)

v = cho_solve((L, True), K_s)
var = kernel(X_test, X_test, length_scale, variance) - np.dot(K_s.T, v)

print(&quot;예측 평균:&quot;, mean)
print(&quot;예측 분산:&quot;, var)
</code></pre>
<p>이 예제는 다음의 단계로 구성된다:</p>
<ol>
<li><strong>데이터 생성</strong>: <code>X_train</code>과 <code>y_train</code>에 데이터 점들을 생성한다. 이 예제에서는 <span class="arithmatex"><span class="MathJax_Preview">\sin(x)</span><script type="math/tex">\sin(x)</script></span> 함수를 따르는 값들을 사용한다.</li>
<li><strong>커널 함수 정의</strong>: RBF 커널 함수는 두 입력 행렬 간의 커널 값을 계산한다.</li>
<li><strong>커널 행렬 계산</strong>: 훈련 데이터의 커널 행렬을 계산하고, 거기에 노이즈를 추가한다.</li>
<li><strong>Cholesky 분해</strong>: 커널 행렬에 Cholesky 분해를 적용하여 하삼각 행렬 <span class="arithmatex"><span class="MathJax_Preview">L</span><script type="math/tex">L</script></span>을 얻는다.</li>
<li><strong>새로운 입력점 생성</strong>: <code>X_test</code> 변수에 새로운 입력점들을 추가한다.</li>
<li><strong>커널 벡터 계산</strong>: 새로운 입력점과 훈련 데이터 사이의 커널 벡터를 계산한다.</li>
<li><strong><span class="arithmatex"><span class="MathJax_Preview">\alpha</span><script type="math/tex">\alpha</script></span> 계산</strong>: 훈련 데이터의 출력값을 Cholesky 분해를 통해 변환하여 <span class="arithmatex"><span class="MathJax_Preview">\alpha</span><script type="math/tex">\alpha</script></span> 값을 얻는다.</li>
<li><strong>예측 계산</strong>: 예측의 평균과 분산을 계산한다.</li>
</ol>
<h2 id="cholesky_2">Cholesky 분해의 장점</h2>
<ul>
<li><strong>수치적 안정성</strong>: Cholesky 분해는 대칭 행렬의 양의 정부호를 보장하며, 수치적으로 더욱 안정적이다.</li>
<li><strong>계산 효율성</strong>: 다른 <span class="arithmatex"><span class="MathJax_Preview">O(n^3)</span><script type="math/tex">O(n^3)</script></span> 알고리즘에 비해 계산 시간이 절약된다.</li>
<li><strong>메모리 절약</strong>: 행렬의 역을 직접 계산하지 않고 분해와 대입을 통해 결과를 얻을 수 있다.</li>
</ul>
<hr />
<p>이 장에서는 Gaussian 프로세스 회귀의 기본 원리와 Cholesky 분해를 통한 효율적인 예측 방법을 설명하였다. Gaussian 프로세스 회귀는 비선형 회귀 문제를 다루는 데 매우 강력한 도구이며, Cholesky 분해를 활용하면 계산 효율성과 수치적 안정성을 동시에 확보할 수 있다. </p>
<p>추가적인 주제로는 다양한 커널 함수, 하이퍼파라미터 최적화, 다변량 Gaussian 프로세스 회귀 등이 있을 수 있다. 이들의 심화된 이해는 학습 및 예측의 정밀도를 극대화하는 데 도움이 된다.</p>

  <br>
    

    
    
      
    

  <div class="row wm-article-nav-buttons" role="navigation" aria-label="navigation">
    
    <div class="wm-article-nav pull-right">
      <a href="../../chapter_08/0801/" class="btn btn-xs btn-default pull-right">
        Next
        <i class="fa fa-chevron-right" aria-hidden="true"></i>
      </a>
      <a href="../../chapter_08/0801/" class="btn btn-xs btn-link">
        Sholesky 분해의 성능 최적화
      </a>
    </div>
    
    <div class="wm-article-nav">
      <a href="../0703/" class="btn btn-xs btn-default pull-left">
        <i class="fa fa-chevron-left" aria-hidden="true"></i>
        Previous</a><a href="../0703/" class="btn btn-xs btn-link">
        Sholesky 분해의 응용
      </a>
    </div>
    
  </div>

    <br>
</div>

<footer class="container-fluid wm-page-content">
  <p>Documentation built with <a href="https://www.mkdocs.org/">MkDocs</a> using <a href="https://github.com/gristlabs/mkdocs-windmill">Windmill</a> theme by Grist Labs.</p>
</footer>

</body>
</html>