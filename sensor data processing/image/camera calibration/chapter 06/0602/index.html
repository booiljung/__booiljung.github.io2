<!DOCTYPE html>
<html lang="en">
<head>
  
  
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    
    
    <link rel="canonical" href="https://booiljung.github.io/sensor%20data%20processing/image/camera%20calibration/chapter%2006/0602/">
    <link rel="shortcut icon" href="../../../../../img/favicon.ico">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" />
    <title>Gauss-Newton 방법 - 실험 도서관</title>
    <link href="../../../../../css/bootstrap-3.3.7.min.css" rel="stylesheet">
    <link href="../../../../../css/font-awesome-4.7.0.css" rel="stylesheet">
    <link href="../../../../../css/base.css" rel="stylesheet">
    <link rel="stylesheet" href="../../../../../css/highlight.css">
    <link href="../../../../../css/custom.css" rel="stylesheet">
    <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.3.0/respond.min.js"></script>
    <![endif]-->

    <script src="../../../../../js/jquery-3.2.1.min.js"></script>
    <script src="../../../../../js/bootstrap-3.3.7.min.js"></script>
    <script src="../../../../../js/highlight.pack.js"></script>
    
    <base target="_top">
    <script>
      var base_url = '../../../../..';
      var is_top_frame = false;
        
        var pageToc = [
          {title: "Gauss-Newton \uc54c\uace0\ub9ac\uc998\uc758 \uac1c\uc694", url: "#_top", children: [
          ]},
          {title: "\ucd5c\uc18c\uc81c\uacf1 \ubb38\uc81c\uc758 \uc218\ud559\uc801 \uc815\uc758", url: "#_1", children: [
          ]},
          {title: "\uc120\ud615\ud654\uc640 Jacobian \ud589\ub82c", url: "#jacobian", children: [
          ]},
          {title: "Gauss-Newton \uc5c5\ub370\uc774\ud2b8 \uaddc\uce59", url: "#gauss-newton_1", children: [
          ]},
          {title: "Gauss-Newton \uc54c\uace0\ub9ac\uc998\uc758 \uc218\ub834 \uc870\uac74", url: "#gauss-newton_2", children: [
          ]},
          {title: "Gauss-Newton \uc54c\uace0\ub9ac\uc998\uc758 \ub2e8\uacc4", url: "#gauss-newton_3", children: [
          ]},
          {title: "\uc7a5\ub2e8\uc810", url: "#_2", children: [
              {title: "\uc7a5\uc810", url: "#_3" },
              {title: "\ub2e8\uc810", url: "#_4" },
          ]},
        ];

    </script>
    <script src="../../../../../js/base.js"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML"></script> 
</head>

<body>
<script>
if (is_top_frame) { $('body').addClass('wm-top-page'); }
</script>



<div class="container-fluid wm-page-content">
  <a name="_top"></a>
    

    
    
      
    

  <div class="row wm-article-nav-buttons" role="navigation" aria-label="navigation">
    
    <div class="wm-article-nav pull-right">
      <a href="../0603/" class="btn btn-xs btn-default pull-right">
        Next
        <i class="fa fa-chevron-right" aria-hidden="true"></i>
      </a>
      <a href="../0603/" class="btn btn-xs btn-link">
        Levenberg-Marquardt 최적화
      </a>
    </div>
    
    <div class="wm-article-nav">
      <a href="../0601/" class="btn btn-xs btn-default pull-left">
        <i class="fa fa-chevron-left" aria-hidden="true"></i>
        Previous</a><a href="../0601/" class="btn btn-xs btn-link">
        Non-linear 최적화 기법
      </a>
    </div>
    
  </div>

    

    <h3 id="gauss-newton">Gauss-Newton 알고리즘의 개요</h3>
<p>Gauss-Newton 방법은 비선형 최소제곱 문제를 해결하기 위한 반복적인 최적화 알고리즘이다. 카메라 캘리브레이션 과정에서 주로 사용되는 최적화 기법 중 하나로, 비선형 함수의 최소 제곱 오차를 최소화하는 데 목적이 있다. 이 방법은 Levenberg-Marquardt와 같은 다른 최적화 알고리즘에 비해 간단한 구조를 가지지만, 매우 효과적인 결과를 제공한다.</p>
<p>Gauss-Newton 방법은 기본적으로 Taylor 급수를 이용하여 비선형 함수를 선형 근사한 후, 그 선형화된 문제를 반복적으로 풀어나가는 방식이다. 수학적으로는 비선형 함수 <span class="arithmatex"><span class="MathJax_Preview">f(\mathbf{x})</span><script type="math/tex">f(\mathbf{x})</script></span>가 주어졌을 때, 이 함수에 대해 잔차(residual) <span class="arithmatex"><span class="MathJax_Preview">r(\mathbf{x})</span><script type="math/tex">r(\mathbf{x})</script></span>를 최소화하는 해 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{x}</span><script type="math/tex">\mathbf{x}</script></span>를 찾는 문제로 볼 수 있다.</p>
<p>잔차 함수 <span class="arithmatex"><span class="MathJax_Preview">r(\mathbf{x})</span><script type="math/tex">r(\mathbf{x})</script></span>는 다음과 같이 정의된다:</p>
<div class="arithmatex">
<div class="MathJax_Preview">
r(\mathbf{x}) = \mathbf{y} - f(\mathbf{x})
</div>
<script type="math/tex; mode=display">
r(\mathbf{x}) = \mathbf{y} - f(\mathbf{x})
</script>
</div>
<p>여기서, <span class="arithmatex"><span class="MathJax_Preview">\mathbf{y}</span><script type="math/tex">\mathbf{y}</script></span>는 관측된 값이고 <span class="arithmatex"><span class="MathJax_Preview">f(\mathbf{x})</span><script type="math/tex">f(\mathbf{x})</script></span>는 모델에 의해 예측된 값이다. Gauss-Newton 방법은 잔차 <span class="arithmatex"><span class="MathJax_Preview">r(\mathbf{x})</span><script type="math/tex">r(\mathbf{x})</script></span>의 제곱 합을 최소화하는 해를 찾는 것이 목표이다.</p>
<h3 id="_1">최소제곱 문제의 수학적 정의</h3>
<p>Gauss-Newton 방법은 다음의 최소제곱 문제를 풀기 위한 방법이다:</p>
<div class="arithmatex">
<div class="MathJax_Preview">
\min_{\mathbf{x}} \frac{1}{2} \sum_{i=1}^{n} \left( r_i(\mathbf{x}) \right)^2
</div>
<script type="math/tex; mode=display">
\min_{\mathbf{x}} \frac{1}{2} \sum_{i=1}^{n} \left( r_i(\mathbf{x}) \right)^2
</script>
</div>
<p>여기서 <span class="arithmatex"><span class="MathJax_Preview">r_i(\mathbf{x})</span><script type="math/tex">r_i(\mathbf{x})</script></span>는 각 데이터 포인트에 대한 잔차를 의미한다. 이 식을 벡터 형태로 표현하면:</p>
<div class="arithmatex">
<div class="MathJax_Preview">
\min_{\mathbf{x}} \frac{1}{2} \| \mathbf{r}(\mathbf{x}) \|^2
</div>
<script type="math/tex; mode=display">
\min_{\mathbf{x}} \frac{1}{2} \| \mathbf{r}(\mathbf{x}) \|^2
</script>
</div>
<p>여기서 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{r}(\mathbf{x})</span><script type="math/tex">\mathbf{r}(\mathbf{x})</script></span>는 잔차 벡터로, 각 구성 요소가 잔차를 나타낸다. 이 문제는 잔차 벡터의 제곱합을 최소화하는 것이다.</p>
<h3 id="jacobian">선형화와 Jacobian 행렬</h3>
<p>비선형 문제를 풀기 위해, Gauss-Newton 방법은 잔차 함수를 선형화하는 과정을 거친다. <span class="arithmatex"><span class="MathJax_Preview">\mathbf{x}</span><script type="math/tex">\mathbf{x}</script></span> 근처에서 잔차 함수 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{r}(\mathbf{x})</span><script type="math/tex">\mathbf{r}(\mathbf{x})</script></span>를 Taylor 급수로 전개하면 다음과 같다:</p>
<div class="arithmatex">
<div class="MathJax_Preview">
\mathbf{r}(\mathbf{x} + \Delta \mathbf{x}) \approx \mathbf{r}(\mathbf{x}) + \mathbf{J}(\mathbf{x}) \Delta \mathbf{x}
</div>
<script type="math/tex; mode=display">
\mathbf{r}(\mathbf{x} + \Delta \mathbf{x}) \approx \mathbf{r}(\mathbf{x}) + \mathbf{J}(\mathbf{x}) \Delta \mathbf{x}
</script>
</div>
<p>여기서 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{J}(\mathbf{x})</span><script type="math/tex">\mathbf{J}(\mathbf{x})</script></span>는 잔차 함수의 Jacobian 행렬이다. Jacobian 행렬 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{J}(\mathbf{x})</span><script type="math/tex">\mathbf{J}(\mathbf{x})</script></span>는 각 잔차 <span class="arithmatex"><span class="MathJax_Preview">r_i(\mathbf{x})</span><script type="math/tex">r_i(\mathbf{x})</script></span>에 대한 변수 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{x}</span><script type="math/tex">\mathbf{x}</script></span>의 편미분으로 구성된 행렬이다:</p>
<div class="arithmatex">
<div class="MathJax_Preview">
\mathbf{J}(\mathbf{x}) = \begin{bmatrix} \frac{\partial r_1}{\partial x_1} &amp; \frac{\partial r_1}{\partial x_2} &amp; \dots &amp; \frac{\partial r_1}{\partial x_n} \\ \frac{\partial r_2}{\partial x_1} &amp; \frac{\partial r_2}{\partial x_2} &amp; \dots &amp; \frac{\partial r_2}{\partial x_n} \\ \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\ \frac{\partial r_m}{\partial x_1} &amp; \frac{\partial r_m}{\partial x_2} &amp; \dots &amp; \frac{\partial r_m}{\partial x_n} \end{bmatrix}
</div>
<script type="math/tex; mode=display">
\mathbf{J}(\mathbf{x}) = \begin{bmatrix} \frac{\partial r_1}{\partial x_1} & \frac{\partial r_1}{\partial x_2} & \dots & \frac{\partial r_1}{\partial x_n} \\ \frac{\partial r_2}{\partial x_1} & \frac{\partial r_2}{\partial x_2} & \dots & \frac{\partial r_2}{\partial x_n} \\ \vdots & \vdots & \ddots & \vdots \\ \frac{\partial r_m}{\partial x_1} & \frac{\partial r_m}{\partial x_2} & \dots & \frac{\partial r_m}{\partial x_n} \end{bmatrix}
</script>
</div>
<p>따라서, 선형화된 잔차 함수에 대한 최적화 문제는 다음과 같이 표현할 수 있다:</p>
<div class="arithmatex">
<div class="MathJax_Preview">
\min_{\Delta \mathbf{x}} \| \mathbf{r}(\mathbf{x}) + \mathbf{J}(\mathbf{x}) \Delta \mathbf{x} \|^2
</div>
<script type="math/tex; mode=display">
\min_{\Delta \mathbf{x}} \| \mathbf{r}(\mathbf{x}) + \mathbf{J}(\mathbf{x}) \Delta \mathbf{x} \|^2
</script>
</div>
<p>이 문제는 선형 최소제곱 문제로 변환되며, 이를 통해 <span class="arithmatex"><span class="MathJax_Preview">\Delta \mathbf{x}</span><script type="math/tex">\Delta \mathbf{x}</script></span>의 해를 구할 수 있다. Gauss-Newton 방법은 이 과정을 반복하여 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{x}</span><script type="math/tex">\mathbf{x}</script></span>를 갱신한다.</p>
<h3 id="gauss-newton_1">Gauss-Newton 업데이트 규칙</h3>
<p>최적화 문제를 풀기 위해, Gauss-Newton 방법은 선형 최소제곱 문제의 해를 이용해 변수 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{x}</span><script type="math/tex">\mathbf{x}</script></span>를 갱신한다. 최적화 과정에서 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{x}</span><script type="math/tex">\mathbf{x}</script></span>는 다음과 같이 업데이트된다:</p>
<div class="arithmatex">
<div class="MathJax_Preview">
\Delta \mathbf{x} = - \left( \mathbf{J}^\top(\mathbf{x}) \mathbf{J}(\mathbf{x}) \right)^{-1} \mathbf{J}^\top(\mathbf{x}) \mathbf{r}(\mathbf{x})
</div>
<script type="math/tex; mode=display">
\Delta \mathbf{x} = - \left( \mathbf{J}^\top(\mathbf{x}) \mathbf{J}(\mathbf{x}) \right)^{-1} \mathbf{J}^\top(\mathbf{x}) \mathbf{r}(\mathbf{x})
</script>
</div>
<p>이 업데이트 식을 이용하여 새로운 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{x}</span><script type="math/tex">\mathbf{x}</script></span>는 다음과 같이 갱신된다:</p>
<div class="arithmatex">
<div class="MathJax_Preview">
\mathbf{x}_{\text{new}} = \mathbf{x} + \Delta \mathbf{x}
</div>
<script type="math/tex; mode=display">
\mathbf{x}_{\text{new}} = \mathbf{x} + \Delta \mathbf{x}
</script>
</div>
<p>여기서, <span class="arithmatex"><span class="MathJax_Preview">\mathbf{J}^\top(\mathbf{x}) \mathbf{J}(\mathbf{x})</span><script type="math/tex">\mathbf{J}^\top(\mathbf{x}) \mathbf{J}(\mathbf{x})</script></span>는 Hessian 행렬의 근사치로 사용되며, 이 값을 통해 비선형 문제를 선형 문제로 풀 수 있다.</p>
<h3 id="gauss-newton_2">Gauss-Newton 알고리즘의 수렴 조건</h3>
<p>Gauss-Newton 방법이 수렴하기 위해서는 몇 가지 중요한 조건이 필요하다. 먼저, 초기 추정값 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{x}_0</span><script type="math/tex">\mathbf{x}_0</script></span>가 실제 해에 가깝게 설정되어야 한다. Gauss-Newton 방법은 기본적으로 2차 정확도(즉, 2차 미분에 대한 정보)를 사용하지 않기 때문에, 초기 값이 너무 멀리 떨어져 있을 경우 잘못된 지역 해에 빠질 수 있다.</p>
<p>또한, Jacobian 행렬 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{J}(\mathbf{x})</span><script type="math/tex">\mathbf{J}(\mathbf{x})</script></span>가 비특이(singular)하지 않아야 한다. 만약 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{J}(\mathbf{x})^\top \mathbf{J}(\mathbf{x})</span><script type="math/tex">\mathbf{J}(\mathbf{x})^\top \mathbf{J}(\mathbf{x})</script></span>가 특이 행렬이라면, 이 식의 역행렬이 존재하지 않게 되어 알고리즘이 실패할 수 있다. 따라서, 문제의 구조가 잘 정의되어 있고 충분히 독립적인 데이터 포인트가 있어야 한다.</p>
<h3 id="gauss-newton_3">Gauss-Newton 알고리즘의 단계</h3>
<p>Gauss-Newton 방법은 다음의 반복적인 절차를 따른다:</p>
<ol>
<li>초기 추정값 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{x}_0</span><script type="math/tex">\mathbf{x}_0</script></span>을 설정한다.</li>
<li>현재의 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{x}_k</span><script type="math/tex">\mathbf{x}_k</script></span>에서 잔차 함수 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{r}(\mathbf{x}_k)</span><script type="math/tex">\mathbf{r}(\mathbf{x}_k)</script></span>와 Jacobian <span class="arithmatex"><span class="MathJax_Preview">\mathbf{J}(\mathbf{x}_k)</span><script type="math/tex">\mathbf{J}(\mathbf{x}_k)</script></span>를 계산한다.</li>
<li>업데이트 규칙 <span class="arithmatex"><span class="MathJax_Preview">\Delta \mathbf{x}_k = - \left( \mathbf{J}^\top(\mathbf{x}_k) \mathbf{J}(\mathbf{x}_k) \right)^{-1} \mathbf{J}^\top(\mathbf{x}_k) \mathbf{r}(\mathbf{x}_k)</span><script type="math/tex">\Delta \mathbf{x}_k = - \left( \mathbf{J}^\top(\mathbf{x}_k) \mathbf{J}(\mathbf{x}_k) \right)^{-1} \mathbf{J}^\top(\mathbf{x}_k) \mathbf{r}(\mathbf{x}_k)</script></span>을 사용하여 <span class="arithmatex"><span class="MathJax_Preview">\Delta \mathbf{x}_k</span><script type="math/tex">\Delta \mathbf{x}_k</script></span>를 계산한다.</li>
<li>새로운 변수 값을 갱신한다: <span class="arithmatex"><span class="MathJax_Preview">\mathbf{x}_{k+1} = \mathbf{x}_k + \Delta \mathbf{x}_k</span><script type="math/tex">\mathbf{x}_{k+1} = \mathbf{x}_k + \Delta \mathbf{x}_k</script></span>.</li>
<li>종료 조건(예: <span class="arithmatex"><span class="MathJax_Preview">\|\Delta \mathbf{x}_k\|</span><script type="math/tex">\|\Delta \mathbf{x}_k\|</script></span> 또는 <span class="arithmatex"><span class="MathJax_Preview">\| \mathbf{r}(\mathbf{x}_k) \|</span><script type="math/tex">\| \mathbf{r}(\mathbf{x}_k) \|</script></span>이 작은 값이 될 때까지)을 만족할 때까지 2번부터 4번 단계를 반복한다.</li>
</ol>
<h3 id="_2">장단점</h3>
<p>Gauss-Newton 방법은 다른 비선형 최적화 알고리즘에 비해 몇 가지 장점과 단점을 가진다.</p>
<h4 id="_3">장점</h4>
<ol>
<li><strong>간단한 구조</strong>: Gauss-Newton 방법은 비교적 간단하게 구현할 수 있으며, 계산 비용도 적은 편이다. 이는 특히 다차원 문제에서도 쉽게 적용할 수 있다.</li>
<li><strong>빠른 수렴</strong>: 초기 추정값이 실제 해에 가까운 경우, Gauss-Newton 방법은 매우 빠르게 수렴할 수 있다.</li>
</ol>
<h4 id="_4">단점</h4>
<ol>
<li><strong>초기값 의존성</strong>: Gauss-Newton 방법은 초기 추정값에 매우 민감하다. 잘못된 초기값을 사용하면 수렴하지 않거나 잘못된 해를 찾을 수 있다.</li>
<li><strong>Jacobian 계산의 복잡성</strong>: Jacobian 행렬을 계산하는 것이 복잡하거나 비용이 많이 들 수 있다. 특히 함수가 복잡한 경우, 이 행렬을 효율적으로 계산하는 것이 까다로울 수 있다.</li>
</ol>

  <br>
    

    
    
      
    

  <div class="row wm-article-nav-buttons" role="navigation" aria-label="navigation">
    
    <div class="wm-article-nav pull-right">
      <a href="../0603/" class="btn btn-xs btn-default pull-right">
        Next
        <i class="fa fa-chevron-right" aria-hidden="true"></i>
      </a>
      <a href="../0603/" class="btn btn-xs btn-link">
        Levenberg-Marquardt 최적화
      </a>
    </div>
    
    <div class="wm-article-nav">
      <a href="../0601/" class="btn btn-xs btn-default pull-left">
        <i class="fa fa-chevron-left" aria-hidden="true"></i>
        Previous</a><a href="../0601/" class="btn btn-xs btn-link">
        Non-linear 최적화 기법
      </a>
    </div>
    
  </div>

    <br>
</div>

<footer class="container-fluid wm-page-content">
  <p>Documentation built with <a href="https://www.mkdocs.org/">MkDocs</a> using <a href="https://github.com/gristlabs/mkdocs-windmill">Windmill</a> theme by Grist Labs.</p>
</footer>

</body>
</html>