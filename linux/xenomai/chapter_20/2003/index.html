<!DOCTYPE html>
<html lang="en">
<head>
  
  
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    
    
    <link rel="canonical" href="https://booiljung.github.io/linux/xenomai/chapter_20/2003/">
    <link rel="shortcut icon" href="../../../../img/favicon.ico">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" />
    <title>Xenomai에서 실시간 오디오 및 멀티미디어 처리 - 소프트웨어 융합</title>
    <link href="../../../../css/bootstrap-3.3.7.min.css" rel="stylesheet">
    <link href="../../../../css/font-awesome-4.7.0.css" rel="stylesheet">
    <link href="../../../../css/base.css" rel="stylesheet">
    <link rel="stylesheet" href="../../../../css/highlight.css">
    <link href="../../../../css/custom.css" rel="stylesheet">
    <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.3.0/respond.min.js"></script>
    <![endif]-->

    <script src="../../../../js/jquery-3.2.1.min.js"></script>
    <script src="../../../../js/bootstrap-3.3.7.min.js"></script>
    <script src="../../../../js/highlight.pack.js"></script>
    
    <base target="_top">
    <script>
      var base_url = '../../../..';
      var is_top_frame = false;
        
        var pageToc = [
          {title: "\uc624\ub514\uc624 \ubc0f \ube44\ub514\uc624 \uc2a4\ud2b8\ub9bc \ub3d9\uae30\ud654", url: "#_top", children: [
              {title: "\ub3d9\uae30\ud654\uc758 \uae30\ubcf8 \uac1c\ub150", url: "#_2" },
              {title: "\ud074\ub7ed \uc18c\uc2a4 \uc124\uc815", url: "#_3" },
              {title: "\ud0c0\uc784\uc2a4\ud0ec\ud504 \uc0dd\uc131 \ubc0f \uad00\ub9ac", url: "#_4" },
              {title: "\ubc84\ud37c \uad00\ub9ac", url: "#_5" },
              {title: "\uc7ac\uc0dd \ub3d9\uae30\ud654", url: "#_6" },
              {title: "\ucd1d \uc815\ub9ac \ubc0f \uc608\uc81c \uc751\uc6a9 \ud504\ub85c\uadf8\ub7a8", url: "#_7" },
          ]},
        ];

    </script>
    <script src="../../../../js/base.js"></script>
      <script src="../../../../js/google_analytics.js"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML"></script>
      <script src="https://www.googletagmanager.com/gtag/js?id=G-3F4LHCTF88"></script> 
</head>

<body>
<script>
if (is_top_frame) { $('body').addClass('wm-top-page'); }
</script>



<div class="container-fluid wm-page-content">
  <a name="_top"></a>
    

    
    
      
    

  <div class="row wm-article-nav-buttons" role="navigation" aria-label="navigation">
    
    <div class="wm-article-nav pull-right">
      <a href="../2004/" class="btn btn-xs btn-default pull-right">
        Next
        <i class="fa fa-chevron-right" aria-hidden="true"></i>
      </a>
      <a href="../2004/" class="btn btn-xs btn-link">
        저지연 오디오 드라이버 개발
      </a>
    </div>
    
    <div class="wm-article-nav">
      <a href="../2002/" class="btn btn-xs btn-default pull-left">
        <i class="fa fa-chevron-left" aria-hidden="true"></i>
        Previous</a><a href="../2002/" class="btn btn-xs btn-link">
        Xenomai를 이용한 실시간 오디오 처리
      </a>
    </div>
    
  </div>

    

    <h3 id="_1">오디오 및 비디오 스트림 동기화</h3>
<p>오디오 및 비디오 스트림의 동기화는 멀티미디어 응용 프로그램에서 매우 중요한 요소이다. 이는 소리와 영상이 동시에 일어나도록 해야 하기 때문이다. Xenomai에서 실시간 특성을 활용하여 이를 원활하게 수행할 수 있다. 다음은 동기화를 수행하는 데 필요한 주요 단계와 기술들이다.</p>
<h4 id="_2">동기화의 기본 개념</h4>
<p>멀티미디어 동기화의 목적은 오디오 프레임과 비디오 프레임이 시간적으로 일치하게 하는 것이다. 이를 위해 일반적으로 '타임스탬프'를 활용한다. 타임스탬프는 각 프레임에 특정 시간 정보를 부여하여 일정 시간 간격에 정확하게 처리되도록 한다.</p>
<h4 id="_3">클럭 소스 설정</h4>
<p>오디오 및 비디오 스트림을 동기화하기 위해 첫 번째 단계는 신뢰할 수 있는 클럭 소스를 설정하는 것이다. 여기 사용되는 클럭 소스는 다음과 같을 수 있다:</p>
<ul>
<li><strong>시스템 클럭</strong>: 운영체제의 시스템 클럭을 사용하여 타임스탬프를 생성.</li>
<li><strong>멀티미디어 하드웨어 타이머</strong>: 특정 하드웨어 장치가 제공하는 하드웨어 타이머를 사용.</li>
</ul>
<p><code>clock_gettime()</code> 함수를 사용하여 타임스탬프를 얻을 수 있다.</p>
<pre><code class="language-c">struct timespec ts;
clock_gettime(CLOCK_REALTIME, &amp;ts);
</code></pre>
<h4 id="_4">타임스탬프 생성 및 관리</h4>
<p>각 오디오와 비디오 프레임에 타임스탬프를 부여할 때는 생성 시간을 기록한다. 이를 통해 각 프레임이 정확히 언제 처리되어야 하는지를 결정할 수 있다. 예를 들어, 비디오 프레임은 24fps로 렌더링되어야 하므로 각 프레임의 간격은 약 41.67ms가 된다.</p>
<p>각 오디오와 비디오 프레임에 대해 다음과 같이 타임스탬프를 부여할 수 있다.</p>
<div class="arithmatex">
<div class="MathJax_Preview">
T_{\text{frame}} = T_{\text{start}} + \frac{1}{\text{fps}} \times N
</div>
<script type="math/tex; mode=display">
T_{\text{frame}} = T_{\text{start}} + \frac{1}{\text{fps}} \times N
</script>
</div>
<p>여기서 <span class="arithmatex"><span class="MathJax_Preview">T_{\text{start}}</span><script type="math/tex">T_{\text{start}}</script></span>는 시작 시간이고, <span class="arithmatex"><span class="MathJax_Preview">\text{fps}</span><script type="math/tex">\text{fps}</script></span>는 프레임 속도, <span class="arithmatex"><span class="MathJax_Preview">N</span><script type="math/tex">N</script></span>은 프레임의 순서이다.</p>
<h4 id="_5">버퍼 관리</h4>
<p>오디오 및 비디오 데이터를 동기화하려면 성공적인 버퍼 관리를 통해 지연을 최소화하는 것이 중요하다. 일반적으로 링 버퍼(Ring Buffer) 또는 큐(Queue)를 사용하여 스트림 데이터를 처리한다.</p>
<p>오디오 및 비디오 프레임을 처리할 때 다음과 같이 버퍼를 사용할 수 있다.</p>
<pre><code class="language-c">// Example Ring Buffer
typedef struct {
   int start;
   int end;
   int size;
   void **buffer;
} RingBuffer;

void enqueue(RingBuffer *rb, void *item) {
   rb-&gt;buffer[rb-&gt;end] = item;
   rb-&gt;end = (rb-&gt;end + 1) % rb-&gt;size;
}

void* dequeue(RingBuffer *rb) {
   void *item = rb-&gt;buffer[rb-&gt;start];
   rb-&gt;start = (rb-&gt;start + 1) % rb-&gt;size;
   return item;
}
</code></pre>
<p>처리 루프에서 버퍼에서 데이터를 빼오고 각 프레임의 타임스탬프를 기반으로 마이크로초 단위의 정확한 시간에 재생해야 한다.</p>
<h4 id="_6">재생 동기화</h4>
<p>오디오와 비디오의 재생 단계에서 각 프레임의 타임스탬프를 확인하고, 현재 시스템 시간과 비교하여 재생 시간을 조정한다. 로컬 타임스탬프와 재생 타임스탬프의 차이를 줄이기 위해 오디오와 비디오 프레임의 시간을 보정할 수 있는 알고리즘이 필요하다.</p>
<p>예를 들어 다음과 같은 간격 기반 접근 방식을 사용할 수 있다.</p>
<pre><code class="language-c">void synchronize_frames(time_t frame_timestamp, time_t now) {
   time_t delay = frame_timestamp - now;
   if (delay &gt; 0) {
      usleep(delay);
   }
}
</code></pre>
<p>위 코드는 현재 시간과 프레임 타임스탬프를 비교하여 필요한 만큼 지연을 추가한다.</p>
<h4 id="_7">총 정리 및 예제 응용 프로그램</h4>
<p>위에서 설명한 개념을 모두 통합하여 간단한 예제 응용 프로그램을 작성할 수 있다. 이 예제는 오디오와 비디오 스트림을 동기화하는 방법을 보여준다.</p>
<pre><code class="language-c">#include &lt;stdio.h&gt;
#include &lt;unistd.h&gt;
#include &lt;time.h&gt;
#include &lt;pthread.h&gt;

#define FPS 24
#define FRAME_INTERVAL (1000000 / FPS) // in microseconds

typedef struct {
   RingBuffer audio_buffer;
   RingBuffer video_buffer;
} StreamBuffers;

void *audio_thread(void *args) {
   StreamBuffers *buffers = (StreamBuffers *)args;
   struct timespec timestamp;
   while (1) {
      clock_gettime(CLOCK_REALTIME, &amp;timestamp);
      enqueue(&amp;buffers-&gt;audio_buffer, &amp;timestamp);
      usleep(FRAME_INTERVAL);
   }
   return NULL;
}

void *video_thread(void *args) {
   StreamBuffers *buffers = (StreamBuffers *)args;
   struct timespec timestamp;
   while (1) {
      clock_gettime(CLOCK_REALTIME, &amp;timestamp);
      enqueue(&amp;buffers-&gt;video_buffer, &amp;timestamp);
      usleep(FRAME_INTERVAL);
   }
   return NULL;
}

void synchronize_and_play(StreamBuffers *buffers) {
   while (1) {
      struct timespec audio_frame, video_frame;

      audio_frame = *(struct timespec *)dequeue(&amp;buffers-&gt;audio_buffer);
      video_frame = *(struct timespec *)dequeue(&amp;buffers-&gt;video_buffer);

      // Synchronize
      synchronize_frames(audio_frame.tv_nsec, video_frame.tv_nsec);

      // Play audio and video frame
      // For demonstration, we'll just print the timestamps.
      printf(&quot;Playing Audio Frame at: %ld:%ld, Video Frame at: %ld:%ld\n&quot;, 
             audio_frame.tv_sec, audio_frame.tv_nsec, 
             video_frame.tv_sec, video_frame.tv_nsec);

      usleep(FRAME_INTERVAL);
   }
}

int main() {
   StreamBuffers buffers;
   pthread_t audio_tid, video_tid;

   // Initialize RingBuffers and other structures
   // Here we assume the buffer size is set correctly and memory is allocated.

   // Create threads for audio and video streaming
   pthread_create(&amp;audio_tid, NULL, audio_thread, &amp;buffers);
   pthread_create(&amp;video_tid, NULL, video_thread, &amp;buffers);

   // Main thread handles synchronization and playing
   synchronize_and_play(&amp;buffers);

   // Join threads (optional)
   pthread_join(audio_tid, NULL);
   pthread_join(video_tid, NULL);

   return 0;
}
</code></pre>
<p>이 코드는 기본적인 스트림 버퍼링, 시간 동기화, 그리고 재생 기능을 포함한다. 각 타임스탬프를 기반으로 오디오와 비디오 프레임을 동기화하여 재생한다. 실제 응용에서는 재생 장치와 상호작용하는 부분이 추가되어야 하고, 버퍼 관리와 에러 처리가 더 강화되어야 한다.</p>
<p>이와 같이 Xenomai를 사용하면 임베디드 시스템에서 실시간 오디오 및 비디오 싱크 작업을 보다 효과적으로 수행할 수 있다. 실시간 커널의 특성 덕분에 지연을 최소화하고 정확한 타이밍으로 멀티미디어 데이터를 처리할 수 있다.</p>

  <br>
    

    
    
      
    

  <div class="row wm-article-nav-buttons" role="navigation" aria-label="navigation">
    
    <div class="wm-article-nav pull-right">
      <a href="../2004/" class="btn btn-xs btn-default pull-right">
        Next
        <i class="fa fa-chevron-right" aria-hidden="true"></i>
      </a>
      <a href="../2004/" class="btn btn-xs btn-link">
        저지연 오디오 드라이버 개발
      </a>
    </div>
    
    <div class="wm-article-nav">
      <a href="../2002/" class="btn btn-xs btn-default pull-left">
        <i class="fa fa-chevron-left" aria-hidden="true"></i>
        Previous</a><a href="../2002/" class="btn btn-xs btn-link">
        Xenomai를 이용한 실시간 오디오 처리
      </a>
    </div>
    
  </div>

    <br>
</div>

<footer class="container-fluid wm-page-content">
  <p>Documentation built with <a href="https://www.mkdocs.org/">MkDocs</a> using <a href="https://github.com/gristlabs/mkdocs-windmill">Windmill</a> theme by Grist Labs.</p>
</footer>

</body>
</html>