<!DOCTYPE html>
<html lang="en">
<head>
  
  
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    
    
    <link rel="canonical" href="https://booiljung.github.io/artificial_intelligent/chatgpt_api/chapter_03/0304/">
    <link rel="shortcut icon" href="../../../../img/favicon.ico">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" />
    <title>요청 파라미터의 이해 - 실험 도서관</title>
    <link href="../../../../css/bootstrap-3.3.7.min.css" rel="stylesheet">
    <link href="../../../../css/font-awesome-4.7.0.css" rel="stylesheet">
    <link href="../../../../css/base.css" rel="stylesheet">
    <link rel="stylesheet" href="../../../../css/highlight.css">
    <link href="../../../../css/custom.css" rel="stylesheet">
    <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.3.0/respond.min.js"></script>
    <![endif]-->

    <script src="../../../../js/jquery-3.2.1.min.js"></script>
    <script src="../../../../js/bootstrap-3.3.7.min.js"></script>
    <script src="../../../../js/highlight.pack.js"></script>
    
    <base target="_top">
    <script>
      var base_url = '../../../..';
      var is_top_frame = false;
        
        var pageToc = [
          {title: "API \uae30\ubcf8 \uc694\uccad \uad6c\uc870", url: "#_top", children: [
          ]},
          {title: "model", url: "#model", children: [
          ]},
          {title: "messages", url: "#messages", children: [
          ]},
          {title: "temperature", url: "#temperature", children: [
          ]},
          {title: "max_tokens", url: "#max_tokens", children: [
          ]},
          {title: "top_p", url: "#top_p", children: [
          ]},
          {title: "presence_penalty", url: "#presence_penalty", children: [
          ]},
          {title: "frequency_penalty", url: "#frequency_penalty", children: [
          ]},
          {title: "stop", url: "#stop", children: [
          ]},
          {title: "logit_bias", url: "#logit_bias", children: [
          ]},
          {title: "n", url: "#n", children: [
          ]},
          {title: "stream", url: "#stream", children: [
          ]},
          {title: "user", url: "#user", children: [
          ]},
          {title: "stream\uacfc \ube44\ub3d9\uae30 \ucc98\ub9ac", url: "#stream_1", children: [
          ]},
          {title: "\ub2e4\uc591\ud55c \ud30c\ub77c\ubbf8\ud130\uc758 \uc870\ud569", url: "#_1", children: [
          ]},
        ];

    </script>
    <script src="../../../../js/base.js"></script>
      <script src="../../../../js/google_analytics.js"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML"></script>
      <script src="https://www.googletagmanager.com/gtag/js?id=G-3F4LHCTF88"></script> 
</head>

<body>
<script>
if (is_top_frame) { $('body').addClass('wm-top-page'); }
</script>



<div class="container-fluid wm-page-content">
  <a name="_top"></a>
    

    
    
      
    

  <div class="row wm-article-nav-buttons" role="navigation" aria-label="navigation">
    
    <div class="wm-article-nav pull-right">
      <a href="../0305/" class="btn btn-xs btn-default pull-right">
        Next
        <i class="fa fa-chevron-right" aria-hidden="true"></i>
      </a>
      <a href="../0305/" class="btn btn-xs btn-link">
        응답 데이터 처리 및 파싱
      </a>
    </div>
    
    <div class="wm-article-nav">
      <a href="../0303/" class="btn btn-xs btn-default pull-left">
        <i class="fa fa-chevron-left" aria-hidden="true"></i>
        Previous</a><a href="../0303/" class="btn btn-xs btn-link">
        간단한 텍스트 생성 예제
      </a>
    </div>
    
  </div>

    

    <p>ChatGPT API를 사용하여 다양한 작업을 수행할 때, 요청 파라미터의 설정은 매우 중요하다. 요청 파라미터는 API가 입력을 어떻게 처리하고, 어떤 방식으로 응답을 생성할지를 제어한다. 이 섹션에서는 주요 요청 파라미터에 대해 상세히 설명하고, 각각의 파라미터가 어떤 역할을 하는지, 그리고 이를 어떻게 최적화할 수 있는지에 대해 다룬다.</p>
<h3 id="api">API 기본 요청 구조</h3>
<p>ChatGPT API 요청은 보통 HTTP POST 요청으로 이루어지며, JSON 형식의 페이로드를 포함한다. 기본적인 구조는 다음과 같다.</p>
<pre><code class="language-python">import openai

response = openai.ChatCompletion.create(
    model=&quot;gpt-4&quot;,
    messages=[
        {&quot;role&quot;: &quot;system&quot;, &quot;content&quot;: &quot;You are a helpful assistant.&quot;},
        {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;Can you help me with some information?&quot;}
    ],
    temperature=0.7,
    max_tokens=100
)
</code></pre>
<p>이 기본적인 예제에서, 우리는 <code>model</code>, <code>messages</code>, <code>temperature</code>, <code>max_tokens</code>와 같은 몇 가지 중요한 파라미터를 사용하였다. 이제 이들 파라미터의 역할과 설정 방법을 상세히 살펴보겠다.</p>
<h3 id="model">model</h3>
<ul>
<li><strong>설명</strong>: <code>model</code> 파라미터는 요청에 사용할 언어 모델을 지정한다. 예를 들어, <code>gpt-4</code>는 GPT-4 모델을, <code>gpt-3.5-turbo</code>는 GPT-3.5 모델을 의미한다.</li>
<li><strong>용도</strong>: 모델의 선택은 응답의 품질과 API 사용 비용에 직접적인 영향을 미친다. 최신 모델일수록 더 나은 성능을 제공하지만, 비용이 더 많이 들 수 있다.</li>
<li><strong>예시</strong>: </li>
</ul>
<pre><code class="language-python">model=&quot;gpt-4&quot;
</code></pre>
<h3 id="messages">messages</h3>
<ul>
<li><strong>설명</strong>: <code>messages</code> 파라미터는 대화의 맥락을 제공하는 입력 메시지들의 리스트이다. 각 메시지는 <code>role</code>과 <code>content</code>로 구성된다.</li>
<li><code>role</code>: 메시지의 역할을 지정하며, <code>system</code>, <code>user</code>, <code>assistant</code> 중 하나를 가질 수 있다.</li>
<li><code>content</code>: 해당 메시지의 실제 내용을 담고 있다.</li>
<li><strong>용도</strong>: 이 파라미터는 대화의 흐름을 관리하며, 시스템의 초기 지침을 설정하거나 사용자의 질문, 그리고 이전 대화 내용을 포함할 수 있다.</li>
<li><strong>예시</strong>:</li>
</ul>
<pre><code class="language-python">messages=[
    {&quot;role&quot;: &quot;system&quot;, &quot;content&quot;: &quot;You are a helpful assistant.&quot;},
    {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;What is the capital of France?&quot;}
]
</code></pre>
<h3 id="temperature">temperature</h3>
<ul>
<li><strong>설명</strong>: <code>temperature</code> 파라미터는 생성되는 텍스트의 창의성을 조절하는 데 사용된다. 이 값은 0과 1 사이의 부동소수점 수로 설정할 수 있다.</li>
<li>값이 높을수록(예: 0.8) 더 창의적이고 다양성 있는 출력을 생성한다.</li>
<li>값이 낮을수록(예: 0.2) 더 집중되고 예측 가능한 출력을 생성한다.</li>
<li><strong>용도</strong>: 창의성이 필요한 작업(예: 이야기 생성)에서는 높은 <code>temperature</code> 값을, 정확한 답변이 필요한 작업(예: 사실 기반 질문)에서는 낮은 <code>temperature</code> 값을 사용하는 것이 일반적이다.</li>
<li><strong>수식</strong>: 텍스트 생성 과정에서의 확률 분포는 다음과 같이 표현될 수 있다.</li>
</ul>
<p>$$</p>
<p>P(w_i) = \frac{\exp\left(\frac{\log P(w_i)}{\text{temperature}}\right)}{\sum_{j} \exp\left(\frac{\log P(w_j)}{\text{temperature}}\right)}</p>
<p>$$</p>
<p>여기서 <span class="arithmatex"><span class="MathJax_Preview">P(w_i)</span><script type="math/tex">P(w_i)</script></span>는 단어 <span class="arithmatex"><span class="MathJax_Preview">w_i</span><script type="math/tex">w_i</script></span>가 선택될 확률을 나타내며, <code>temperature</code> 값이 확률 분포의 집중도에 영향을 준다.</p>
<ul>
<li><strong>예시</strong>:</li>
</ul>
<pre><code class="language-python">temperature=0.7
</code></pre>
<h3 id="max_tokens">max_tokens</h3>
<ul>
<li><strong>설명</strong>: <code>max_tokens</code> 파라미터는 API가 생성할 수 있는 최대 토큰 수를 지정한다. 여기서 "토큰"은 단어의 조각이나 전체 단어를 나타낼 수 있으며, 모델에 따라 다르게 정의된다.</li>
<li><strong>용도</strong>: 생성되는 텍스트의 길이를 제어하는 데 사용된다. 긴 응답이 필요한 경우 이 값을 높이고, 짧은 응답이 필요한 경우 이 값을 낮춘다.</li>
<li><strong>수식</strong>: 출력 텍스트 <span class="arithmatex"><span class="MathJax_Preview">T</span><script type="math/tex">T</script></span>는 다음과 같이 표현될 수 있다.</li>
</ul>
<p>$$</p>
<p>T = \sum_{i=1}^{n} t_i \quad \text{where} \quad n \leq \text{max_tokens}</p>
<p>$$</p>
<p>여기서 <span class="arithmatex"><span class="MathJax_Preview">t_i</span><script type="math/tex">t_i</script></span>는 개별 토큰을 의미하며, 총합 <span class="arithmatex"><span class="MathJax_Preview">T</span><script type="math/tex">T</script></span>의 길이는 <code>max_tokens</code>를 초과할 수 없다.</p>
<ul>
<li><strong>예시</strong>:</li>
</ul>
<pre><code class="language-python">max_tokens=100
</code></pre>
<h3 id="top_p">top_p</h3>
<ul>
<li><strong>설명</strong>: <code>top_p</code> 파라미터는 Nucleus Sampling(핵심 샘플링) 기법을 사용하여 텍스트 생성을 제어한다. <code>top_p</code>는 확률의 누적 합계가 <code>top_p</code> 이상이 될 때까지 후보 단어를 포함한다.</li>
<li><code>top_p=1.0</code>은 nucleus sampling을 사용하지 않음을 의미하며, 모든 후보 단어가 고려된다.</li>
<li><code>top_p=0.9</code>은 상위 90%의 확률 질량을 차지하는 단어들만 고려한다.</li>
<li><strong>용도</strong>: 이 파라미터는 모델의 출력을 더욱 다양하게 만들 수 있으며, 특정 응답 유형을 선호하는 데 도움이 된다.</li>
<li><strong>수식</strong>: 텍스트 생성 시 후보 단어들의 누적 확률은 다음과 같다.</li>
</ul>
<p>$$</p>
<p>\sum_{i=1}^{k} P(w_i) \geq \text{top_p}</p>
<p>$$</p>
<p>여기서 <span class="arithmatex"><span class="MathJax_Preview">k</span><script type="math/tex">k</script></span>는 선택된 단어의 수를 나타내며, 총합이 <code>top_p</code> 이상이 되면 후보 선택이 종료된다.</p>
<ul>
<li><strong>예시</strong>:</li>
</ul>
<pre><code class="language-python">top_p=0.9
</code></pre>
<h3 id="presence_penalty">presence_penalty</h3>
<ul>
<li><strong>설명</strong>: <code>presence_penalty</code>는 모델이 새로운 주제를 도입하는 빈도를 증가시키거나 감소시키는 데 사용된다. 값이 양수일 경우 새로운 주제를 도입하는 경향이 증가하고, 음수일 경우 감소한다.</li>
<li><strong>용도</strong>: 대화의 다양성을 높이거나 특정 주제에 대한 집중도를 조절할 때 유용하다.</li>
<li><strong>수식</strong>: 각 단어의 로그 확률 <span class="arithmatex"><span class="MathJax_Preview">\log P(w_i)</span><script type="math/tex">\log P(w_i)</script></span>에 가중치를 적용하여 계산된다.</li>
</ul>
<p>$$</p>
<p>\log P(w_i) = \log P(w_i) + (\text{presence_penalty})</p>
<p>$$</p>
<ul>
<li><strong>예시</strong>:</li>
</ul>
<pre><code class="language-python">presence_penalty=0.6
</code></pre>
<h3 id="frequency_penalty">frequency_penalty</h3>
<ul>
<li><strong>설명</strong>: <code>frequency_penalty</code>는 동일한 단어가 반복되는 빈도를 제어한다. 양수 값은 반복을 줄이고, 음수 값은 반복을 허용하는 경향이 있다.</li>
<li><strong>용도</strong>: 특정 단어의 반복을 피하고자 할 때 사용된다.</li>
<li><strong>수식</strong>: 반복 단어에 대해 로그 확률이 페널티를 받는다.</li>
</ul>
<p>$$</p>
<p>\log P(w_i) = \log P(w_i) - (\text{frequency_penalty} \times \text{count}(w_i))</p>
<p>$$</p>
<ul>
<li><strong>예시</strong>:</li>
</ul>
<pre><code class="language-python">frequency_penalty=0.5
</code></pre>
<h3 id="stop">stop</h3>
<ul>
<li><strong>설명</strong>: <code>stop</code> 파라미터는 생성된 텍스트를 멈추게 하는 문자열 또는 문자열 목록을 지정한다. 모델은 이 문자열을 만나면 추가 텍스트 생성을 중단한다.</li>
<li><strong>용도</strong>: 특정 구문이나 문장이 나타날 때 응답을 종료하고자 할 때 유용하다. 예를 들어, 대화형 응답에서 문장이 너무 길어지지 않도록 할 때 사용할 수 있다.</li>
<li><strong>예시</strong>:</li>
</ul>
<pre><code class="language-python">stop=[&quot;\n&quot;, &quot;User:&quot;]
</code></pre>
<p>위의 예시는 줄바꿈 문자나 "User:" 문자열을 만나면 텍스트 생성을 멈추도록 설정한다.</p>
<h3 id="logit_bias">logit_bias</h3>
<ul>
<li><strong>설명</strong>: <code>logit_bias</code> 파라미터는 특정 토큰의 선택 확률을 수정하는 데 사용된다. 토큰의 ID와 그에 대한 가중치를 매핑하여, 모델이 특정 토큰을 더 자주 또는 덜 자주 선택하도록 강제할 수 있다. </li>
<li><strong>용도</strong>: 특정 단어를 억제하거나 선호할 때 사용된다. 예를 들어, 부정적인 단어의 사용을 줄이거나 특정 키워드를 강조할 수 있다.</li>
<li><strong>수식</strong>: 각 토큰 <span class="arithmatex"><span class="MathJax_Preview">t_i</span><script type="math/tex">t_i</script></span>의 로그 확률 <span class="arithmatex"><span class="MathJax_Preview">\log P(t_i)</span><script type="math/tex">\log P(t_i)</script></span>는 다음과 같이 수정된다.</li>
</ul>
<p>$$</p>
<p>\log P(t_i) = \log P(t_i) + \text{logit_bias}(t_i)</p>
<p>$$</p>
<p>여기서 <code>logit_bias(t_i)</code>는 토큰 <span class="arithmatex"><span class="MathJax_Preview">t_i</span><script type="math/tex">t_i</script></span>에 적용되는 바이어스를 나타낸다.</p>
<ul>
<li><strong>예시</strong>:</li>
</ul>
<pre><code class="language-python">logit_bias={50256: -100}  # 특정 토큰의 확률을 사실상 0으로 만듦
</code></pre>
<h3 id="n">n</h3>
<ul>
<li><strong>설명</strong>: <code>n</code> 파라미터는 각 요청에서 생성할 응답의 개수를 지정한다. 하나의 요청에 대해 여러 개의 응답을 받아 다양한 출력을 비교할 수 있다.</li>
<li><strong>용도</strong>: 모델의 출력을 샘플링하여 다양한 응답을 생성하고자 할 때 유용하다. 여러 개의 응답을 받은 후, 그 중에서 가장 적합한 것을 선택할 수 있다.</li>
<li><strong>수식</strong>: 생성된 응답의 개수는 다음과 같이 표현된다.</li>
</ul>
<p>$$</p>
<p>\text{Number of responses} = n</p>
<p>$$</p>
<ul>
<li><strong>예시</strong>:</li>
</ul>
<pre><code class="language-python">n=3
</code></pre>
<h3 id="stream">stream</h3>
<ul>
<li><strong>설명</strong>: <code>stream</code> 파라미터는 응답을 스트리밍 방식으로 받을지를 결정한다. <code>stream=True</code>로 설정하면 응답이 생성되는 대로 실시간으로 전달된다.</li>
<li><strong>용도</strong>: 응답이 긴 경우 전체 응답을 기다리지 않고 부분적으로 처리할 수 있어, 사용자에게 더 빠른 피드백을 제공할 수 있다.</li>
<li><strong>예시</strong>:</li>
</ul>
<pre><code class="language-python">stream=True
</code></pre>
<h3 id="user">user</h3>
<ul>
<li><strong>설명</strong>: <code>user</code> 파라미터는 요청을 보낸 사용자의 식별자를 지정할 수 있는 필드이다. 이 정보는 사용자 맞춤형 로그 및 분석을 위해 사용될 수 있다.</li>
<li><strong>용도</strong>: 다중 사용자 환경에서 각 사용자의 요청을 식별하고, 사용자별로 응답을 최적화할 때 유용하다.</li>
<li><strong>예시</strong>:</li>
</ul>
<pre><code class="language-python">user=&quot;user-1234&quot;
</code></pre>
<h3 id="stream_1">stream과 비동기 처리</h3>
<p><code>stream=True</code> 옵션을 사용하면, 응답을 실시간으로 수신할 수 있다. 이때 비동기 처리 방식으로 API 호출을 관리하는 것이 중요하다. Python에서는 <code>asyncio</code> 모듈을 사용하여 비동기 API 호출을 쉽게 처리할 수 있다.</p>
<pre><code class="language-python">import openai
import asyncio

async def generate_response():
    response = await openai.ChatCompletion.acreate(
        model=&quot;gpt-4&quot;,
        messages=[
            {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;Tell me a story.&quot;}
        ],
        stream=True
    )

    async for chunk in response:
        print(chunk['choices'][0]['delta'].get('content', ''), end='')

asyncio.run(generate_response())
</code></pre>
<p>위 코드에서는 <code>stream=True</code>로 설정된 API 호출이 비동기적으로 처리되며, 응답이 부분적으로 전달될 때마다 출력된다.</p>
<h3 id="_1">다양한 파라미터의 조합</h3>
<p>이제까지 다룬 여러 파라미터들을 적절히 조합하여, 모델의 출력을 최적화할 수 있다. 예를 들어, <code>temperature</code>와 <code>top_p</code>를 함께 조정하거나, <code>frequency_penalty</code>와 <code>presence_penalty</code>를 결합하여 텍스트의 반복성과 다양성을 동시에 관리할 수 있다.</p>
<ul>
<li>예를 들어, 다음과 같은 설정을 사용해 볼 수 있다.</li>
</ul>
<pre><code class="language-python">response = openai.ChatCompletion.create(
    model=&quot;gpt-4&quot;,
    messages=[{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;Write a creative story.&quot;}],
    temperature=0.85,
    max_tokens=150,
    top_p=0.95,
    frequency_penalty=0.5,
    presence_penalty=0.6
)
</code></pre>
<p>이 조합은 창의적이고 다양한 이야기를 생성하지만, 동일한 표현의 반복을 줄이고 새로운 주제를 도입할 가능성을 높인다.</p>

  <br>
    

    
    
      
    

  <div class="row wm-article-nav-buttons" role="navigation" aria-label="navigation">
    
    <div class="wm-article-nav pull-right">
      <a href="../0305/" class="btn btn-xs btn-default pull-right">
        Next
        <i class="fa fa-chevron-right" aria-hidden="true"></i>
      </a>
      <a href="../0305/" class="btn btn-xs btn-link">
        응답 데이터 처리 및 파싱
      </a>
    </div>
    
    <div class="wm-article-nav">
      <a href="../0303/" class="btn btn-xs btn-default pull-left">
        <i class="fa fa-chevron-left" aria-hidden="true"></i>
        Previous</a><a href="../0303/" class="btn btn-xs btn-link">
        간단한 텍스트 생성 예제
      </a>
    </div>
    
  </div>

    <br>
</div>

<footer class="container-fluid wm-page-content">
  <p>Documentation built with <a href="https://www.mkdocs.org/">MkDocs</a> using <a href="https://github.com/gristlabs/mkdocs-windmill">Windmill</a> theme by Grist Labs.</p>
</footer>

</body>
</html>