<!DOCTYPE html>
<html lang="en">
<head>
  
  
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    
    
    <link rel="canonical" href="https://booiljung.github.io/artificial_intelligent/chatgpt_api/chapter_07/0703/">
    <link rel="shortcut icon" href="../../../../img/favicon.ico">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" />
    <title>캐싱을 활용한 성능 개선 - 실험 도서관</title>
    <link href="../../../../css/bootstrap-3.3.7.min.css" rel="stylesheet">
    <link href="../../../../css/font-awesome-4.7.0.css" rel="stylesheet">
    <link href="../../../../css/base.css" rel="stylesheet">
    <link rel="stylesheet" href="../../../../css/highlight.css">
    <link href="../../../../css/custom.css" rel="stylesheet">
    <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.3.0/respond.min.js"></script>
    <![endif]-->

    <script src="../../../../js/jquery-3.2.1.min.js"></script>
    <script src="../../../../js/bootstrap-3.3.7.min.js"></script>
    <script src="../../../../js/highlight.pack.js"></script>
    
    <base target="_top">
    <script>
      var base_url = '../../../..';
      var is_top_frame = false;
        
        var pageToc = [
          {title: "\uce90\uc2f1\uc758 \uae30\ubcf8 \uac1c\ub150", url: "#_top", children: [
              {title: "\uae30\ubcf8 \uce90\uc2f1 \uc6d0\ub9ac", url: "#_2" },
          ]},
          {title: "\uce90\uc2f1 \uc804\ub7b5", url: "#_3", children: [
              {title: "1. \ub2e8\uc21c \uce90\uc2f1(Simple Caching)", url: "#1-simple-caching" },
              {title: "2. TTL(Time To Live) \uae30\ubc18 \uce90\uc2f1", url: "#2-ttltime-to-live" },
              {title: "3. LRU(Least Recently Used) \uce90\uc2f1", url: "#3-lruleast-recently-used" },
          ]},
          {title: "\uce90\uc2dc\uc758 \uc800\uc7a5 \uc704\uce58", url: "#_4", children: [
              {title: "1. \uba54\ubaa8\ub9ac \uce90\uc2f1(In-Memory Caching)", url: "#1-in-memory-caching" },
              {title: "2. \ub514\uc2a4\ud06c \uce90\uc2f1(Disk Caching)", url: "#2-disk-caching" },
          ]},
          {title: "\uce90\uc2f1 \uc801\uc6a9 \uc2dc \uc8fc\uc758\uc0ac\ud56d", url: "#_5", children: [
              {title: "1. \ub370\uc774\ud130 \uc77c\uad00\uc131", url: "#1" },
              {title: "2. \uce90\uc2dc \ud06c\uae30 \uad00\ub9ac", url: "#2" },
              {title: "3. \uce90\uc2dc \ubbf8\uc2a4(Cache Miss)", url: "#3-cache-miss" },
          ]},
          {title: "\uce90\uc2f1 \uc801\uc6a9 \uc608\uc81c", url: "#_6", children: [
              {title: "Redis \uce90\uc2f1 \uc608\uc81c", url: "#redis" },
              {title: "\ucf54\ub4dc \uc124\uba85", url: "#_7" },
              {title: "\uc7a5\uc810\uacfc \ud55c\uacc4", url: "#_8" },
          ]},
          {title: "TTL \uc804\ub7b5\uc758 \uc801\uc6a9", url: "#ttl", children: [
              {title: "TTL\uacfc \ub370\uc774\ud130 \uc77c\uad00\uc131", url: "#ttl_1" },
          ]},
          {title: "\uce90\uc2f1 \ubbf8\uc2a4\uc640 \ud788\ud2b8\uc728 \uacc4\uc0b0", url: "#_9", children: [
          ]},
          {title: "\uce90\uc2dc \ubb34\ud6a8\ud654(Invalidation)", url: "#invalidation", children: [
          ]},
        ];

    </script>
    <script src="../../../../js/base.js"></script>
      <script src="../../../../js/google_analytics.js"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML"></script>
      <script src="https://www.googletagmanager.com/gtag/js?id=G-3F4LHCTF88"></script> 
</head>

<body>
<script>
if (is_top_frame) { $('body').addClass('wm-top-page'); }
</script>



<div class="container-fluid wm-page-content">
  <a name="_top"></a>
    

    
    
      
    

  <div class="row wm-article-nav-buttons" role="navigation" aria-label="navigation">
    
    <div class="wm-article-nav pull-right">
      <a href="../0704/" class="btn btn-xs btn-default pull-right">
        Next
        <i class="fa fa-chevron-right" aria-hidden="true"></i>
      </a>
      <a href="../0704/" class="btn btn-xs btn-link">
        프롬프트 최적화를 통한 성능 향상
      </a>
    </div>
    
    <div class="wm-article-nav">
      <a href="../0702/" class="btn btn-xs btn-default pull-left">
        <i class="fa fa-chevron-left" aria-hidden="true"></i>
        Previous</a><a href="../0702/" class="btn btn-xs btn-link">
        비용 효율적인 API 사용 전략
      </a>
    </div>
    
  </div>

    

    <p>ChatGPT API를 사용하는 애플리케이션의 성능을 최적화하는 중요한 방법 중 하나는 <strong>캐싱</strong>을 적절히 사용하는 것이다. 캐싱은 자주 반복되는 API 호출을 줄이고, 불필요한 네트워크 트래픽과 처리 시간을 최소화하여 성능을 크게 향상시킬 수 있다. 이 섹션에서는 캐싱의 기본 개념, 적용 방법, 다양한 캐싱 전략, 그리고 실전 예제에 대해 다룬다.</p>
<h3 id="_1">캐싱의 기본 개념</h3>
<p><strong>캐싱(Cache)</strong>은 데이터나 계산 결과를 임시로 저장해 두었다가 동일한 요청이 반복될 때 재사용하는 기술이다. 특히, ChatGPT API와 같은 외부 API를 사용할 때, 같은 프롬프트로 여러 번 호출을 하는 경우 API 응답 데이터를 캐싱해두면 매번 새로운 요청을 보내지 않아도 된다. 캐싱의 기본 목적은 <strong>응답 시간 단축</strong>과 <strong>비용 절감</strong>이다.</p>
<h4 id="_2">기본 캐싱 원리</h4>
<p>캐싱은 기본적으로 <strong>Key-Value</strong> 구조로 동작한다. API 요청을 보낼 때 요청 데이터를 키로 저장하고, API 응답을 값으로 저장한다. 이후 동일한 키로 요청이 들어오면 캐시에 저장된 값을 반환하여 API 호출을 대체한다.</p>
<p>$$</p>
<p>\text{Cache}( \mathbf{x} ) = 
\begin{cases} 
    \text{API 응답 데이터} &amp; \text{캐시에 존재할 때} \
    \text{API 호출 후 데이터 저장} &amp; \text{캐시에 없을 때} 
\end{cases}</p>
<p>$$</p>
<p>여기서 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{x}</span><script type="math/tex">\mathbf{x}</script></span>는 요청 데이터로, 프롬프트와 파라미터를 포함한다.</p>
<h3 id="_3">캐싱 전략</h3>
<p>캐싱 전략을 선택하는 것은 성능 최적화의 핵심이다. ChatGPT API를 사용할 때 적합한 몇 가지 캐싱 전략은 다음과 같다.</p>
<h4 id="1-simple-caching">1. <strong>단순 캐싱(Simple Caching)</strong></h4>
<p>가장 기본적인 캐싱 방법으로, API 요청과 응답의 매핑을 캐시 메모리에 저장한다. 이 방법은 동일한 프롬프트와 설정으로 여러 번 API 호출을 하는 경우에 유용하다. 다만, 응답이 변동되거나 동적 요청이 많은 경우에는 적합하지 않는다.</p>
<ul>
<li><strong>장점</strong>: 구현이 간단하고 빠름.</li>
<li><strong>단점</strong>: 동적 데이터에 적합하지 않음.</li>
</ul>
<h4 id="2-ttltime-to-live">2. <strong>TTL(Time To Live) 기반 캐싱</strong></h4>
<p>TTL(Time To Live)은 캐시 항목이 얼마 동안 유효한지를 정의한다. 특정 시간 동안 캐시된 데이터를 사용하고, 이후에는 새로운 요청을 보내어 캐시를 갱신한다. 예를 들어, 뉴스 헤드라인이나 실시간 데이터를 캐싱할 때 유용하다.</p>
<p>$$</p>
<p>\text{TTL}(\mathbf{x}) = t_{\text{현재 시간}} - t_{\text{저장 시간}}</p>
<p>$$</p>
<p>여기서 <span class="arithmatex"><span class="MathJax_Preview">t_{\text{현재 시간}}</span><script type="math/tex">t_{\text{현재 시간}}</script></span>은 현재 시간이고, <span class="arithmatex"><span class="MathJax_Preview">t_{\text{저장 시간}}</span><script type="math/tex">t_{\text{저장 시간}}</script></span>은 데이터가 캐시에 저장된 시간이다. <span class="arithmatex"><span class="MathJax_Preview">\text{TTL}(\mathbf{x})</span><script type="math/tex">\text{TTL}(\mathbf{x})</script></span>이 설정된 시간보다 크다면 캐시가 만료된 것으로 간주하고, API 호출을 통해 데이터를 갱신한다.</p>
<ul>
<li><strong>장점</strong>: 주기적으로 갱신이 필요한 데이터에 적합.</li>
<li><strong>단점</strong>: TTL이 너무 짧으면 캐시 효과가 감소하고, 너무 길면 오래된 데이터를 반환할 수 있음.</li>
</ul>
<h4 id="3-lruleast-recently-used">3. <strong>LRU(Least Recently Used) 캐싱</strong></h4>
<p>LRU 캐싱은 가장 오랫동안 사용되지 않은 캐시 항목을 제거하는 전략이다. 캐시 메모리가 한정적일 때 주로 사용되며, 캐시 공간을 효율적으로 관리하는 데 적합한다. 자주 호출되지 않는 데이터를 캐시에서 제거하여 중요한 데이터의 접근 속도를 유지할 수 있다.</p>
<p>$$</p>
<p>\text{Cache}<em>{\text{LRU}}( \mathbf{x} ) = \min</em>{\mathbf{x}<em>i \in \mathbf{C}} \left( t</em>{\text{사용 시간}}(\mathbf{x}_i) \right)</p>
<p>$$</p>
<p>여기서 <span class="arithmatex"><span class="MathJax_Preview">t_{\text{사용 시간}}(\mathbf{x}_i)</span><script type="math/tex">t_{\text{사용 시간}}(\mathbf{x}_i)</script></span>는 항목 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{x}_i</span><script type="math/tex">\mathbf{x}_i</script></span>가 마지막으로 사용된 시간을 나타낸다.</p>
<ul>
<li><strong>장점</strong>: 메모리 효율이 높고, 자주 사용되는 데이터를 우선적으로 보관.</li>
<li><strong>단점</strong>: LRU 알고리즘 구현에 추가적인 메모리와 계산 비용이 발생.</li>
</ul>
<h3 id="_4">캐시의 저장 위치</h3>
<p>캐시는 주로 메모리와 디스크에 저장된다. 각각의 방법은 장단점이 있으며, 사용 사례에 따라 선택해야 한다.</p>
<h4 id="1-in-memory-caching">1. <strong>메모리 캐싱(In-Memory Caching)</strong></h4>
<p>메모리 캐싱은 가장 빠른 캐싱 방법이다. 데이터를 RAM에 저장하기 때문에 매우 짧은 응답 시간을 보장한다. 그러나 메모리 용량이 제한적이며, 서버 재시작 시 캐시된 데이터가 사라지는 단점이 있다.</p>
<ul>
<li><strong>예시</strong>: <code>redis-py</code>, <code>memcached</code></li>
</ul>
<h4 id="2-disk-caching">2. <strong>디스크 캐싱(Disk Caching)</strong></h4>
<p>디스크 캐싱은 하드디스크 또는 SSD에 캐시 데이터를 저장한다. 메모리 캐싱보다 느리지만, 대량의 데이터를 장기간 저장할 수 있으며, 서버 재시작 후에도 데이터를 유지할 수 있다.</p>
<ul>
<li><strong>예시</strong>: 파일 시스템을 사용하는 <code>diskcache</code></li>
</ul>
<h3 id="_5">캐싱 적용 시 주의사항</h3>
<p>캐싱을 잘못 사용하면 성능 향상 대신 오히려 문제가 발생할 수 있다. 캐싱 적용 시 고려해야 할 중요한 요소는 다음과 같다.</p>
<h4 id="1">1. <strong>데이터 일관성</strong></h4>
<p>동적 또는 실시간 변화가 많은 데이터를 캐싱하면 오래된 데이터를 반환하여 일관성 문제가 발생할 수 있다. 이런 경우 TTL이나 조건부 갱신(conditional refreshing) 전략을 사용하여 데이터의 최신성을 보장해야 한다.</p>
<h4 id="2">2. <strong>캐시 크기 관리</strong></h4>
<p>캐시에 너무 많은 데이터를 저장하면 메모리 또는 디스크 용량이 부족해질 수 있다. LRU와 같은 전략을 사용하여 캐시 크기를 제한하거나, 캐시 항목에 크기 제한을 두어야 한다.</p>
<h4 id="3-cache-miss">3. <strong>캐시 미스(Cache Miss)</strong></h4>
<p>캐시 미스는 캐시에 요청한 데이터가 존재하지 않는 상황을 의미한다. 캐시 미스가 발생하면 API를 다시 호출해야 하므로, 캐시의 히트율을 최대화하는 것이 성능 향상의 핵심이다. 이를 위해 적절한 캐싱 전략과 파라미터 설정이 필요하다.</p>
<h3 id="_6">캐싱 적용 예제</h3>
<p>이제 캐싱을 적용한 간단한 Python 예제를 살펴보겠다. 여기서는 <code>redis</code>와 같은 메모리 기반 캐시 시스템을 사용하여 ChatGPT API 호출의 결과를 캐싱하는 방법을 설명한다.</p>
<h4 id="redis">Redis 캐싱 예제</h4>
<p>Redis는 메모리 기반의 고성능 데이터 저장소로, 간단한 캐시 시스템을 구축하는 데 자주 사용된다. 먼저, Python에서 <code>redis-py</code> 패키지를 사용하여 Redis와 연동한 캐시 시스템을 구현하는 방법을 보여드린다.</p>
<ol>
<li><strong>Redis 서버 설치 및 설정</strong>: 로컬에 Redis 서버를 설치한 후, 실행한다.</li>
<li><strong>Python에서 Redis 사용을 위한 설정</strong>: <code>redis-py</code> 패키지를 설치하고 Redis에 연결하는 코드를 작성한다.</li>
</ol>
<pre><code class="language-python">import openai
import redis
import hashlib
import json

cache = redis.StrictRedis(host='localhost', port=6379, db=0)

def get_chatgpt_response(prompt):
    # 캐시 키 생성 (프롬프트의 해시값을 사용)
    key = hashlib.sha256(prompt.encode('utf-8')).hexdigest()

    # 캐시에서 데이터 조회
    cached_response = cache.get(key)
    if cached_response:
        # 캐시에 데이터가 있으면 반환
        return json.loads(cached_response)

    # 캐시에 데이터가 없으면 API 호출
    response = openai.Completion.create(
        model=&quot;text-davinci-003&quot;,
        prompt=prompt,
        max_tokens=100
    )

    # 응답을 캐시에 저장 (TTL은 60초로 설정)
    cache.setex(key, 60, json.dumps(response))

    return response
</code></pre>
<h4 id="_7">코드 설명</h4>
<ol>
<li><strong>캐시 키 생성</strong>: 요청된 프롬프트의 해시값을 캐시의 키로 사용한다. 해시 알고리즘을 사용하는 이유는 프롬프트가 길어질 수 있기 때문에 이를 압축해 캐시에 효율적으로 저장하기 위함이다.</li>
</ol>
<p>$$</p>
<p>\text{Key}(\mathbf{prompt}) = \text{SHA256}(\mathbf{prompt})</p>
<p>$$</p>
<ol>
<li>
<p><strong>캐시 조회</strong>: Redis에 저장된 데이터를 조회하고, 캐시가 존재하면 해당 데이터를 반환한다.</p>
</li>
<li>
<p><strong>캐시 미스 시 API 호출</strong>: 캐시에 데이터가 없으면 ChatGPT API를 호출하여 응답을 받는다.</p>
</li>
<li>
<p><strong>캐시에 데이터 저장</strong>: API 응답을 캐시에 저장하며, TTL(Time To Live)을 60초로 설정해 일정 시간이 지나면 캐시가 자동으로 갱신되도록 한다.</p>
</li>
</ol>
<h4 id="_8">장점과 한계</h4>
<ul>
<li><strong>장점</strong>: 자주 호출되는 프롬프트에 대해 API 호출 수를 줄여 비용과 응답 시간을 줄일 수 있다.</li>
<li><strong>한계</strong>: 프롬프트가 동적으로 변하거나 자주 변경되는 경우 캐시의 효과가 크지 않을 수 있다. 또한, 캐시를 잘못 관리하면 오래된 데이터를 제공할 위험이 있다.</li>
</ul>
<h3 id="ttl">TTL 전략의 적용</h3>
<p>TTL 전략을 사용하여 캐시 데이터를 주기적으로 갱신할 수 있다. TTL은 캐시에 저장된 데이터가 얼마 동안 유효한지 정의하는 값이다. 예를 들어, 데이터가 자주 변동되는 경우 TTL을 짧게 설정하여 오래된 데이터가 반환되지 않도록 할 수 있다.</p>
<pre><code class="language-python">cache.setex(key, 300, json.dumps(response))
</code></pre>
<p>여기서, 캐시 항목의 TTL은 300초로 설정되었으며, 이 시간이 지나면 Redis는 해당 항목을 자동으로 제거한다. 이후 동일한 요청이 들어오면 새로운 API 호출을 통해 캐시를 갱신한다.</p>
<h4 id="ttl_1">TTL과 데이터 일관성</h4>
<p>TTL을 적절히 설정하는 것이 중요하다. 너무 짧으면 캐시의 장점이 사라지고, 너무 길면 오래된 데이터를 반환하여 데이터 일관성 문제가 발생할 수 있다. </p>
<p>$$</p>
<p>t_{\text{TTL}} \approx \frac{t_{\text{최신 데이터 필요 시간}}}{2}</p>
<p>$$</p>
<p>위 공식에서 <span class="arithmatex"><span class="MathJax_Preview">t_{\text{TTL}}</span><script type="math/tex">t_{\text{TTL}}</script></span>은 최신 데이터가 필요할 때까지의 시간을 반영하여 설정할 수 있다.</p>
<h3 id="_9">캐싱 미스와 히트율 계산</h3>
<p>캐시의 효과를 분석하기 위해 <strong>캐시 미스</strong>와 <strong>캐시 히트율</strong>을 계산할 수 있다. 캐시 히트율은 전체 요청 중 캐시에서 데이터를 반환한 비율을 나타낸다.</p>
<p>$$</p>
<p>\text{히트율} = \frac{\text{캐시 히트 수}}{\text{총 요청 수}} = \frac{H}{R}</p>
<p>$$</p>
<p>여기서:
- <span class="arithmatex"><span class="MathJax_Preview">H</span><script type="math/tex">H</script></span>는 캐시 히트 횟수
- <span class="arithmatex"><span class="MathJax_Preview">R</span><script type="math/tex">R</script></span>은 총 요청 횟수이다.</p>
<p>히트율이 높을수록 캐시가 효과적으로 동작하고 있다는 것을 의미하며, 미스율이 높다면 캐싱 전략을 조정하거나 캐시 크기, TTL 등을 최적화해야 한다.</p>
<h3 id="invalidation">캐시 무효화(Invalidation)</h3>
<p>캐시 무효화는 데이터가 오래되어 더 이상 유효하지 않을 때 캐시를 갱신하는 메커니즘이다. 특히, 동적 데이터나 자주 변경되는 데이터의 경우 캐시 무효화 전략을 잘 설계해야 한다.</p>
<p>캐시 무효화 방법은 다음과 같다.</p>
<ol>
<li>
<p><strong>수동 무효화</strong>: 특정 조건에 맞춰 프로그래밍적으로 캐시 항목을 제거하거나 갱신한다.</p>
</li>
<li>
<p><strong>TTL 기반 자동 무효화</strong>: TTL을 설정하여 일정 시간이 지나면 캐시 항목을 자동으로 제거한다.</p>
</li>
</ol>
<pre><code class="language-python">cache.delete(key)
</code></pre>
<p>이 방식은 사용자나 시스템이 명시적으로 캐시를 무효화할 때 사용된다.</p>
<hr />
<p>캐싱을 활용한 성능 개선은 ChatGPT API의 응답 속도를 향상시키고, 비용을 절감하는 매우 효과적인 방법이다. 캐싱 전략, 캐시 저장소, TTL 관리, 캐시 미스와 히트율 분석 등의 요소를 잘 고려하면 최적의 성능을 얻을 수 있다. 캐시를 적용할 때는 데이터의 일관성을 유지하고, 캐시 크기와 TTL을 적절히 설정하여 효율적으로 운영하는 것이 중요하다.</p>

  <br>
    

    
    
      
    

  <div class="row wm-article-nav-buttons" role="navigation" aria-label="navigation">
    
    <div class="wm-article-nav pull-right">
      <a href="../0704/" class="btn btn-xs btn-default pull-right">
        Next
        <i class="fa fa-chevron-right" aria-hidden="true"></i>
      </a>
      <a href="../0704/" class="btn btn-xs btn-link">
        프롬프트 최적화를 통한 성능 향상
      </a>
    </div>
    
    <div class="wm-article-nav">
      <a href="../0702/" class="btn btn-xs btn-default pull-left">
        <i class="fa fa-chevron-left" aria-hidden="true"></i>
        Previous</a><a href="../0702/" class="btn btn-xs btn-link">
        비용 효율적인 API 사용 전략
      </a>
    </div>
    
  </div>

    <br>
</div>

<footer class="container-fluid wm-page-content">
  <p>Documentation built with <a href="https://www.mkdocs.org/">MkDocs</a> using <a href="https://github.com/gristlabs/mkdocs-windmill">Windmill</a> theme by Grist Labs.</p>
</footer>

</body>
</html>