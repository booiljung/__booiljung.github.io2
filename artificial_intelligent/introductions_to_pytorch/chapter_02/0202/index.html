<!DOCTYPE html>
<html lang="en">
<head>
  
  
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    
    
    <link rel="canonical" href="https://booiljung.github.io/artificial_intelligent/introductions_to_pytorch/chapter_02/0202/">
    <link rel="shortcut icon" href="../../../../img/favicon.ico">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" />
    <title>Tensor의 데이터 타입과 변환 - 소프트웨어 융합</title>
    <link href="../../../../css/bootstrap-3.3.7.min.css" rel="stylesheet">
    <link href="../../../../css/font-awesome-4.7.0.css" rel="stylesheet">
    <link href="../../../../css/base.css" rel="stylesheet">
    <link rel="stylesheet" href="../../../../css/highlight.css">
    <link href="../../../../css/custom.css" rel="stylesheet">
    <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.3.0/respond.min.js"></script>
    <![endif]-->

    <script src="../../../../js/jquery-3.2.1.min.js"></script>
    <script src="../../../../js/bootstrap-3.3.7.min.js"></script>
    <script src="../../../../js/highlight.pack.js"></script>
    
    <base target="_top">
    <script>
      var base_url = '../../../..';
      var is_top_frame = false;
        
        var pageToc = [
          {title: "Tensor\uc758 \ub370\uc774\ud130 \ud0c0\uc785\uacfc \ubcc0\ud658", url: "#_top", children: [
              {title: "\ub370\uc774\ud130 \ud0c0\uc785 \uac1c\uc694", url: "#_1" },
              {title: "\ub370\uc774\ud130 \ud0c0\uc785 \uc9c0\uc815 \ubc0f \ubcc0\uacbd", url: "#_2" },
              {title: "\ub2e4\uc591\ud55c \ub370\uc774\ud130 \ud0c0\uc785\uc758 \uc5f0\uc0b0", url: "#_4" },
              {title: "\ub370\uc774\ud130 \ud0c0\uc785 \ubcc0\ud658\uc758 \uc608\uc2dc\uc640 \uace0\ub824 \uc0ac\ud56d", url: "#_5" },
              {title: "\ud2b9\uc815 \ub370\uc774\ud130 \ud0c0\uc785 \uac04\uc758 \ubcc0\ud658", url: "#_7" },
              {title: "\ud150\uc11c \uc7a5\uce58 \ubcc0\ud658\uacfc \ub370\uc774\ud130 \ud0c0\uc785 \ubcc0\ud658\uc758 \uacb0\ud569", url: "#_11" },
              {title: "astype() \ud568\uc218\uc758 \ub300\uc548\uc73c\ub85c .type()\uacfc .to()", url: "#astype-type-to" },
              {title: "\ub370\uc774\ud130 \ud0c0\uc785 \ubcc0\ud658\uc758 \uc2e4\uc804 \uc608\uc81c", url: "#_12" },
          ]},
        ];

    </script>
    <script src="../../../../js/base.js"></script>
      <script src="../../../../js/google_analytics.js"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML"></script>
      <script src="https://www.googletagmanager.com/gtag/js?id=G-3F4LHCTF88"></script> 
</head>

<body>
<script>
if (is_top_frame) { $('body').addClass('wm-top-page'); }
</script>



<div class="container-fluid wm-page-content">
  <a name="_top"></a>
    

    

    <h1 id="tensor">Tensor의 데이터 타입과 변환</h1>
<h3 id="_1">데이터 타입 개요</h3>
<p>PyTorch에서 텐서(Tensor)는 다양한 데이터 타입을 지원합니다. 각 데이터 타입은 저장되는 데이터의 종류와 연산의 정확성에 영향을 미치며, 따라서 사용 목적에 맞는 적절한 데이터 타입을 선택하는 것이 중요합니다. PyTorch의 텐서는 <code>torch.Tensor</code> 클래스를 기반으로 하며, 기본적으로 <code>float32</code> (32-bit 부동소수점) 타입을 사용합니다. 그러나 다른 데이터 타입도 지원하며, 주로 사용하는 데이터 타입은 다음과 같습니다.</p>
<table>
<thead>
<tr>
<th>데이터 타입</th>
<th>설명</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>torch.float32</code></td>
<td>32-bit 부동소수점 (기본값)</td>
</tr>
<tr>
<td><code>torch.float64</code></td>
<td>64-bit 부동소수점 (더 높은 정밀도)</td>
</tr>
<tr>
<td><code>torch.float16</code></td>
<td>16-bit 부동소수점 (적은 메모리, 빠른 연산)</td>
</tr>
<tr>
<td><code>torch.int64</code></td>
<td>64-bit 정수 (일반적인 정수 연산에 사용)</td>
</tr>
<tr>
<td><code>torch.int32</code></td>
<td>32-bit 정수</td>
</tr>
<tr>
<td><code>torch.uint8</code></td>
<td>8-bit 부호 없는 정수 (이미지 처리 등)</td>
</tr>
<tr>
<td><code>torch.bool</code></td>
<td>Boolean 값 (<code>True</code> 또는 <code>False</code>)</td>
</tr>
</tbody>
</table>
<h3 id="_2">데이터 타입 지정 및 변경</h3>
<h4 id="_3">텐서 생성 시 데이터 타입 지정</h4>
<p>텐서를 생성할 때 특정 데이터 타입을 지정할 수 있습니다. 예를 들어, <code>torch.float64</code> 타입의 텐서를 생성하려면 <code>dtype</code> 인자를 사용합니다.</p>
<pre><code class="language-python">import torch

# float64 타입의 텐서 생성
tensor_a = torch.tensor([1.0, 2.0, 3.0], dtype=torch.float64)
print(tensor_a.dtype)  # 출력: torch.float64
</code></pre>
<h4 id="type-casting">데이터 타입 변환 (Type Casting)</h4>
<p>이미 생성된 텐서의 데이터 타입을 변경하려면 <code>.type()</code> 또는 <code>.to()</code> 메서드를 사용할 수 있습니다. 예를 들어, <code>float32</code> 타입의 텐서를 <code>int32</code> 타입으로 변환하려면 다음과 같이 합니다.</p>
<pre><code class="language-python">tensor_b = torch.tensor([1.5, 2.8, 3.2])
tensor_b_int = tensor_b.type(torch.int32)
print(tensor_b_int)  # 출력: tensor([1, 2, 3], dtype=torch.int32)
</code></pre>
<p><code>.to()</code> 메서드는 텐서의 데이터 타입을 변환하는 데도 사용될 수 있으며, GPU나 CPU로의 장치 이동도 동시에 처리할 수 있는 장점이 있습니다.</p>
<pre><code class="language-python">tensor_c = tensor_b.to(torch.float16)
print(tensor_c.dtype)  # 출력: torch.float16
</code></pre>
<h3 id="_4">다양한 데이터 타입의 연산</h3>
<p>PyTorch는 서로 다른 데이터 타입을 가진 텐서 간의 연산에 제약을 둡니다. 예를 들어, <code>float32</code> 텐서와 <code>int32</code> 텐서를 직접 연산하려고 하면 오류가 발생합니다. 따라서 연산을 수행하기 전에 데이터 타입을 맞추는 것이 필요합니다. 다음과 같은 예를 통해 확인할 수 있습니다.</p>
<pre><code class="language-python">tensor_d = torch.tensor([1.0, 2.0, 3.0], dtype=torch.float32)
tensor_e = torch.tensor([1, 2, 3], dtype=torch.int32)

try:
    result = tensor_d + tensor_e
except RuntimeError as e:
    print(e)
</code></pre>
<p>위의 코드에서는 <code>RuntimeError</code>가 발생하며, 텐서 간의 타입을 맞추기 위해 <code>tensor_e</code>를 <code>float32</code>로 변환하거나 <code>tensor_d</code>를 <code>int32</code>로 변환해야 합니다.</p>
<pre><code class="language-python"># 데이터 타입 맞추기
tensor_e_float = tensor_e.to(torch.float32)
result = tensor_d + tensor_e_float
print(result)  # 정상 작동
</code></pre>
<h3 id="_5">데이터 타입 변환의 예시와 고려 사항</h3>
<h4 id="_6">정밀도와 메모리 효율성</h4>
<p>텐서의 데이터 타입은 메모리 사용량과 계산 정밀도에 직접적인 영향을 미칩니다. 예를 들어, <code>float64</code>는 <code>float32</code>보다 두 배의 메모리를 사용하지만, 더 높은 정밀도를 제공합니다. 다음과 같은 연산에서 이러한 차이를 확인할 수 있습니다.</p>
<p>수식으로 표현하면, 다음과 같은 벡터 연산을 고려해볼 수 있습니다.</p>
<div class="arithmatex">
<div class="MathJax_Preview">
\mathbf{v} = \begin{bmatrix} 1.1234567 \\ 2.1234567 \\ 3.1234567 \end{bmatrix}, \quad \mathbf{w} = \mathbf{v} + \mathbf{v}
</div>
<script type="math/tex; mode=display">
\mathbf{v} = \begin{bmatrix} 1.1234567 \\ 2.1234567 \\ 3.1234567 \end{bmatrix}, \quad \mathbf{w} = \mathbf{v} + \mathbf{v}
</script>
</div>
<p>위의 벡터 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{v}</span><script type="math/tex">\mathbf{v}</script></span>를 각각 <code>float32</code>와 <code>float64</code>로 처리했을 때 결과의 정밀도가 다를 수 있습니다. 정밀도가 필요한 연산을 할 때는 <code>float64</code>를 선택하는 것이 좋지만, 일반적인 딥러닝 연산에서는 <code>float32</code>가 더 일반적입니다.</p>
<h3 id="_7">특정 데이터 타입 간의 변환</h3>
<h4 id="_8">부동소수점 변환</h4>
<p>부동소수점 간의 변환은 정밀도와 범위에 주의해야 합니다. 예를 들어, <code>float64</code>에서 <code>float32</code>로 변환할 때는 정밀도가 감소할 수 있으며, 일부 값은 반올림될 수 있습니다.</p>
<pre><code class="language-python">tensor_f = torch.tensor([1.123456789], dtype=torch.float64)
tensor_g = tensor_f.to(torch.float32)
print(tensor_f)  # 출력: tensor([1.123456789], dtype=torch.float64)
print(tensor_g)  # 출력: tensor([1.1234568], dtype=torch.float32)
</code></pre>
<p>위 코드에서 <code>float64</code> 값이 <code>float32</code>로 변환되면서 정밀도가 손실된 것을 볼 수 있습니다. 이처럼 부동소수점의 정밀도 차이를 알고 있어야 합니다.</p>
<h4 id="_9">정수 데이터 타입 간 변환</h4>
<p>정수 타입 간의 변환에서도 유사한 문제가 발생할 수 있습니다. 특히, 더 작은 크기의 정수 타입으로 변환할 때는 값의 범위를 초과하면 오류가 발생하거나 값이 왜곡될 수 있습니다. 예를 들어, <code>int64</code>에서 <code>int32</code>로 변환할 때 데이터 손실의 위험이 존재합니다.</p>
<pre><code class="language-python">tensor_h = torch.tensor([2147483647], dtype=torch.int64)  # 32-bit 정수의 최대값
tensor_i = tensor_h.to(torch.int32)
print(tensor_i)  # 출력: tensor([2147483647], dtype=torch.int32)

tensor_j = torch.tensor([2147483648], dtype=torch.int64)  # 32-bit 정수의 범위 초과
try:
    tensor_k = tensor_j.to(torch.int32)
except RuntimeError as e:
    print(e)
</code></pre>
<p>위 코드에서는 <code>tensor_j</code>를 <code>int32</code>로 변환할 수 없습니다. 이는 <code>int32</code>의 표현 범위를 초과했기 때문입니다. 변환을 시도하면 오류가 발생합니다.</p>
<h4 id="_10">부호 있는 정수와 부호 없는 정수</h4>
<p>부호 있는 정수(<code>int32</code>, <code>int64</code>)와 부호 없는 정수(<code>uint8</code>) 간의 변환 시에도 주의가 필요합니다. 특히, 음수를 부호 없는 정수로 변환할 때는 값이 왜곡될 수 있습니다.</p>
<pre><code class="language-python">tensor_l = torch.tensor([-1], dtype=torch.int32)
tensor_m = tensor_l.to(torch.uint8)
print(tensor_m)  # 출력: tensor([255], dtype=torch.uint8)
</code></pre>
<p>위 예시에서 <code>-1</code>이 <code>uint8</code>로 변환되면서 255로 변경된 것을 볼 수 있습니다. 이는 2의 보수 표현에 따른 변환 결과로, 부호 없는 정수로 음수를 변환할 때는 이러한 왜곡이 발생할 수 있음을 주의해야 합니다.</p>
<h3 id="_11">텐서 장치 변환과 데이터 타입 변환의 결합</h3>
<h4 id="to"><code>.to()</code> 메서드를 활용한 변환</h4>
<p>PyTorch의 <code>.to()</code> 메서드는 텐서의 장치(CPU/GPU)와 데이터 타입을 동시에 변경할 수 있는 강력한 기능을 제공합니다. 예를 들어, CPU에서 <code>float32</code> 타입의 텐서를 GPU에서 <code>float16</code> 타입으로 변환할 수 있습니다.</p>
<pre><code class="language-python">device = torch.device(&quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;)

# float32 텐서를 생성하고, float16 타입으로 변환하여 GPU로 전송
tensor_n = torch.tensor([1.0, 2.0, 3.0], dtype=torch.float32)
tensor_o = tensor_n.to(torch.float16).to(device)
print(tensor_o.dtype)  # 출력: torch.float16
print(tensor_o.device)  # 출력: cuda:0 (또는 cpu)
</code></pre>
<p>위 코드에서 <code>.to()</code> 메서드는 데이터 타입 변환과 장치 이동을 동시에 수행합니다. 이는 복잡한 연산에서 코드의 가독성을 높이고, 효율적으로 연산을 관리할 수 있게 해줍니다.</p>
<h3 id="astype-type-to"><code>astype()</code> 함수의 대안으로 <code>.type()</code>과 <code>.to()</code></h3>
<p>다른 프로그래밍 언어(예: NumPy)에서는 데이터 타입을 변경할 때 <code>astype()</code> 함수를 사용하는 것이 일반적입니다. PyTorch에서는 <code>.type()</code>이나 <code>.to()</code>를 사용하여 같은 기능을 수행합니다. <code>astype()</code>와의 차이점은 <code>.to()</code>가 장치 이동까지 포함한다는 점입니다. </p>
<p>수학적으로 이러한 변환을 생각할 때, 텐서 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{T}</span><script type="math/tex">\mathbf{T}</script></span>가 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{T}_{\text{float32}}</span><script type="math/tex">\mathbf{T}_{\text{float32}}</script></span>로 변환된다면:</p>
<div class="arithmatex">
<div class="MathJax_Preview">
\mathbf{T}_{\text{float32}} = \text{cast}(\mathbf{T}, \text{float32})
</div>
<script type="math/tex; mode=display">
\mathbf{T}_{\text{float32}} = \text{cast}(\mathbf{T}, \text{float32})
</script>
</div>
<p>과 같이 표현할 수 있습니다. PyTorch에서는 이를 다음과 같이 처리할 수 있습니다.</p>
<pre><code class="language-python">tensor_p = tensor_n.to(torch.float32)
</code></pre>
<h3 id="_12">데이터 타입 변환의 실전 예제</h3>
<h4 id="1">예제 1: 이미지를 모델에 입력하기 전 변환하기</h4>
<p>이미지 데이터를 처리할 때, 일반적으로 <code>uint8</code> 타입의 데이터를 부동소수점으로 변환하여 모델에 입력합니다. 이는 신경망이 주로 <code>float32</code> 타입의 데이터를 사용하기 때문입니다. 이미지의 각 픽셀 값이 0부터 255 사이의 <code>uint8</code>로 주어지면, 이를 0부터 1 사이의 <code>float32</code>로 변환합니다.</p>
<pre><code class="language-python"># 예제: uint8 -&gt; float32 변환
image_tensor = torch.randint(0, 256, (3, 224, 224), dtype=torch.uint8)  # 예제 이미지
image_tensor = image_tensor.float() / 255.0  # 0-1 범위로 변환
print(image_tensor.dtype)  # 출력: torch.float32
</code></pre>
<h4 id="2-float16">예제 2: 계산 효율성을 위한 <code>float16</code> 활용</h4>
<p>딥러닝 모델의 학습에서는 <code>float16</code> 데이터 타입을 사용하여 메모리 사용량을 줄이고 연산 속도를 높이는 "혼합 정밀도 학습" 기법이 자주 사용됩니다. 이를 통해 GPU 메모리를 효율적으로 활용하고, 계산 시간을 단축할 수 있습니다.</p>
<pre><code class="language-python"># 모델의 입력을 float16으로 변환하여 계산 효율성을 증가
input_tensor = torch.randn(128, 3, 32, 32).to(torch.float16).to(device)
model_output = model(input_tensor)
</code></pre>
<p>위 코드에서는 입력 데이터를 <code>float16</code>으로 변환하여 모델에 입력함으로써 학습 속도를 개선할 수 있습니다.</p>

  <br>
    

    <br>
</div>

<footer class="container-fluid wm-page-content">
  <p>Documentation built with <a href="https://www.mkdocs.org/">MkDocs</a> using <a href="https://github.com/gristlabs/mkdocs-windmill">Windmill</a> theme by Grist Labs.</p>
</footer>

</body>
</html>