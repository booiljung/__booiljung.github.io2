<!DOCTYPE html>
<html lang="en">
<head>
  
  
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    
    
    <link rel="canonical" href="https://booiljung.github.io/artificial_intelligent/introductions_to_pytorch/chapter_02/0201/">
    <link rel="shortcut icon" href="../../../../img/favicon.ico">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" />
    <title>Tensor의 생성과 초기화 - 소프트웨어 융합</title>
    <link href="../../../../css/bootstrap-3.3.7.min.css" rel="stylesheet">
    <link href="../../../../css/font-awesome-4.7.0.css" rel="stylesheet">
    <link href="../../../../css/base.css" rel="stylesheet">
    <link rel="stylesheet" href="../../../../css/highlight.css">
    <link href="../../../../css/custom.css" rel="stylesheet">
    <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.3.0/respond.min.js"></script>
    <![endif]-->

    <script src="../../../../js/jquery-3.2.1.min.js"></script>
    <script src="../../../../js/bootstrap-3.3.7.min.js"></script>
    <script src="../../../../js/highlight.pack.js"></script>
    
    <base target="_top">
    <script>
      var base_url = '../../../..';
      var is_top_frame = false;
        
        var pageToc = [
          {title: "Tensor\uc758 \uc0dd\uc131\uacfc \ucd08\uae30\ud654", url: "#_top", children: [
              {title: "Tensor \uc0dd\uc131 \ubc29\ubc95", url: "#tensor_1" },
              {title: "\ucd08\uae30\ud654 \uc635\uc158\uacfc \ub370\uc774\ud130 \ud0c0\uc785", url: "#_1" },
              {title: "Tensor\uc758 \ud615\ud0dc\uc640 \ud06c\uae30 \uc9c0\uc815", url: "#tensor_2" },
              {title: "Tensor\uc758 \ud615\ud0dc \ubcc0\ud658", url: "#tensor_3" },
              {title: "\ucd08\uae30\ud654 \uc804\ub7b5", url: "#_2" },
              {title: "\ub2e4\uc591\ud55c \ud615\ud0dc\uc758 Tensor", url: "#tensor_4" },
              {title: "Tensor\uc758 \ucd08\uae30\ud654 \uc2e4\uc2b5", url: "#tensor_5" },
          ]},
        ];

    </script>
    <script src="../../../../js/base.js"></script>
      <script src="../../../../js/google_analytics.js"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML"></script>
      <script src="https://www.googletagmanager.com/gtag/js?id=G-3F4LHCTF88"></script> 
</head>

<body>
<script>
if (is_top_frame) { $('body').addClass('wm-top-page'); }
</script>



<div class="container-fluid wm-page-content">
  <a name="_top"></a>
    

    

    <h1 id="tensor">Tensor의 생성과 초기화</h1>
<p>PyTorch에서 Tensor는 다차원 배열을 나타내며, 이를 통해 다양한 수치 연산을 수행할 수 있습니다. Tensor는 다양한 방법으로 생성하고 초기화할 수 있으며, 그 형태와 데이터 타입은 사용자가 원하는 대로 설정할 수 있습니다. 이 장에서는 Tensor를 생성하고 초기화하는 여러 가지 방법을 다룹니다.</p>
<h3 id="tensor_1">Tensor 생성 방법</h3>
<h4 id="1">1. 기본 생성자 함수</h4>
<p>PyTorch에서는 <code>torch.Tensor()</code>를 이용해 Tensor를 생성할 수 있습니다. 이 생성자는 주어진 데이터로부터 Tensor를 생성합니다. 예를 들어, 다음과 같이 Python 리스트로부터 Tensor를 생성할 수 있습니다.</p>
<pre><code class="language-python">import torch

# 1차원 Tensor 생성
tensor1 = torch.Tensor([1, 2, 3, 4, 5])

# 2차원 Tensor 생성
tensor2 = torch.Tensor([[1, 2, 3], [4, 5, 6]])
</code></pre>
<p>위의 코드에서 <code>tensor1</code>은 1차원 Tensor이고, <code>tensor2</code>는 2차원 Tensor입니다. <code>torch.Tensor()</code>는 입력 데이터를 그대로 복사하여 새로운 Tensor를 생성하므로, 원본 데이터가 변경되어도 Tensor에는 영향을 주지 않습니다.</p>
<h4 id="2-numpy">2. Numpy 배열로부터 생성</h4>
<p>Numpy 배열을 PyTorch Tensor로 변환하려면 <code>torch.from_numpy()</code> 함수를 사용합니다. 이 함수는 Numpy 배열을 공유 메모리 방식으로 변환하므로, Numpy 배열과 Tensor 간의 데이터 변경이 서로 영향을 미칩니다.</p>
<pre><code class="language-python">import numpy as np

# Numpy 배열 생성
np_array = np.array([1.0, 2.0, 3.0])

# Tensor로 변환
tensor_from_numpy = torch.from_numpy(np_array)
</code></pre>
<p>위의 예제에서 Numpy 배열 <code>np_array</code>와 Tensor <code>tensor_from_numpy</code>는 메모리를 공유하므로, <code>np_array</code>의 값을 변경하면 <code>tensor_from_numpy</code>의 값도 변경됩니다.</p>
<h4 id="3-tensor">3. 특정 값으로 초기화된 Tensor 생성</h4>
<p>PyTorch에서는 특정 값으로 초기화된 Tensor를 생성할 수 있는 다양한 함수들이 제공됩니다. 주로 사용되는 함수는 다음과 같습니다.</p>
<ul>
<li><code>torch.zeros()</code>: 모든 요소가 0인 Tensor 생성</li>
<li><code>torch.ones()</code>: 모든 요소가 1인 Tensor 생성</li>
<li><code>torch.full()</code>: 사용자가 지정한 값으로 모든 요소가 채워진 Tensor 생성</li>
</ul>
<p>예를 들어, 다음 코드는 모두 크기가 <span class="arithmatex"><span class="MathJax_Preview">3 \times 3</span><script type="math/tex">3 \times 3</script></span>인 Tensor를 생성하지만, 초기화 방법이 다릅니다.</p>
<pre><code class="language-python"># 모든 요소가 0인 3x3 Tensor
zero_tensor = torch.zeros(3, 3)

# 모든 요소가 1인 3x3 Tensor
one_tensor = torch.ones(3, 3)

# 모든 요소가 7인 3x3 Tensor
full_tensor = torch.full((3, 3), 7)
</code></pre>
<h4 id="4-tensor">4. 랜덤 값으로 초기화된 Tensor 생성</h4>
<p>모델 학습 초기 단계에서 랜덤 값으로 Tensor를 초기화하는 것은 일반적인 방법입니다. PyTorch는 다음과 같은 랜덤 초기화 함수들을 제공합니다.</p>
<ul>
<li><code>torch.randn()</code>: 평균이 0이고 분산이 1인 정규분포에서 샘플링된 값을 가지는 Tensor 생성</li>
<li><code>torch.rand()</code>: <span class="arithmatex"><span class="MathJax_Preview">[0, 1)</span><script type="math/tex">[0, 1)</script></span> 범위에서 균등분포로 샘플링된 값을 가지는 Tensor 생성</li>
<li><code>torch.randint()</code>: 지정된 범위 내의 정수 값으로 구성된 Tensor 생성</li>
</ul>
<pre><code class="language-python"># 정규분포에서 샘플링된 값으로 초기화된 Tensor
randn_tensor = torch.randn(3, 3)

# 균등분포에서 샘플링된 값으로 초기화된 Tensor
rand_tensor = torch.rand(3, 3)

# 범위 내의 정수 값으로 초기화된 Tensor
randint_tensor = torch.randint(0, 10, (3, 3))
</code></pre>
<p>이와 같이 랜덤 값으로 초기화된 Tensor는 주로 딥러닝 모델의 가중치를 초기화할 때 사용됩니다.</p>
<h3 id="_1">초기화 옵션과 데이터 타입</h3>
<h4 id="1_1">1. 데이터 타입 지정</h4>
<p>PyTorch에서 생성된 Tensor의 데이터 타입은 기본적으로 <code>float32</code>입니다. 다른 데이터 타입을 사용하려면 <code>dtype</code> 인자를 명시적으로 지정해야 합니다. 예를 들어, <code>int64</code> 타입의 Tensor를 생성하려면 다음과 같이 할 수 있습니다.</p>
<pre><code class="language-python"># int64 타입의 Tensor 생성
int_tensor = torch.zeros(3, 3, dtype=torch.int64)
</code></pre>
<p>데이터 타입을 명시적으로 지정하는 것은 메모리 사용량을 줄이거나 계산 속도를 개선하는 데 유용할 수 있습니다. 또한, 딥러닝 모델에서 입력 데이터와 가중치의 데이터 타입이 일치해야 하므로, 이를 조정하는 데도 중요합니다.</p>
<h4 id="2">2. 장치 옵션</h4>
<p>PyTorch는 Tensor를 CPU와 GPU 모두에서 생성할 수 있습니다. GPU를 활용하여 연산 속도를 개선하려면 <code>device</code> 옵션을 지정해야 합니다. </p>
<pre><code class="language-python"># GPU가 사용 가능한 경우, GPU 장치에 Tensor 생성
device = torch.device(&quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;)
tensor_on_gpu = torch.ones(3, 3, device=device)
</code></pre>
<p>위의 코드에서는 GPU가 사용 가능한 경우 GPU에, 그렇지 않으면 CPU에 Tensor를 생성합니다. </p>
<h3 id="tensor_2">Tensor의 형태와 크기 지정</h3>
<p>Tensor를 생성할 때는 그 형태(shape)를 지정할 수 있습니다. 형태는 Tensor의 각 차원의 크기를 의미하며, 일반적으로 다음과 같은 함수들을 통해 원하는 크기의 Tensor를 쉽게 생성할 수 있습니다.</p>
<h4 id="1-torchempty">1. <code>torch.empty()</code></h4>
<p><code>torch.empty()</code>는 초기화되지 않은 Tensor를 생성합니다. 초기화되지 않았다는 것은 메모리의 임의의 값을 그대로 가지고 있기 때문에, 특정 값으로 채워져 있지 않음을 의미합니다. 이는 단순히 메모리를 할당하고 초기화 과정을 생략함으로써 속도를 개선할 수 있습니다.</p>
<pre><code class="language-python"># 초기화되지 않은 3x3 Tensor 생성
empty_tensor = torch.empty(3, 3)
</code></pre>
<h4 id="2-torcheye">2. <code>torch.eye()</code></h4>
<p>단위 행렬(identity matrix)을 생성하는 함수입니다. 단위 행렬은 대각선 성분이 1이고 나머지 성분이 0인 정사각 행렬입니다.</p>
<div class="arithmatex">
<div class="MathJax_Preview">
\mathbf{I}_n = \begin{bmatrix} 1 &amp; 0 &amp; \cdots &amp; 0 \\ 0 &amp; 1 &amp; \cdots &amp; 0 \\ \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\ 0 &amp; 0 &amp; \cdots &amp; 1 \end{bmatrix}
</div>
<script type="math/tex; mode=display">
\mathbf{I}_n = \begin{bmatrix} 1 & 0 & \cdots & 0 \\ 0 & 1 & \cdots & 0 \\ \vdots & \vdots & \ddots & \vdots \\ 0 & 0 & \cdots & 1 \end{bmatrix}
</script>
</div>
<p>다음 코드는 크기가 <span class="arithmatex"><span class="MathJax_Preview">4 \times 4</span><script type="math/tex">4 \times 4</script></span>인 단위 행렬을 생성합니다.</p>
<pre><code class="language-python"># 4x4 단위 행렬 생성
identity_tensor = torch.eye(4)
</code></pre>
<h4 id="3-torcharange-torchlinspace">3. <code>torch.arange()</code>와 <code>torch.linspace()</code></h4>
<p>특정 간격으로 값을 채운 1차원 Tensor를 생성할 때 사용되는 함수들입니다.</p>
<ul>
<li><code>torch.arange(start, end, step)</code>: 지정한 간격(<code>step</code>)으로 값을 생성합니다.</li>
<li><code>torch.linspace(start, end, steps)</code>: 시작과 끝 값을 포함하여 일정한 간격으로 값을 생성합니다.</li>
</ul>
<pre><code class="language-python"># 0에서 10까지 2씩 증가하는 값으로 채워진 Tensor
arange_tensor = torch.arange(0, 10, 2)

# 0에서 1까지 5개의 값을 선형 간격으로 채운 Tensor
linspace_tensor = torch.linspace(0, 1, 5)
</code></pre>
<p><code>torch.arange()</code>는 주로 정수 배열을 생성할 때 사용되며, <code>torch.linspace()</code>는 두 지점 사이를 일정한 간격으로 나눌 때 유용합니다.</p>
<h3 id="tensor_3">Tensor의 형태 변환</h3>
<p>생성된 Tensor의 형태를 변경해야 하는 경우가 자주 발생합니다. PyTorch에서는 Tensor의 차원을 재배열하거나 변경할 수 있는 다양한 방법을 제공합니다.</p>
<h4 id="1-torchreshape">1. <code>torch.reshape()</code></h4>
<p><code>reshape()</code> 함수는 Tensor의 원소 수를 유지한 채로 새로운 형태를 지정할 수 있게 해줍니다. 예를 들어, <span class="arithmatex"><span class="MathJax_Preview">1 \times 12</span><script type="math/tex">1 \times 12</script></span> 형태의 Tensor를 <span class="arithmatex"><span class="MathJax_Preview">3 \times 4</span><script type="math/tex">3 \times 4</script></span>로 변환할 수 있습니다.</p>
<div class="arithmatex">
<div class="MathJax_Preview">
\mathbf{t} = \begin{bmatrix} 1 &amp; 2 &amp; 3 &amp; 4 &amp; 5 &amp; 6 &amp; 7 &amp; 8 &amp; 9 &amp; 10 &amp; 11 &amp; 12 \end{bmatrix} \rightarrow \mathbf{T} = \begin{bmatrix} 1 &amp; 2 &amp; 3 &amp; 4 \\ 5 &amp; 6 &amp; 7 &amp; 8 \\ 9 &amp; 10 &amp; 11 &amp; 12 \end{bmatrix}
</div>
<script type="math/tex; mode=display">
\mathbf{t} = \begin{bmatrix} 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10 & 11 & 12 \end{bmatrix} \rightarrow \mathbf{T} = \begin{bmatrix} 1 & 2 & 3 & 4 \\ 5 & 6 & 7 & 8 \\ 9 & 10 & 11 & 12 \end{bmatrix}
</script>
</div>
<pre><code class="language-python"># 1x12 Tensor 생성
original_tensor = torch.arange(1, 13)

# 3x4 형태로 재구성
reshaped_tensor = original_tensor.reshape(3, 4)
</code></pre>
<h4 id="2-torchview">2. <code>torch.view()</code></h4>
<p><code>view()</code>는 <code>reshape()</code>와 비슷하지만, 원래 데이터와 메모리를 공유합니다. 따라서, 하나의 Tensor를 변경하면 다른 Tensor에도 영향을 미칩니다. 이 점을 고려하여 사용할 필요가 있습니다.</p>
<pre><code class="language-python"># 3x4 형태로 재구성 (메모리 공유)
view_tensor = original_tensor.view(3, 4)
</code></pre>
<h4 id="3-torchunsqueeze-torchsqueeze">3. 차원 추가 및 제거: <code>torch.unsqueeze()</code>와 <code>torch.squeeze()</code></h4>
<p><code>unsqueeze()</code>는 Tensor에 새로운 차원을 추가합니다. 반대로, <code>squeeze()</code>는 크기가 1인 차원을 제거합니다.</p>
<div class="arithmatex">
<div class="MathJax_Preview">
\mathbf{x} = \begin{bmatrix} 1 &amp; 2 &amp; 3 \end{bmatrix} \rightarrow \mathbf{y} = \begin{bmatrix} \begin{bmatrix} 1 \end{bmatrix} \\ \begin{bmatrix} 2 \end{bmatrix} \\ \begin{bmatrix} 3 \end{bmatrix} \end{bmatrix}
</div>
<script type="math/tex; mode=display">
\mathbf{x} = \begin{bmatrix} 1 & 2 & 3 \end{bmatrix} \rightarrow \mathbf{y} = \begin{bmatrix} \begin{bmatrix} 1 \end{bmatrix} \\ \begin{bmatrix} 2 \end{bmatrix} \\ \begin{bmatrix} 3 \end{bmatrix} \end{bmatrix}
</script>
</div>
<pre><code class="language-python"># 1차원 Tensor
x = torch.tensor([1, 2, 3])

# 2차원으로 확장
y = x.unsqueeze(1)

# 다시 1차원으로 압축
z = y.squeeze(1)
</code></pre>
<h3 id="_2">초기화 전략</h3>
<p>모델 학습에서 Tensor의 초기화는 매우 중요한 역할을 합니다. 잘못된 초기화는 학습 속도를 저하시킬 수 있으며, 최적의 가중치를 찾는 것을 어렵게 할 수 있습니다. 초기화 전략에는 여러 가지가 있으며, 각 전략은 특정한 조건에서 더 나은 성능을 발휘할 수 있습니다.</p>
<h4 id="1-xavier">1. Xavier 초기화</h4>
<p>Xavier 초기화는 특정 활성화 함수(주로 <code>tanh</code>)를 사용할 때 신경망의 학습을 안정적으로 만들어줍니다. 이 방식은 가중치가 <span class="arithmatex"><span class="MathJax_Preview">U(-\sqrt{\frac{6}{n_{in} + n_{out}}}, \sqrt{\frac{6}{n_{in} + n_{out}}})</span><script type="math/tex">U(-\sqrt{\frac{6}{n_{in} + n_{out}}}, \sqrt{\frac{6}{n_{in} + n_{out}}})</script></span>로 초기화됩니다.</p>
<div class="arithmatex">
<div class="MathJax_Preview">
W_{i,j} \sim U\left(-\sqrt{\frac{6}{n_{in} + n_{out}}}, \sqrt{\frac{6}{n_{in} + n_{out}}}\right)
</div>
<script type="math/tex; mode=display">
W_{i,j} \sim U\left(-\sqrt{\frac{6}{n_{in} + n_{out}}}, \sqrt{\frac{6}{n_{in} + n_{out}}}\right)
</script>
</div>
<p>여기서 <span class="arithmatex"><span class="MathJax_Preview">n_{in}</span><script type="math/tex">n_{in}</script></span>은 입력의 크기, <span class="arithmatex"><span class="MathJax_Preview">n_{out}</span><script type="math/tex">n_{out}</script></span>은 출력의 크기입니다.</p>
<pre><code class="language-python"># Xavier 초기화를 적용한 Tensor 생성
xavier_tensor = torch.empty(3, 3)
torch.nn.init.xavier_uniform_(xavier_tensor)
</code></pre>
<h4 id="2-he">2. He 초기화</h4>
<p>He 초기화는 ReLU와 같은 활성화 함수에 적합한 초기화 방법입니다. 이는 Xavier 초기화의 변형으로, 가중치를 <span class="arithmatex"><span class="MathJax_Preview">\mathcal{N}(0, \frac{2}{n_{in}})</span><script type="math/tex">\mathcal{N}(0, \frac{2}{n_{in}})</script></span> 분포에서 샘플링하여 초기화합니다. 이 방식은 활성화 함수의 특성상 많은 뉴런이 활성화되지 않는 문제를 완화하는 데 도움이 됩니다.</p>
<div class="arithmatex">
<div class="MathJax_Preview">
W_{i,j} \sim \mathcal{N}(0, \frac{2}{n_{in}})
</div>
<script type="math/tex; mode=display">
W_{i,j} \sim \mathcal{N}(0, \frac{2}{n_{in}})
</script>
</div>
<p>여기서 <span class="arithmatex"><span class="MathJax_Preview">n_{in}</span><script type="math/tex">n_{in}</script></span>은 입력의 크기입니다.</p>
<pre><code class="language-python"># He 초기화를 적용한 Tensor 생성
he_tensor = torch.empty(3, 3)
torch.nn.init.kaiming_normal_(he_tensor, mode='fan_in', nonlinearity='relu')
</code></pre>
<h4 id="3">3. 정규분포 및 균등분포 초기화</h4>
<p>가중치를 초기화할 때 기본적인 방법으로 정규분포나 균등분포를 사용할 수도 있습니다. PyTorch는 이를 쉽게 설정할 수 있는 함수들을 제공합니다.</p>
<ul>
<li><code>torch.nn.init.normal_(tensor, mean=0.0, std=1.0)</code>: 평균과 표준편차를 지정한 정규분포로 초기화</li>
<li><code>torch.nn.init.uniform_(tensor, a=0.0, b=1.0)</code>: <span class="arithmatex"><span class="MathJax_Preview">[a, b]</span><script type="math/tex">[a, b]</script></span> 범위의 균등분포로 초기화</li>
</ul>
<pre><code class="language-python"># 평균이 0이고 표준편차가 1인 정규분포로 초기화된 Tensor
normal_tensor = torch.empty(3, 3)
torch.nn.init.normal_(normal_tensor, mean=0.0, std=1.0)

# 0에서 1 사이의 균등분포로 초기화된 Tensor
uniform_tensor = torch.empty(3, 3)
torch.nn.init.uniform_(uniform_tensor, a=0.0, b=1.0)
</code></pre>
<h3 id="tensor_4">다양한 형태의 Tensor</h3>
<h4 id="1-tensor">1. 스칼라, 벡터, 행렬, 고차원 Tensor</h4>
<p>Tensor는 수학에서의 다양한 객체(스칼라, 벡터, 행렬, 고차원 배열)를 일반화한 형태입니다.</p>
<ul>
<li>
<p><strong>스칼라 (Scalar)</strong>: 차원이 없는 0차원 Tensor
  [
  s = 5
  ]</p>
</li>
<li>
<p><strong>벡터 (Vector)</strong>: 1차원 Tensor
  [
  \mathbf{v} = \begin{bmatrix} 1 &amp; 2 &amp; 3 \end{bmatrix}
  ]</p>
</li>
<li>
<p><strong>행렬 (Matrix)</strong>: 2차원 Tensor
  [
  \mathbf{M} = \begin{bmatrix} 1 &amp; 2 \ 3 &amp; 4 \end{bmatrix}
  ]</p>
</li>
<li>
<p><strong>고차원 Tensor (Higher-Dimensional Tensor)</strong>: 3차원 이상의 Tensor
  [
  \mathbf{T}_{ijk} = \text{3D Tensor}
  ]</p>
</li>
</ul>
<p>각 차원에 따라 Tensor의 연산 방법과 응용 분야가 달라지며, PyTorch는 모든 차원의 Tensor를 효율적으로 처리할 수 있도록 설계되었습니다.</p>
<h4 id="2-batch-tensor">2. Batch와 고차원 Tensor</h4>
<p>딥러닝에서 고차원 Tensor는 주로 이미지나 시퀀스 데이터와 같은 고차원 데이터를 처리하는 데 사용됩니다. 예를 들어, 이미지는 일반적으로 <span class="arithmatex"><span class="MathJax_Preview">C \times H \times W</span><script type="math/tex">C \times H \times W</script></span> 형태로 표현되며, 여기서 <span class="arithmatex"><span class="MathJax_Preview">C</span><script type="math/tex">C</script></span>는 채널 수, <span class="arithmatex"><span class="MathJax_Preview">H</span><script type="math/tex">H</script></span>는 높이, <span class="arithmatex"><span class="MathJax_Preview">W</span><script type="math/tex">W</script></span>는 너비를 나타냅니다.</p>
<pre><code class="language-python"># 3채널 RGB 이미지의 Batch를 표현하는 4차원 Tensor 생성
image_batch = torch.randn(32, 3, 224, 224)
</code></pre>
<p>여기서 <code>image_batch</code>는 크기가 <span class="arithmatex"><span class="MathJax_Preview">(32, 3, 224, 224)</span><script type="math/tex">(32, 3, 224, 224)</script></span>인 Tensor이며, 이는 32개의 RGB 이미지로 구성된 Batch를 나타냅니다. 각 이미지의 크기는 <span class="arithmatex"><span class="MathJax_Preview">224 \times 224</span><script type="math/tex">224 \times 224</script></span>이며, 각 픽셀은 3개의 채널(R, G, B)을 가지고 있습니다.</p>
<h4 id="3-tensor_1">3. Tensor의 복사와 변경</h4>
<p>Tensor를 생성하고 초기화한 후에는 데이터를 복사하거나 부분적으로 변경하는 작업이 필요할 수 있습니다. PyTorch에서는 다양한 방법으로 이를 처리할 수 있습니다.</p>
<ul>
<li><code>clone()</code>: 기존 Tensor의 데이터를 복사하여 새로운 Tensor를 생성</li>
<li><code>copy_()</code>: 기존 Tensor의 값을 다른 Tensor에 복사</li>
</ul>
<pre><code class="language-python"># 기존 Tensor를 복사하여 새로운 Tensor 생성
original_tensor = torch.tensor([1, 2, 3])
copied_tensor = original_tensor.clone()

# 원본 Tensor의 값을 다른 Tensor에 복사
target_tensor = torch.tensor([0, 0, 0])
target_tensor.copy_(original_tensor)
</code></pre>
<p><code>clone()</code>과 <code>copy_()</code>는 Tensor를 다룰 때 자주 사용되며, 데이터의 독립성을 보장하거나 특정 조건을 충족하기 위해 활용됩니다.</p>
<h3 id="tensor_5">Tensor의 초기화 실습</h3>
<p>Tensor의 초기화는 다양한 조건에 따라 다르게 적용할 수 있습니다. 예를 들어, 특정 범위 내의 난수를 사용하여 초기화하거나, 복잡한 연산을 통해 초기 값을 결정할 수 있습니다. 이러한 실습을 통해 Tensor 초기화 방법을 구체적으로 이해할 수 있습니다.</p>
<pre><code class="language-python"># 0과 1 사이의 난수로 초기화된 3x3 Tensor
random_tensor = torch.rand(3, 3)

# 정규분포의 평균과 표준편차를 지정하여 초기화
gaussian_tensor = torch.randn(3, 3) * 0.01 + 0.5
</code></pre>
<p>위의 코드 예제들은 PyTorch에서 다양한 초기화 방법을 실습하는 과정입니다. 이러한 실습을 통해 Tensor의 생성과 초기화를 명확하게 이해할 수 있으며, 이는 모델 학습의 효율성과 성능 향상에 기여할 수 있습니다.</p>

  <br>
    

    <br>
</div>

<footer class="container-fluid wm-page-content">
  <p>Documentation built with <a href="https://www.mkdocs.org/">MkDocs</a> using <a href="https://github.com/gristlabs/mkdocs-windmill">Windmill</a> theme by Grist Labs.</p>
</footer>

</body>
</html>