<!DOCTYPE html>

<html lang="en">
<head>
<meta charset="utf-8"/>
<meta content="IE=edge" http-equiv="X-UA-Compatible"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<link href="https://booiljung.github.io/robot/ros2_humble/chapter_22/2201/" rel="canonical"/>
<link href="../../../../img/favicon.ico" rel="shortcut icon"/>
<meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport">
<title>rviz2 사용법 - 실험 도서관</title>
<link href="../../../../css/bootstrap-3.3.7.min.css" rel="stylesheet"/>
<link href="../../../../css/font-awesome-4.7.0.css" rel="stylesheet"/>
<link href="../../../../css/base.css" rel="stylesheet"/>
<link href="../../../../css/highlight.css" rel="stylesheet"/>
<link href="../../../../css/custom.css" rel="stylesheet"/>
<!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
<!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.3.0/respond.min.js"></script>
    <![endif]-->
<script src="../../../../js/jquery-3.2.1.min.js"></script>
<script src="../../../../js/bootstrap-3.3.7.min.js"></script>
<script src="../../../../js/highlight.pack.js"></script>
<base target="_top"/>
<script>
      var base_url = '../../../..';
      var is_top_frame = false;
        
        var pageToc = [
          {title: "rviz2 \uc18c\uac1c", url: "#_top", children: [
          ]},
          {title: "rviz2 \uc124\uce58", url: "#rviz2_1", children: [
              {title: "Ubuntu \uc124\uce58", url: "#ubuntu" },
              {title: "Windows \ubc0f macOS \uc124\uce58", url: "#windows-macos" },
          ]},
          {title: "rviz2 \uc778\ud130\ud398\uc774\uc2a4", url: "#rviz2_2", children: [
          ]},
          {title: "\uae30\ubcf8 \uc124\uc815", url: "#_1", children: [
              {title: "Global Options", url: "#global-options" },
              {title: "Displays", url: "#displays" },
              {title: "\uce74\uba54\ub77c \uc2dc\uc810 \uc870\uc791", url: "#_2" },
          ]},
          {title: "rviz2\ub97c \ud1b5\ud55c \ub370\uc774\ud130 \uc2dc\uac01\ud654", url: "#rviz2_3", children: [
              {title: "LaserScan \ub370\uc774\ud130 \uc2dc\uac01\ud654", url: "#laserscan" },
              {title: "LaserScan \ud1a0\ud53d\uc758 \ub370\uc774\ud130 \uad6c\uc870", url: "#laserscan_1" },
          ]},
          {title: "PointCloud2 \ub370\uc774\ud130 \uc2dc\uac01\ud654", url: "#pointcloud2", children: [
              {title: "PointCloud2 \ub370\uc774\ud130 \ud37c\ube14\ub9ac\uc154 \uc124\uc815", url: "#pointcloud2_1" },
              {title: "rviz2\uc5d0\uc11c PointCloud2 \uc2dc\uac01\ud654", url: "#rviz2-pointcloud2" },
              {title: "PointCloud2\uc758 \uc0c9\uc0c1 \uc124\uc815", url: "#pointcloud2_2" },
          ]},
          {title: "\uc88c\ud45c \ubcc0\ud658(TF)\uc758 \uc2dc\uac01\ud654", url: "#tf", children: [
              {title: "TF \uba54\uc2dc\uc9c0\uc758 \uad6c\uc870", url: "#tf_1" },
              {title: "TF \uc2dc\uac01\ud654 \uc124\uc815", url: "#tf_2" },
              {title: "TF\uc640 \uace0\uc815 \ud504\ub808\uc784\uc758 \uad00\uacc4", url: "#tf_3" },
          ]},
          {title: "\uce74\uba54\ub77c \uc2dc\uac01\ud654", url: "#_3", children: [
              {title: "\uce74\uba54\ub77c \ub370\uc774\ud130 \ud37c\ube14\ub9ac\uc154 \uc124\uc815", url: "#_4" },
              {title: "rviz2\uc5d0\uc11c \uce74\uba54\ub77c \ub370\uc774\ud130 \uc2dc\uac01\ud654", url: "#rviz2_4" },
              {title: "Image \uba54\uc2dc\uc9c0\uc758 \uad6c\uc870", url: "#image" },
          ]},
          {title: "\ub9c8\ucee4(Marker) \uc2dc\uac01\ud654", url: "#marker", children: [
              {title: "Marker \uba54\uc2dc\uc9c0\uc758 \uad6c\uc870", url: "#marker_1" },
              {title: "\ub9c8\ucee4 \uc0dd\uc131 \ubc0f \uc2dc\uac01\ud654", url: "#_5" },
              {title: "\ub9c8\ucee4 \uc885\ub958", url: "#_6" },
              {title: "\ub9c8\ucee4\ub97c \uc774\uc6a9\ud55c 3D \uac1d\uccb4 \uc2dc\uac01\ud654", url: "#3d" },
          ]},
          {title: "QoS \uc815\ucc45 \uc774\ud574", url: "#qos", children: [
          ]},
          {title: "\uc2dc\ubbac\ub808\uc774\uc158 \ub370\uc774\ud130 \uc2dc\uac01\ud654", url: "#_7", children: [
              {title: "1. rviz2\uc5d0\uc11c\uc758 \uc2dc\ubbac\ub808\uc774\uc158 \ub370\uc774\ud130 \uc2dc\uac01\ud654", url: "#1-rviz2" },
              {title: "2. \uba54\uc2dc\uc9c0 \ud0c0\uc785 \ubc0f \ubcc0\ud658", url: "#2" },
              {title: "3. \uc2dc\ubbac\ub808\uc774\uc158 \ub370\uc774\ud130\uc640 \uc2dc\uac01\ud654\uc758 \ud6a8\uc728\uc131", url: "#3" },
              {title: "4. 3D \ub370\uc774\ud130 \uc2dc\uac01\ud654\uc640 \uc88c\ud45c \ubcc0\ud658", url: "#4-3d" },
              {title: "5. ROS2\uc640 Gazebo \uc2dc\ubbac\ub808\uc774\uc158 \ub370\uc774\ud130 \uc2dc\uac01\ud654", url: "#5-ros2-gazebo" },
          ]},
        ];

    </script>
<script src="../../../../js/base.js"></script>
<script src="../../../../js/google_analytics.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML"></script>
<script src="https://www.googletagmanager.com/gtag/js?id=G-3F4LHCTF88"></script>
</meta></head>
<body>
<script>
if (is_top_frame) { $('body').addClass('wm-top-page'); }
</script>
<div class="container-fluid wm-page-content">
<a name="_top"></a>
<div aria-label="navigation" class="row wm-article-nav-buttons" role="navigation">
<div class="wm-article-nav pull-right">
<a class="btn btn-xs btn-default pull-right" href="../2202/">
        Next
        <i aria-hidden="true" class="fa fa-chevron-right"></i>
</a>
<a class="btn btn-xs btn-link" href="../2202/">
        로봇 및 센서 데이터 시각화
      </a>
</div>
<div class="wm-article-nav">
<a class="btn btn-xs btn-default pull-left" href="../../chapter_21/2106/">
<i aria-hidden="true" class="fa fa-chevron-left"></i>
        Previous</a><a class="btn btn-xs btn-link" href="../../chapter_21/2106/">
        TF2의 성능 최적화
      </a>
</div>
</div>
<h3 id="rviz2">rviz2 소개</h3>
<p>rviz2는 ROS2에서 제공하는 시각화 도구로, 센서 데이터, 로봇의 상태, 좌표 변환 등을 직관적으로 확인할 수 있는 GUI 기반의 툴이다. 이 도구는 특히 복잡한 로봇 시스템에서 각종 데이터가 의도한 대로 처리되고 있는지를 확인하는 데 중요한 역할을 한다. ROS2 시스템에서의 실시간 데이터 시각화, 디버깅, 그리고 시뮬레이션 결과를 확인하는데 필수적으로 사용된다.</p>
<h3 id="rviz2_1">rviz2 설치</h3>
<p>rviz2는 ROS2의 일부로 포함되어 있으며, ROS2를 설치할 때 기본적으로 포함된다. Ubuntu, Windows, macOS에서의 설치는 아래와 같다.</p>
<h4 id="ubuntu">Ubuntu 설치</h4>
<pre><code class="language-bash">sudo apt update
sudo apt install ros-humble-rviz2
</code></pre>
<h4 id="windows-macos">Windows 및 macOS 설치</h4>
<p>Windows와 macOS는 ROS2 Humble을 설치할 때 rviz2가 함께 설치된다. 추가적으로 별도의 설치 과정은 필요하지 않는다.</p>
<h3 id="rviz2_2">rviz2 인터페이스</h3>
<p>rviz2의 기본 인터페이스는 다음과 같은 주요 구성 요소로 이루어져 있다:</p>
<ol>
<li>
<p><strong>Displays 패널</strong>: 시각화할 항목을 추가하고 관리하는 패널이다. 각 항목은 로봇 상태, 센서 데이터, 메시지 등을 포함하며, 각 항목에 대해 세부 설정을 조정할 수 있다.</p>
</li>
<li>
<p><strong>Views</strong>: 카메라 시점 또는 3D 뷰의 설정을 관리한다. 이를 통해 사용자는 로봇과 주변 환경을 다양한 각도에서 관찰할 수 있다.</p>
</li>
<li>
<p><strong>Global Options</strong>: rviz2에서 시각화할 환경의 기본적인 설정을 담당하는 곳이다. 여기에서는 좌표 축의 길이, 배경 색상, 고정 프레임 등을 설정할 수 있다.</p>
</li>
</ol>
<h3 id="_1">기본 설정</h3>
<h4 id="global-options">Global Options</h4>
<p>rviz2 사용을 시작할 때 가장 먼저 설정해야 하는 옵션은 <strong>Global Options</strong>이다. 특히, <strong>Fixed Frame</strong> 설정이 중요한데, 이는 시각화의 기준이 되는 좌표계를 의미한다. 일반적으로 로봇의 기본 프레임이나 월드 프레임을 사용하게 된다.</p>
<ul>
<li><strong>Fixed Frame</strong>: 기본적으로 <code>world</code> 또는 <code>base_link</code> 등의 로봇 기준 프레임을 설정한다. 이 프레임은 rviz2에서 모든 시각화 요소의 기준이 된다.</li>
</ul>
<h4 id="displays">Displays</h4>
<p>Displays 패널에서는 rviz2에 다양한 시각화 항목을 추가할 수 있다. 가장 많이 사용되는 항목은 아래와 같다.</p>
<ol>
<li><strong>Grid</strong>: 좌표축 상의 격자를 그려준다. 로봇의 위치와 방향을 파악할 때 유용하다.</li>
<li><strong>TF</strong>: ROS2의 TF 트리를 시각화하여, 각 좌표계 간의 관계를 쉽게 파악할 수 있다.</li>
<li><strong>LaserScan</strong>: LiDAR 등의 레이저 스캔 데이터를 시각화한다.</li>
<li><strong>PointCloud2</strong>: 3D 포인트 클라우드 데이터를 시각화한다.</li>
</ol>
<p>Displays에 새로운 항목을 추가하는 방법은 아래와 같다.</p>
<ol>
<li>Displays 패널의 하단에 있는 <strong>Add</strong> 버튼을 클릭한다.</li>
<li>원하는 항목을 선택하여 추가한다.</li>
</ol>
<h4 id="_2">카메라 시점 조작</h4>
<p>rviz2에서 3D 공간을 자유롭게 탐색하기 위해 카메라의 시점을 조작할 수 있다. 마우스를 사용하여 다음과 같이 조작할 수 있다:</p>
<ul>
<li><strong>좌클릭</strong>: 3D 공간을 회전한다.</li>
<li><strong>우클릭</strong>: 시점을 상하좌우로 이동시킨다.</li>
<li><strong>휠 스크롤</strong>: 줌 인/아웃을 수행한다.</li>
</ul>
<h3 id="rviz2_3">rviz2를 통한 데이터 시각화</h3>
<h4 id="laserscan">LaserScan 데이터 시각화</h4>
<p>LiDAR와 같은 센서로부터 얻은 레이저 스캔 데이터를 rviz2에서 시각화하는 방법을 설명한다. 레이저 스캔 데이터는 일반적으로 <code>sensor_msgs/LaserScan</code> 타입으로 퍼블리싱되며, 이를 rviz2에서 확인하기 위해서는 다음과 같은 과정을 거친다.</p>
<ol>
<li>
<p><strong>LaserScan 데이터 퍼블리셔 설정</strong>
   먼저 ROS2에서 LaserScan 데이터를 퍼블리싱하는 노드를 실행해야 한다. 이는 실제 LiDAR 센서나 시뮬레이션 환경에서 이루어질 수 있다.</p>
</li>
<li>
<p><strong>rviz2에서 LaserScan 시각화</strong>
   rviz2를 실행하고, <strong>Displays</strong> 패널에서 <strong>LaserScan</strong> 항목을 추가한다. 추가된 LaserScan 항목의 <strong>Topic</strong> 필드에 퍼블리싱되는 토픽 이름을 입력한다.</p>
</li>
</ol>
<h4 id="laserscan_1">LaserScan 토픽의 데이터 구조</h4>
<p>LaserScan 메시지의 중요한 필드는 다음과 같다:</p>
<ul>
<li><strong>angle_min</strong>: 스캔이 시작되는 각도 <span class="arithmatex"><span class="MathJax_Preview">\theta_{min}</span><script type="math/tex">\theta_{min}</script></span>.</li>
<li><strong>angle_max</strong>: 스캔이 끝나는 각도 <span class="arithmatex"><span class="MathJax_Preview">\theta_{max}</span><script type="math/tex">\theta_{max}</script></span>.</li>
<li><strong>ranges</strong>: 각도 범위에 따른 거리 값들의 배열. 이 값은 로봇의 주변 환경을 2D 거리 측정 데이터로 나타낸다.</li>
</ul>
<p>레이저 스캔의 각도 범위는 다음과 같이 정의된다:</p>
<p>$$</p>
<p>\mathbf{\theta} = [\theta_{min}, \theta_{max}]</p>
<p>$$</p>
<p>거리 데이터 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{d}</span><script type="math/tex">\mathbf{d}</script></span>는 레이저 스캔에서 반환된 거리 값들의 배열로 나타낼 수 있다:</p>
<p>$$</p>
<p>\mathbf{d} = [d_1, d_2, \dots, d_n]</p>
<p>$$</p>
<h3 id="pointcloud2">PointCloud2 데이터 시각화</h3>
<p>3D 포인트 클라우드(PointCloud2) 데이터는 LiDAR, RGB-D 카메라 또는 기타 3D 센서를 사용하여 수집된 환경 정보를 시각화하는 데 사용된다. 포인트 클라우드는 3차원 공간에서 각 포인트의 위치를 정의하며, rviz2에서는 이를 직관적으로 확인할 수 있다.</p>
<h4 id="pointcloud2_1">PointCloud2 데이터 퍼블리셔 설정</h4>
<p>먼저 ROS2에서 3D 포인트 클라우드 데이터를 퍼블리싱하는 노드를 실행해야 한다. 일반적으로 <code>sensor_msgs/PointCloud2</code> 메시지 형식을 사용하여 포인트 클라우드 데이터를 퍼블리싱한다. 이 메시지의 주요 필드는 다음과 같다:</p>
<ul>
<li><strong>width</strong>: 포인트 클라우드의 포인트 개수</li>
<li><strong>height</strong>: 포인트 클라우드의 행 수 (2D 배열로 표현되는 경우)</li>
<li><strong>fields</strong>: 각 포인트의 필드 (x, y, z 좌표와 색상 정보 등)</li>
</ul>
<h4 id="rviz2-pointcloud2">rviz2에서 PointCloud2 시각화</h4>
<ol>
<li><strong>Displays</strong> 패널에서 <strong>PointCloud2</strong> 항목을 추가한다.</li>
<li><strong>Topic</strong> 필드에 퍼블리싱 중인 <code>sensor_msgs/PointCloud2</code> 메시지의 토픽 이름을 입력한다.</li>
<li>데이터가 정상적으로 퍼블리싱되면 rviz2에서 3D 공간 상에 각 포인트들이 표시된다.</li>
</ol>
<p>포인트 클라우드는 3D 공간에서 좌표 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{p}_i = (x_i, y_i, z_i)</span><script type="math/tex">\mathbf{p}_i = (x_i, y_i, z_i)</script></span>로 정의된다. 각 포인트의 좌표는 다음과 같은 벡터로 표현된다:</p>
<p>$$</p>
<p>\mathbf{P} = \begin{bmatrix} 
x_1 &amp; y_1 &amp; z_1 \
x_2 &amp; y_2 &amp; z_2 \
\vdots &amp; \vdots &amp; \vdots \
x_n &amp; y_n &amp; z_n \
\end{bmatrix}</p>
<p>$$</p>
<p>rviz2에서는 이러한 좌표들을 사용하여 3D 공간 상에서 점들의 위치를 시각화한다. 각 포인트는 해당 위치에 3D 점으로 나타나며, 센서의 거리 데이터를 직관적으로 확인할 수 있다.</p>
<h4 id="pointcloud2_2">PointCloud2의 색상 설정</h4>
<p>포인트 클라우드 데이터는 색상 정보도 함께 포함할 수 있다. rviz2에서 포인트의 색상을 나타내기 위해 <strong>Color Transformer</strong> 설정을 사용할 수 있다. 포인트의 색상은 <code>rgb</code> 또는 <code>intensity</code> 필드를 기반으로 시각화되며, 사용자가 이를 원하는 방식으로 설정할 수 있다.</p>
<h3 id="tf">좌표 변환(TF)의 시각화</h3>
<p>rviz2에서는 로봇의 각 구성 요소 또는 센서들이 서로 다른 좌표계를 가지고 있을 때, 이들 간의 변환을 시각적으로 확인할 수 있다. 이를 위해 ROS2의 TF2 라이브러리를 사용하며, 각 좌표계 간의 변환 정보를 시각화한다.</p>
<h4 id="tf_1">TF 메시지의 구조</h4>
<p>TF 메시지는 좌표계 간의 변환을 나타내며, 각 변환은 다음과 같은 수식으로 표현된다:</p>
<p>$$</p>
<p>\mathbf{T} = \begin{bmatrix} 
\mathbf{R} &amp; \mathbf{t} \
0 &amp; 1 \
\end{bmatrix}</p>
<p>$$</p>
<p>여기서 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{R}</span><script type="math/tex">\mathbf{R}</script></span>은 회전 행렬이고, <span class="arithmatex"><span class="MathJax_Preview">\mathbf{t}</span><script type="math/tex">\mathbf{t}</script></span>는 변환 벡터이다. </p>
<p>rviz2에서는 이러한 변환 행렬을 기반으로 각 좌표계의 위치와 방향을 화살표로 표시한다. 화살표의 길이와 방향은 변환 행렬에 따라 결정된다.</p>
<h4 id="tf_2">TF 시각화 설정</h4>
<ol>
<li><strong>Displays</strong> 패널에서 <strong>TF</strong> 항목을 추가한다.</li>
<li>각 노드의 좌표 변환 정보를 시각화하려면 <strong>Fixed Frame</strong>을 설정하고, 다른 좌표계가 어떻게 변환되는지 확인할 수 있다.</li>
</ol>
<p>TF를 시각화할 때, 고정 프레임을 기준으로 모든 좌표 변환이 이루어지며, 이를 통해 로봇의 각 구성 요소가 어떤 위치와 방향에 있는지를 확인할 수 있다.</p>
<h4 id="tf_3">TF와 고정 프레임의 관계</h4>
<p>TF 시각화에서 중요한 것은 고정 프레임(Fixed Frame)이다. 고정 프레임은 로봇의 기본적인 좌표계 또는 월드 좌표계를 의미하며, 다른 모든 좌표계는 이 고정 프레임을 기준으로 상대적인 변환을 갖는다.</p>
<p>예를 들어, 로봇의 베이스 프레임이 <code>base_link</code>라면, 고정 프레임을 <code>base_link</code>로 설정하고, 다른 모든 센서나 액추에이터의 좌표계는 이 <code>base_link</code>를 기준으로 변환된다.</p>
<h3 id="_3">카메라 시각화</h3>
<p>rviz2에서는 카메라의 실시간 영상 데이터를 시각화할 수 있다. 이를 통해 로봇이 수집한 비전 데이터를 실시간으로 모니터링하거나 카메라 센서의 동작을 확인할 수 있다. ROS2에서 카메라 데이터를 퍼블리싱할 때, 일반적으로 <code>sensor_msgs/Image</code> 메시지를 사용하며, 이를 rviz2에서 시각화하는 방법은 다음과 같다.</p>
<h4 id="_4">카메라 데이터 퍼블리셔 설정</h4>
<p>카메라 노드를 실행하여 <code>sensor_msgs/Image</code> 형식의 데이터를 퍼블리싱해야 한다. 실제 로봇에 연결된 카메라나 가상 시뮬레이션 환경에서의 카메라 노드가 이를 처리할 수 있다.</p>
<h4 id="rviz2_4">rviz2에서 카메라 데이터 시각화</h4>
<ol>
<li><strong>Displays</strong> 패널에서 <strong>Image</strong> 항목을 추가한다.</li>
<li><strong>Topic</strong> 필드에 퍼블리싱 중인 <code>sensor_msgs/Image</code> 메시지의 토픽 이름을 입력한다.</li>
<li>카메라에서 퍼블리싱되는 영상이 rviz2의 뷰에 표시된다.</li>
</ol>
<h4 id="image">Image 메시지의 구조</h4>
<p><code>sensor_msgs/Image</code> 메시지는 2D 이미지 데이터를 포함하며, 주요 필드는 다음과 같다:</p>
<ul>
<li><strong>width</strong>: 이미지의 가로 픽셀 수</li>
<li><strong>height</strong>: 이미지의 세로 픽셀 수</li>
<li><strong>encoding</strong>: 이미지의 인코딩 방식 (예: <code>rgb8</code>, <code>mono8</code>, <code>bgr8</code> 등)</li>
<li><strong>step</strong>: 각 줄의 바이트 수</li>
<li><strong>data</strong>: 실제 이미지 데이터를 포함하는 바이트 배열</li>
</ul>
<p>이 메시지를 시각화할 때 rviz2는 인코딩된 이미지 데이터를 처리하여 사용자에게 보여준다.</p>
<h3 id="marker">마커(Marker) 시각화</h3>
<p>rviz2에서 사용자는 마커(Marker)를 이용하여 3D 공간에 다양한 형태의 객체를 시각적으로 표시할 수 있다. 마커는 로봇의 상태나 경로를 표시하거나, 특정 지점을 강조하는 데 유용하게 사용할 수 있다. ROS2에서는 <code>visualization_msgs/Marker</code> 메시지를 통해 마커 데이터를 퍼블리싱한다.</p>
<h4 id="marker_1">Marker 메시지의 구조</h4>
<p><code>visualization_msgs/Marker</code> 메시지는 다양한 3D 객체(점, 선, 화살표, 큐브, 스피어 등)를 시각화할 수 있는 구조로 되어 있다. 주요 필드는 다음과 같다:</p>
<ul>
<li><strong>type</strong>: 마커의 유형 (화살표, 큐브, 스피어, 선 등)</li>
<li><strong>pose</strong>: 마커가 위치할 좌표 및 방향 정보</li>
<li><strong>scale</strong>: 마커의 크기를 나타내는 3D 벡터</li>
<li><strong>color</strong>: 마커의 색상 (RGBA 형식)</li>
<li><strong>lifetime</strong>: 마커가 화면에 표시되는 시간 (영구적 표시를 원하면 0으로 설정)</li>
</ul>
<h4 id="_5">마커 생성 및 시각화</h4>
<ol>
<li><strong>Displays</strong> 패널에서 <strong>Marker</strong> 항목을 추가한다.</li>
<li>퍼블리싱 중인 <code>visualization_msgs/Marker</code> 메시지의 토픽 이름을 <strong>Topic</strong> 필드에 입력한다.</li>
<li>설정된 마커가 rviz2에서 시각화된다.</li>
</ol>
<p>마커는 다양한 방식으로 사용될 수 있으며, 로봇의 이동 경로, 장애물의 위치, 센서가 탐지한 주요 지점 등을 시각화할 때 매우 유용하다.</p>
<h4 id="_6">마커 종류</h4>
<p>마커의 유형은 다양하며, 각각의 사용 방법에 따라 적절한 시각화 결과를 얻을 수 있다. 몇 가지 대표적인 마커는 다음과 같다:</p>
<ol>
<li><strong>화살표 (Arrow)</strong>: 방향을 표시하는 데 사용된다.</li>
<li><strong>큐브 (Cube)</strong>: 특정 구역이나 객체를 나타내는 데 유용하다.</li>
<li><strong>스피어 (Sphere)</strong>: 구체 형태로 시각화할 때 사용된다.</li>
<li><strong>라인 리스트 (Line List)</strong>: 선을 그려 경로나 구조를 시각화한다.</li>
</ol>
<h4 id="3d">마커를 이용한 3D 객체 시각화</h4>
<p>마커는 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{P} = (x, y, z)</span><script type="math/tex">\mathbf{P} = (x, y, z)</script></span> 위치에 크기 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{S} = (s_x, s_y, s_z)</span><script type="math/tex">\mathbf{S} = (s_x, s_y, s_z)</script></span>와 색상 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{C} = (r, g, b, a)</span><script type="math/tex">\mathbf{C} = (r, g, b, a)</script></span>로 표현될 수 있다. 이를 수학적으로 나타내면:</p>
<p>$$</p>
<p>\mathbf{M} = \left{ \mathbf{P}, \mathbf{S}, \mathbf{C} \right}</p>
<p>$$</p>
<p>여기서:
- <span class="arithmatex"><span class="MathJax_Preview">\mathbf{P}</span><script type="math/tex">\mathbf{P}</script></span>는 마커의 위치 벡터이다.
- <span class="arithmatex"><span class="MathJax_Preview">\mathbf{S}</span><script type="math/tex">\mathbf{S}</script></span>는 마커의 크기 벡터이다.
- <span class="arithmatex"><span class="MathJax_Preview">\mathbf{C}</span><script type="math/tex">\mathbf{C}</script></span>는 마커의 색상 벡터로, 각각 빨강(R), 초록(G), 파랑(B), 알파(A) 값을 갖는다.</p>
<h3 id="qos">QoS 정책 이해</h3>
<p>rviz2에서 데이터의 시각화는 QoS(Quality of Service) 정책에 따라 영향을 받을 수 있다. ROS2는 퍼블리셔와 서브스크라이버 간의 통신 품질을 관리하기 위해 다양한 QoS 프로파일을 지원한다. 특히, 시각화 데이터는 실시간성과 신뢰성이 중요하기 때문에 적절한 QoS 설정이 필요하다.</p>
<p>QoS 프로파일의 중요한 요소는 다음과 같다:</p>
<ul>
<li><strong>History</strong>: 데이터 버퍼링 설정</li>
<li><code>KEEP_LAST</code>: 최근 데이터만 유지한다.</li>
<li>
<p><code>KEEP_ALL</code>: 모든 데이터를 유지한다.</p>
</li>
<li>
<p><strong>Depth</strong>: 버퍼에 저장할 메시지의 수를 설정한다.</p>
</li>
<li>
<p><strong>Reliability</strong>: 신뢰성 여부 설정</p>
</li>
<li><code>RELIABLE</code>: 모든 메시지가 전달되도록 보장한다.</li>
<li>
<p><code>BEST_EFFORT</code>: 가능한 한 많은 메시지를 전달한다.</p>
</li>
<li>
<p><strong>Durability</strong>: 이전 메시지에 대한 구독 설정</p>
</li>
<li><code>VOLATILE</code>: 새로운 구독자는 이전 메시지를 받지 않는다.</li>
<li><code>TRANSIENT_LOCAL</code>: 구독자가 연결되기 전 메시지까지 받을 수 있다.</li>
</ul>
<p>rviz2에서 데이터 시각화에 적절한 QoS 프로파일을 설정하는 것은 시각화 성능을 높이는 데 중요하다.</p>
<h1 id="_7">시뮬레이션 데이터 시각화</h1>
<p>시뮬레이션 데이터 시각화는 ROS2에서 매우 중요한 부분이다. 로봇의 동작이나 센서 데이터를 시뮬레이션할 때 그 데이터를 직관적으로 이해하고 문제를 분석하는 데에 유용하게 사용된다. ROS2에서는 주로 <strong>rviz2</strong>라는 시각화 도구를 활용하여 데이터를 시각적으로 표현할 수 있다. 시뮬레이션 데이터는 센서 값, 로봇의 위치 및 자세, 경로 계획, 장애물 탐지 등 다양한 정보를 포함할 수 있으며, 이러한 정보를 시각적으로 표현하는 것은 개발 과정에서 필수적인 요소이다.</p>
<h3 id="1-rviz2">1. rviz2에서의 시뮬레이션 데이터 시각화</h3>
<p><strong>rviz2</strong>는 ROS2에서 기본적으로 제공하는 시각화 도구로, 다양한 형식의 데이터를 실시간으로 시각화할 수 있는 환경을 제공한다. rviz2에서 시뮬레이션 데이터를 시각화하려면 먼저 적절한 <strong>Display</strong>를 설정해야 한다. Display는 시각화하려는 데이터의 종류에 따라 설정하는 것이 달라진다. </p>
<h4 id="11">1.1 기본 구성 요소</h4>
<p>rviz2의 기본 구성 요소는 다음과 같다:</p>
<ul>
<li><strong>Fixed Frame</strong>: 모든 데이터를 참조할 기본 좌표계로 설정하는 프레임이다. 주로 로봇의 <strong>base_link</strong> 또는 <strong>odom</strong> 프레임을 사용한다.</li>
<li><strong>Display</strong>: 시각화할 데이터 유형에 맞는 디스플레이 설정을 추가한다. 예를 들어, <strong>LaserScan</strong> 데이터는 <strong>LaserScan Display</strong>를 사용하고, <strong>Pose</strong> 데이터는 <strong>Pose Display</strong>를 사용한다.</li>
</ul>
<h4 id="12">1.2 주요 데이터 시각화 종류</h4>
<ul>
<li>
<p><strong>PointCloud2</strong>: 3D 스캐너나 LiDAR에서 수집된 포인트 클라우드 데이터를 시각화하는데 사용된다. 이 데이터는 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{P} = \{ \mathbf{p}_1, \mathbf{p}_2, \dots, \mathbf{p}_n \}</span><script type="math/tex">\mathbf{P} = \{ \mathbf{p}_1, \mathbf{p}_2, \dots, \mathbf{p}_n \}</script></span> 형태의 점들로 구성되며, 각각의 점 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{p}_i</span><script type="math/tex">\mathbf{p}_i</script></span>는 3차원 공간의 좌표값을 갖는다.</p>
</li>
<li>
<p><strong>LaserScan</strong>: 2D 라이다(LiDAR) 데이터를 시각화하는데 사용된다. 라이다에서 출력된 데이터는 <strong>rviz2</strong>에서 <strong>LaserScan Display</strong>로 시각화되며, 이를 통해 로봇 주변 환경의 장애물 정보를 파악할 수 있다. </p>
</li>
<li>
<p>라이다 데이터는 보통 벡터 형식으로 표현된다: <span class="arithmatex"><span class="MathJax_Preview">\mathbf{d} = [d_1, d_2, \dots, d_n]</span><script type="math/tex">\mathbf{d} = [d_1, d_2, \dots, d_n]</script></span>, 여기서 <span class="arithmatex"><span class="MathJax_Preview">d_i</span><script type="math/tex">d_i</script></span>는 로봇으로부터 각도 <span class="arithmatex"><span class="MathJax_Preview">\theta_i</span><script type="math/tex">\theta_i</script></span>에 해당하는 거리이다.</p>
</li>
<li>
<p>각 데이터는 각도 <span class="arithmatex"><span class="MathJax_Preview">\theta</span><script type="math/tex">\theta</script></span>와 거리 <span class="arithmatex"><span class="MathJax_Preview">d</span><script type="math/tex">d</script></span>의 관계로 표현된다:</p>
</li>
</ul>
<p>$$</p>
<p>\mathbf{p}_i = \begin{bmatrix} 
  d_i \cos \theta_i \ 
  d_i \sin \theta_i 
  \end{bmatrix}</p>
<p>$$</p>
<p>여기서 <span class="arithmatex"><span class="MathJax_Preview">i = 1, 2, \dots, n</span><script type="math/tex">i = 1, 2, \dots, n</script></span>이다.</p>
<ul>
<li>
<p><strong>Odometry</strong>: 로봇의 위치 및 자세 데이터를 시각화한다. 위치는 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{x} = [x, y, z]^T</span><script type="math/tex">\mathbf{x} = [x, y, z]^T</script></span>로, 자세는 회전 행렬 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{R} \in SO(3)</span><script type="math/tex">\mathbf{R} \in SO(3)</script></span> 또는 쿼터니언 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{q} = [q_x, q_y, q_z, q_w]</span><script type="math/tex">\mathbf{q} = [q_x, q_y, q_z, q_w]</script></span>로 표현된다.</p>
</li>
<li>
<p><strong>Path</strong>: 로봇의 경로 데이터를 시각화하는데 사용된다. 경로는 여러 개의 좌표로 이루어진 벡터 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{p}_i = [x_i, y_i, z_i]</span><script type="math/tex">\mathbf{p}_i = [x_i, y_i, z_i]</script></span>로 표현된다. 경로 데이터는 로봇의 계획된 이동 경로나 이동한 실제 경로를 표시하는 데 유용하다.</p>
</li>
</ul>
<h4 id="13-qos">1.3 QoS 정책과 시각화의 관계</h4>
<p><strong>Quality of Service(QoS)</strong> 정책은 시뮬레이션 데이터의 전송 품질을 관리한다. 실시간으로 데이터를 시각화할 때 QoS 정책을 적절히 설정하는 것은 데이터 손실을 최소화하고 성능을 최적화하는 데 중요한 역할을 한다. <strong>QoS 정책</strong>의 주요 파라미터는 다음과 같다:</p>
<ul>
<li><strong>Reliability</strong>: 퍼블리셔에서 송신한 데이터가 모두 도착하는지 여부를 설정한다. </li>
<li><strong>Reliable</strong> 모드는 모든 메시지를 보장하지만, 네트워크 지연이 발생할 수 있다.</li>
<li>
<p><strong>Best Effort</strong> 모드는 빠른 전송을 목표로 하지만 데이터 손실이 있을 수 있다.</p>
</li>
<li>
<p><strong>Durability</strong>: 퍼블리셔가 생성한 메시지가 구독자가 연결되기 전에 보존되는지 여부를 설정한다.</p>
</li>
<li><strong>Transient Local</strong> 모드는 새로운 구독자가 연결될 때도 이전 메시지를 받을 수 있도록 설정한다.</li>
<li><strong>Volatile</strong> 모드는 메시지가 보존되지 않고, 최신 메시지만을 구독자에게 제공한다.</li>
</ul>
<p><strong>QoS</strong> 정책에 따라 시각화 성능이 달라질 수 있으며, 실시간 데이터 흐름을 시각화할 때 적절한 정책을 설정하는 것이 중요하다.</p>
<h3 id="2">2. 메시지 타입 및 변환</h3>
<p>시뮬레이션 데이터는 다양한 <strong>ROS2 메시지 타입</strong>으로 표현된다. 각 메시지 타입은 데이터의 특정 구조를 정의하며, 이를 통해 rviz2에서 데이터를 시각화할 수 있다.</p>
<h4 id="21">2.1 메시지 직렬화와 역직렬화</h4>
<p>시뮬레이션 데이터를 퍼블리싱할 때, 메시지 데이터는 직렬화(serialization) 과정을 거쳐 전송된다. 이후 구독자가 해당 데이터를 수신하면 역직렬화(deserialization) 과정을 통해 데이터를 복원한다. 메시지 직렬화 과정은 데이터 전송의 효율성을 높이기 위한 필수적인 단계이다.</p>
<h3 id="3">3. 시뮬레이션 데이터와 시각화의 효율성</h3>
<p>시뮬레이션 데이터를 실시간으로 시각화할 때는 데이터의 양과 복잡도에 따라 시스템 성능이 영향을 받을 수 있다. 따라서 효율적으로 시각화하려면 적절한 데이터 필터링 및 최적화를 적용해야 한다. </p>
<h4 id="31">3.1 데이터 필터링</h4>
<ul>
<li><strong>포인트 클라우드 데이터</strong>(PointCloud2)와 같은 대규모 데이터는 특히 많은 자원을 소모하므로, 시각화 전에 <strong>다운샘플링</strong>이나 <strong>필터링</strong>을 통해 불필요한 데이터를 줄일 수 있다. 포인트 클라우드 필터링은 주로 <strong>voxel grid filter</strong>와 같은 방법을 사용하여 데이터 밀도를 줄이는 방식으로 이루어진다.</li>
</ul>
<p>포인트 클라우드 데이터의 필터링 과정을 수학적으로 표현하면, 주어진 포인트 클라우드 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{P} = \{ \mathbf{p}_1, \mathbf{p}_2, \dots, \mathbf{p}_n \}</span><script type="math/tex">\mathbf{P} = \{ \mathbf{p}_1, \mathbf{p}_2, \dots, \mathbf{p}_n \}</script></span>에서 <strong>voxel grid filter</strong>를 적용하여 필터링된 포인트 클라우드 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{P'} = \{ \mathbf{p'}_1, \mathbf{p'}_2, \dots, \mathbf{p'}_m \}</span><script type="math/tex">\mathbf{P'} = \{ \mathbf{p'}_1, \mathbf{p'}_2, \dots, \mathbf{p'}_m \}</script></span>을 얻을 수 있다. 여기서 <span class="arithmatex"><span class="MathJax_Preview">m \ll n</span><script type="math/tex">m \ll n</script></span>이다.</p>
<h4 id="32">3.2 메시지 압축</h4>
<p>시각화를 위한 대용량 데이터는 네트워크 전송 중에 압축이 필요할 수 있다. ROS2에서는 데이터 전송 시 <strong>TLS (Transport Layer Security)</strong>와 같은 전송 보안 기능과 함께 <strong>메시지 압축</strong> 방식을 사용할 수 있다. 이는 대역폭을 절약하고 데이터 전송 속도를 높이는 데 중요한 역할을 한다. </p>
<ul>
<li>압축된 메시지의 전송은 다음과 같은 과정으로 이루어진다:</li>
<li>메시지 데이터 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{M}</span><script type="math/tex">\mathbf{M}</script></span>을 압축 알고리즘 <span class="arithmatex"><span class="MathJax_Preview">f</span><script type="math/tex">f</script></span>에 적용하여 압축된 데이터 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{M'} = f(\mathbf{M})</span><script type="math/tex">\mathbf{M'} = f(\mathbf{M})</script></span>을 생성한다.</li>
<li>수신 측에서 압축 해제 알고리즘 <span class="arithmatex"><span class="MathJax_Preview">f^{-1}</span><script type="math/tex">f^{-1}</script></span>을 사용하여 원본 데이터를 복원한다: <span class="arithmatex"><span class="MathJax_Preview">\mathbf{M} = f^{-1}(\mathbf{M'})</span><script type="math/tex">\mathbf{M} = f^{-1}(\mathbf{M'})</script></span>.</li>
</ul>
<h4 id="33">3.3 시각화 데이터의 해상도 관리</h4>
<p>시뮬레이션에서 데이터를 고해상도로 시각화할 경우, 시스템 리소스를 많이 소모할 수 있다. 이를 해결하기 위해 시각화 데이터의 해상도를 상황에 맞게 조절하는 방법이 필요하다. 예를 들어, 멀리 있는 객체는 저해상도로 시각화하고, 로봇에 가까운 객체는 고해상도로 시각화하는 방식으로 자원 사용을 최적화할 수 있다.</p>
<h4 id="34-gpu">3.4 GPU 가속 활용</h4>
<p><strong>rviz2</strong>와 같은 시각화 도구는 GPU를 활용하여 시각화 성능을 향상시킬 수 있다. 특히, 3D 데이터인 포인트 클라우드나 로봇 모델의 시각화에서 GPU 가속은 필수적이다. GPU를 사용하면 대량의 데이터를 실시간으로 처리할 수 있으며, 렌더링 속도도 크게 개선된다.</p>
<h4 id="35">3.5 네트워크 최적화</h4>
<p>분산 시스템에서 시뮬레이션 데이터를 시각화할 때 네트워크 최적화는 중요한 요소이다. 네트워크의 대역폭을 효율적으로 사용하기 위해서는 데이터 전송량을 줄이는 방법과 함께 네트워크 지연(Latency)을 최소화하는 전략이 필요하다.</p>
<ul>
<li>네트워크 최적화를 위한 주요 방법:</li>
<li><strong>메시지 전송 주기 조정</strong>: 필요에 따라 데이터 전송 주기를 늘리거나 줄일 수 있다. 예를 들어, 고속으로 변화하는 데이터는 빠르게 퍼블리싱하고, 상대적으로 변화가 적은 데이터는 퍼블리싱 주기를 늘릴 수 있다.</li>
<li><strong>QoS 설정</strong>: 위에서 설명한 QoS 정책을 적절히 설정하여, 네트워크 트래픽을 제어하고 데이터 손실을 방지할 수 있다.</li>
</ul>
<h3 id="4-3d">4. 3D 데이터 시각화와 좌표 변환</h3>
<p>시뮬레이션 데이터 중 특히 3D 데이터는 로봇의 위치, 자세, 센서의 출력 등을 포함한다. 이를 정확하게 시각화하려면 좌표 변환에 대한 이해가 필요하다. ROS2에서 3D 데이터는 보통 서로 다른 좌표계에서 제공되며, 이를 하나의 통합된 프레임으로 변환하여 시각화해야 한다.</p>
<h4 id="41">4.1 좌표 변환의 개념</h4>
<p>ROS2에서는 <strong>TF2</strong>라는 프레임워크를 사용하여 좌표 변환을 처리한다. <strong>TF2</strong>는 여러 프레임 간의 관계를 관리하며, 시각화를 위해 필요한 데이터는 각 프레임의 변환 정보를 이용하여 올바르게 표현된다.</p>
<ul>
<li>예를 들어, 로봇의 센서가 위치한 <strong>sensor_frame</strong>에서 얻은 데이터를 로봇의 <strong>base_link</strong> 프레임으로 변환하려면 다음과 같은 변환 행렬 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{T}_{\text{sensor} \to \text{base}}</span><script type="math/tex">\mathbf{T}_{\text{sensor} \to \text{base}}</script></span>을 적용해야 한다:</li>
</ul>
<p>$$</p>
<p>\mathbf{p}<em>{\text{base}} = \mathbf{T}</em>{\text{sensor} \to \text{base}} \mathbf{p}_{\text{sensor}}</p>
<p>$$</p>
<p>여기서 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{T}_{\text{sensor} \to \text{base}}</span><script type="math/tex">\mathbf{T}_{\text{sensor} \to \text{base}}</script></span>는 회전과 병진 변환을 포함하는 4x4 변환 행렬이다.</p>
<h4 id="42">4.2 좌표 변환 시각화</h4>
<p><strong>rviz2</strong>에서 TF2를 활용하여 좌표 변환을 시각화할 수 있다. 각 프레임 간의 관계를 선으로 연결하여 로봇의 여러 프레임을 한눈에 파악할 수 있으며, 이를 통해 센서 데이터가 어느 좌표계에서 나온 것인지 직관적으로 확인할 수 있다. </p>
<h3 id="5-ros2-gazebo">5. ROS2와 Gazebo 시뮬레이션 데이터 시각화</h3>
<p>ROS2와 <strong>Gazebo</strong> 시뮬레이터는 로봇 개발에서 자주 함께 사용되며, Gazebo에서 생성된 시뮬레이션 데이터를 <strong>rviz2</strong>에서 시각화하는 것은 매우 유용하다. Gazebo는 3D 시뮬레이션 환경에서 로봇의 동작을 테스트할 수 있도록 해주며, ROS2와의 통합을 통해 시뮬레이션된 데이터를 실시간으로 처리할 수 있다.</p>
<h4 id="51-gazebo-ros2">5.1 Gazebo와 ROS2 간 통신</h4>
<p>Gazebo에서 생성된 시뮬레이션 데이터는 ROS2 메시지로 변환되어 퍼블리싱된다. 이를 통해 rviz2에서 Gazebo의 데이터를 실시간으로 시각화할 수 있다. 일반적으로 Gazebo에서 ROS2와 통신하기 위해서는 <strong>ROS2 플러그인</strong>을 사용한다. 이 플러그인은 Gazebo의 센서 데이터를 ROS2 메시지 형식으로 변환해준다.</p>
<p>주요 통신 흐름은 다음과 같다:</p>
<div class="mermaid">graph TD;
    Gazebo --&gt;|ROS2 Plugin| ROS2[ROS2 Nodes];
    ROS2 --&gt;|Messages| rviz2[rviz2 Visualization];
</div>
<p>Gazebo에서 발생하는 각종 데이터 (센서 데이터, 로봇 상태 등)는 ROS2 플러그인을 통해 ROS2 메시지로 변환되어 퍼블리싱되고, rviz2에서 이를 구독하여 시각화하게 된다.</p>
<h4 id="52-gazebo">5.2 Gazebo 시뮬레이션 데이터의 종류</h4>
<p>Gazebo는 다양한 형태의 시뮬레이션 데이터를 제공한다. 이 데이터를 rviz2에서 시각화하는 것은 실제 하드웨어를 연결하지 않고도 로봇의 동작을 검증하고 분석하는 데 유용하다. Gazebo에서 제공하는 주요 데이터는 다음과 같다:</p>
<ul>
<li>
<p><strong>센서 데이터</strong>: Gazebo에 포함된 각종 센서(예: 카메라, LiDAR, IMU)에서 생성된 데이터를 ROS2 메시지로 변환하여 퍼블리시한다. 이러한 센서 데이터를 rviz2에서 실시간으로 시각화할 수 있다.</p>
</li>
<li>
<p><strong>로봇 상태</strong>: 로봇의 위치, 속도, 가속도, 조인트 각도 등과 같은 물리적 상태 데이터를 포함한다. 이 데이터를 통해 로봇의 움직임과 동작을 시각화할 수 있다.</p>
</li>
</ul>
<h4 id="53-gazebo">5.3 Gazebo 시뮬레이션 데이터의 시각화</h4>
<p>Gazebo와 ROS2의 통합을 통해 시뮬레이션된 데이터를 rviz2에서 시각화할 때, 각 데이터 유형에 맞는 Display 설정을 해야 한다. 예를 들어, Gazebo에서 퍼블리싱한 <strong>LaserScan</strong> 데이터를 시각화하기 위해서는 rviz2에서 <strong>LaserScan Display</strong>를 설정해야 한다.</p>
<ul>
<li>
<p><strong>LaserScan</strong>: Gazebo에서 시뮬레이션된 라이다 데이터를 시각화할 수 있다. 이를 통해 로봇이 감지한 장애물 정보를 실시간으로 확인할 수 있다.</p>
</li>
<li>
<p><strong>IMU 데이터</strong>: Gazebo에서 시뮬레이션된 IMU(관성 측정 장치) 데이터를 퍼블리싱하면 rviz2에서 로봇의 자세 변화를 시각화할 수 있다. IMU 데이터는 보통 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{q} = [q_x, q_y, q_z, q_w]</span><script type="math/tex">\mathbf{q} = [q_x, q_y, q_z, q_w]</script></span>로 표현되는 쿼터니언 형식으로 제공되며, 이를 통해 3차원 회전 정보를 시각적으로 확인할 수 있다.</p>
</li>
<li>
<p><strong>PointCloud2</strong>: 3D 센서에서 생성된 포인트 클라우드 데이터를 시각화할 수 있다. Gazebo에서 생성된 3D 포인트 클라우드 데이터는 rviz2에서 실시간으로 표현되며, 로봇 주변 환경의 3차원 구조를 확인하는 데 유용하다.</p>
</li>
</ul>
<h4 id="54">5.4 시뮬레이션 시간과 실제 시간의 차이</h4>
<p>Gazebo에서 시뮬레이션을 실행할 때, 시뮬레이션 시간과 실제 시간은 서로 다를 수 있다. 이를 ROS2와 연동할 때는 <strong>시뮬레이션 시간</strong>을 기반으로 데이터가 퍼블리싱되기 때문에, ROS2 노드에서 이를 적절히 처리해야 한다. ROS2는 시뮬레이션 시간과 시스템 시간을 구분하는 기능을 제공하며, 이를 사용하여 시각화할 데이터를 정확히 처리할 수 있다.</p>
<ul>
<li>시뮬레이션 시간 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{t}_{\text{sim}}</span><script type="math/tex">\mathbf{t}_{\text{sim}}</script></span>은 실제 시간 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{t}_{\text{real}}</span><script type="math/tex">\mathbf{t}_{\text{real}}</script></span>과 다를 수 있으며, ROS2의 각 노드에서 이 차이를 고려해야 한다.</li>
</ul>
<h4 id="55-gazebo">5.5 Gazebo에서의 좌표 변환과 시각화</h4>
<p>Gazebo 시뮬레이터에서 사용되는 좌표계와 ROS2에서 사용하는 좌표계 간의 변환이 필요할 때, <strong>TF2</strong>를 사용하여 이를 처리할 수 있다. Gazebo에서 로봇의 위치 및 자세 정보를 <strong>base_link</strong> 또는 <strong>odom</strong>과 같은 프레임으로 변환하여 rviz2에서 시각화할 수 있다.</p>
<p>예를 들어, Gazebo에서 얻은 로봇의 위치 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{p}_{\text{gazebo}} = [x, y, z]</span><script type="math/tex">\mathbf{p}_{\text{gazebo}} = [x, y, z]</script></span>를 ROS2에서 사용하는 좌표계로 변환하려면 TF2의 변환 행렬 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{T}_{\text{gazebo} \to \text{ros}}</span><script type="math/tex">\mathbf{T}_{\text{gazebo} \to \text{ros}}</script></span>을 적용하여 다음과 같이 변환할 수 있다:</p>
<p>$$</p>
<p>\mathbf{p}<em>{\text{ros}} = \mathbf{T}</em>{\text{gazebo} \to \text{ros}} \mathbf{p}_{\text{gazebo}}</p>
<p>$$</p>
<h4 id="56-gazebo">5.6 Gazebo에서의 로봇 모델 시각화</h4>
<p>Gazebo는 로봇 모델을 시뮬레이션 환경에 배치하여 시각화할 수 있는 기능을 제공한다. 이 로봇 모델은 <strong>URDF (Unified Robot Description Format)</strong>나 <strong>SDF (Simulation Description Format)</strong>로 정의된다. 이러한 형식으로 정의된 로봇 모델을 Gazebo에서 불러와 시뮬레이션할 수 있으며, 이를 rviz2에서 실시간으로 시각화할 수 있다.</p>
<h5 id="561-urdfsdf">5.6.1 URDF/SDF를 통한 로봇 모델링</h5>
<p>ROS2와 Gazebo의 통합 시, 로봇의 모델을 표현하기 위해 <strong>URDF</strong> 또는 <strong>SDF</strong> 파일을 사용한다. URDF는 주로 로봇의 기하학적 구조, 조인트 정보, 센서 배치 등을 기술하며, SDF는 URDF와 비슷하지만 좀 더 상세한 시뮬레이션 요소(물리 엔진 설정 등)를 포함한다.</p>
<ul>
<li><strong>URDF</strong> 형식에서의 로봇 모델 표현:</li>
<li>링크의 기하학적 형상 및 조인트 위치를 정의하여 로봇의 물리적 구조를 나타낸다.</li>
<li>
<p>센서의 위치와 좌표계를 정의하여 로봇의 센서 데이터를 정확히 시뮬레이션한다.</p>
</li>
<li>
<p><strong>SDF</strong>는 URDF보다 더 강력한 기능을 제공하며, 특히 Gazebo에서의 물리 시뮬레이션에 적합한 구조를 가지고 있다. 예를 들어, 물리 엔진의 마찰, 질량, 중력 설정 등을 포함한다.</p>
</li>
</ul>
<h5 id="562-urdfsdf-rviz2">5.6.2 URDF/SDF와 rviz2 연동</h5>
<p>로봇의 URDF 또는 SDF 모델이 정의되면, 이 모델을 rviz2에서 시각화하여 로봇의 상태를 직관적으로 파악할 수 있다. rviz2에서 로봇 모델을 불러오기 위해서는 <strong>RobotModel</strong> Display를 추가하고, 로봇 모델이 표현될 프레임을 설정한다.</p>
<p>로봇 모델이 rviz2에서 정확하게 시각화되려면, TF2를 사용하여 로봇의 각 링크와 조인트에 대한 좌표 변환이 적절하게 이루어져야 한다. 로봇의 각 링크에 대한 변환 행렬 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{T}_{\text{link}_i}</span><script type="math/tex">\mathbf{T}_{\text{link}_i}</script></span>는 TF2를 통해 정의되며, rviz2에서 이를 시각적으로 확인할 수 있다.</p>
<h5 id="563-gazebo-ros2-urdfsdf">5.6.3 Gazebo와 ROS2의 URDF/SDF 데이터 처리 흐름</h5>
<p>Gazebo에서 정의된 URDF/SDF 로봇 모델은 ROS2 노드와 상호작용할 수 있도록 설정된다. ROS2의 각 노드는 해당 로봇 모델을 기반으로 데이터를 퍼블리싱하거나 구독할 수 있으며, rviz2에서 이를 시각화할 수 있다.</p>
<div class="mermaid">graph LR;
    URDF/SDF --&gt;|Gazebo| Gazebo_Sim[Gazebo Simulation];
    Gazebo_Sim --&gt;|Publish| ROS2_Nodes[ROS2 Nodes];
    ROS2_Nodes --&gt;|Visualize| rviz2[rviz2];
</div>
<h4 id="57-gazebo">5.7 Gazebo에서의 물리 시뮬레이션 시각화</h4>
<p>Gazebo는 로봇의 물리적 상호작용을 시뮬레이션할 수 있는 강력한 물리 엔진을 내장하고 있다. 이를 통해 충돌 처리, 마찰, 관성 등과 같은 물리적 효과를 시뮬레이션할 수 있으며, 이러한 데이터를 rviz2에서 실시간으로 시각화할 수 있다.</p>
<h5 id="571">5.7.1 물리 엔진의 역할</h5>
<p>Gazebo에서 사용되는 주요 물리 엔진은 다음과 같다:</p>
<ul>
<li><strong>ODE (Open Dynamics Engine)</strong>: Gazebo에서 기본적으로 사용하는 물리 엔진으로, 로봇의 충돌 처리와 강체의 움직임을 시뮬레이션한다.</li>
<li><strong>Bullet</strong>: 고속 충돌 처리와 물리적 상호작용을 시뮬레이션하는 물리 엔진으로, 특히 고성능 로봇 시뮬레이션에 적합한다.</li>
</ul>
<p>각 물리 엔진은 로봇의 동작과 환경과의 상호작용을 시뮬레이션하는 데 사용되며, 이를 통해 로봇의 실제 동작을 테스트할 수 있다.</p>
<h5 id="572">5.7.2 충돌 데이터 시각화</h5>
<p>Gazebo에서 충돌 데이터를 시각화하려면, 로봇 모델의 충돌 지점을 시각화할 수 있는 방법을 사용한다. 충돌 데이터는 로봇의 각 링크와 물체 간의 충돌 여부와 충돌 강도를 나타낸다. 이러한 데이터는 <strong>rviz2</strong>에서 실시간으로 확인할 수 있으며, 이를 통해 로봇의 동작이 의도한 대로 이루어지는지 검증할 수 있다.</p>
<h4 id="58-gazebo">5.8 Gazebo 시뮬레이션에서의 센서 데이터 시각화</h4>
<p>Gazebo는 다양한 센서를 시뮬레이션할 수 있으며, 이 데이터를 ROS2 노드로 퍼블리싱하여 rviz2에서 시각화할 수 있다. 주로 사용되는 센서로는 <strong>LiDAR</strong>, <strong>카메라</strong>, <strong>IMU</strong>, <strong>GPS</strong> 등이 있다. 각 센서 데이터는 특정 메시지 타입으로 변환되어 퍼블리싱되며, rviz2에서는 해당 데이터에 맞는 Display를 통해 시각화된다.</p>
<h5 id="581-lidar-laserscan">5.8.1 LiDAR (LaserScan) 시각화</h5>
<p>LiDAR 데이터는 주로 <strong>LaserScan</strong> 메시지 타입으로 퍼블리싱된다. Gazebo에서 시뮬레이션된 LiDAR는 2D 또는 3D 스캔 데이터를 제공하며, 이는 로봇 주변 환경의 거리 정보를 포함하고 있다.</p>
<ul>
<li><strong>LaserScan</strong> 데이터는 벡터 형식으로 표현된다: </li>
</ul>
<p>$$</p>
<p>\mathbf{d} = [d_1, d_2, \dots, d_n]</p>
<p>$$</p>
<p>여기서 <span class="arithmatex"><span class="MathJax_Preview">d_i</span><script type="math/tex">d_i</script></span>는 로봇으로부터의 거리이며, <span class="arithmatex"><span class="MathJax_Preview">\theta_i</span><script type="math/tex">\theta_i</script></span>는 각도이다.</p>
<p>rviz2에서 LaserScan 데이터를 시각화하면, 로봇이 인식한 주변 환경을 실시간으로 확인할 수 있다. 이 데이터는 로봇의 장애물 회피, 환경 매핑 등에 사용된다.</p>
<h5 id="582">5.8.2 카메라 데이터 시각화</h5>
<p>Gazebo에서 시뮬레이션된 카메라 데이터는 ROS2의 <strong>Image</strong> 메시지 타입으로 퍼블리싱된다. 이 데이터는 rviz2에서 <strong>Image</strong> Display를 사용하여 시각화할 수 있다. 카메라 센서를 사용하면 로봇이 시뮬레이션 환경에서 보는 영상을 실시간으로 확인할 수 있으며, 이를 통해 시각적 피드백을 활용한 로봇 제어를 할 수 있다.</p>
<ul>
<li>카메라 데이터는 2D 이미지 배열로 표현되며, 각 픽셀은 RGB 값을 갖는다:</li>
</ul>
<p>$$</p>
<p>\mathbf{I} = { \mathbf{I}_{ij} \mid i = 1, \dots, h; j = 1, \dots, w }</p>
<p>$$</p>
<p>여기서 <span class="arithmatex"><span class="MathJax_Preview">h</span><script type="math/tex">h</script></span>는 이미지의 높이, <span class="arithmatex"><span class="MathJax_Preview">w</span><script type="math/tex">w</script></span>는 이미지의 너비, <span class="arithmatex"><span class="MathJax_Preview">\mathbf{I}_{ij}</span><script type="math/tex">\mathbf{I}_{ij}</script></span>는 해당 좌표의 픽셀 값이다.</p>
<h5 id="583-imu">5.8.3 IMU 데이터 시각화</h5>
<p>IMU(Inertial Measurement Unit) 데이터는 <strong>sensor_msgs/Imu</strong> 메시지 타입으로 퍼블리싱되며, 이는 로봇의 가속도, 각속도, 자세(오리엔테이션) 정보를 포함한다. IMU 데이터는 주로 로봇의 균형 유지나 동작 제어에 사용된다.</p>
<ul>
<li>IMU 데이터는 가속도 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{a} = [a_x, a_y, a_z]</span><script type="math/tex">\mathbf{a} = [a_x, a_y, a_z]</script></span>, 각속도 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{\omega} = [\omega_x, \omega_y, \omega_z]</span><script type="math/tex">\mathbf{\omega} = [\omega_x, \omega_y, \omega_z]</script></span>, 그리고 쿼터니언 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{q} = [q_x, q_y, q_z, q_w]</span><script type="math/tex">\mathbf{q} = [q_x, q_y, q_z, q_w]</script></span>로 표현된다.</li>
</ul>
<p>rviz2에서 IMU 데이터를 시각화하면 로봇의 자세와 동작을 실시간으로 확인할 수 있으며, 이를 통해 로봇의 안정성을 분석할 수 있다.</p>
<h5 id="584-gps">5.8.4 GPS 데이터 시각화</h5>
<p>Gazebo에서 시뮬레이션된 GPS 데이터는 <strong>NavSatFix</strong> 메시지 타입으로 퍼블리싱되며, 이는 로봇의 전역 위치 정보를 나타낸다. GPS 데이터를 통해 로봇의 위치를 rviz2에서 시각화할 수 있으며, 이를 기반으로 로봇의 경로를 계획하거나 추적할 수 있다.</p>
<ul>
<li>GPS 데이터는 위도, 경도, 고도 <span class="arithmatex"><span class="MathJax_Preview">(\phi, \lambda, h)</span><script type="math/tex">(\phi, \lambda, h)</script></span>로 표현된다:</li>
</ul>
<p>$$</p>
<p>\mathbf{p}_{\text{GPS}} = [\phi, \lambda, h]</p>
<p>$$</p>
<p>여기서 <span class="arithmatex"><span class="MathJax_Preview">\phi</span><script type="math/tex">\phi</script></span>는 위도, <span class="arithmatex"><span class="MathJax_Preview">\lambda</span><script type="math/tex">\lambda</script></span>는 경도, <span class="arithmatex"><span class="MathJax_Preview">h</span><script type="math/tex">h</script></span>는 고도이다.</p>
<p>GPS 데이터는 실시간으로 로봇의 위치 변화를 시각적으로 확인할 수 있으며, 이를 통해 로봇의 이동 경로를 추적하고 분석할 수 있다.</p>
<h4 id="59">5.9 실시간 시뮬레이션 데이터 분석</h4>
<p>rviz2를 통해 시뮬레이션 데이터를 시각화하는 것 외에도, 실시간으로 데이터를 분석하고 문제를 해결하는 것이 중요하다. 시각화 도구를 사용하여 실시간으로 데이터를 모니터링하고, 이를 기반으로 로봇의 동작을 수정할 수 있다.</p>
<h5 id="591">5.9.1 실시간 경로 추적</h5>
<p>로봇의 경로 데이터를 실시간으로 시각화하면, 로봇이 계획된 경로를 얼마나 정확하게 따르고 있는지 분석할 수 있다. 이때, 경로 데이터는 <strong>nav_msgs/Path</strong> 메시지 타입으로 퍼블리싱되며, 경로는 일련의 위치 좌표로 구성된다:</p>
<p>$$</p>
<p>\mathbf{P} = { \mathbf{p}_1, \mathbf{p}_2, \dots, \mathbf{p}_n }</p>
<p>$$</p>
<p>여기서 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{p}_i = [x_i, y_i, z_i]</span><script type="math/tex">\mathbf{p}_i = [x_i, y_i, z_i]</script></span>는 로봇의 특정 시점에서의 위치를 나타낸다. rviz2에서 경로 데이터를 시각화하면, 로봇의 실시간 경로 추적 성능을 시각적으로 확인할 수 있다.</p>
<h5 id="592">5.9.2 로봇 상태 모니터링</h5>
<p>실시간으로 로봇의 상태를 모니터링하는 것은 로봇의 동작을 분석하고 문제가 발생했을 때 신속하게 대처하는 데 필수적이다. 로봇의 상태는 <strong>odometry</strong>, <strong>IMU</strong>, <strong>GPS</strong> 데이터 등을 포함하며, 이를 통해 로봇의 자세, 속도, 위치 등을 실시간으로 확인할 수 있다.</p>
<h5 id="593">5.9.3 시뮬레이션 성능 최적화</h5>
<p>시뮬레이션 데이터를 실시간으로 시각화할 때 성능 최적화도 고려해야 한다. 특히 복잡한 환경에서 많은 데이터를 시각화할 경우, 시스템의 성능 저하가 발생할 수 있다. 이를 방지하기 위해 데이터 전송 주기 조정, QoS 설정, 데이터 필터링 등의 방법을 사용하여 성능을 최적화할 수 있다.</p>
<br/>
<div aria-label="navigation" class="row wm-article-nav-buttons" role="navigation">
<div class="wm-article-nav pull-right">
<a class="btn btn-xs btn-default pull-right" href="../2202/">
        Next
        <i aria-hidden="true" class="fa fa-chevron-right"></i>
</a>
<a class="btn btn-xs btn-link" href="../2202/">
        로봇 및 센서 데이터 시각화
      </a>
</div>
<div class="wm-article-nav">
<a class="btn btn-xs btn-default pull-left" href="../../chapter_21/2106/">
<i aria-hidden="true" class="fa fa-chevron-left"></i>
        Previous</a><a class="btn btn-xs btn-link" href="../../chapter_21/2106/">
        TF2의 성능 최적화
      </a>
</div>
</div>
<br/>
</div>
<footer class="container-fluid wm-page-content">
<p>Documentation built with <a href="https://www.mkdocs.org/">MkDocs</a> using <a href="https://github.com/gristlabs/mkdocs-windmill">Windmill</a> theme by Grist Labs.</p>
</footer>
<script type="module">import mermaid from "https://unpkg.com/mermaid@10.4.0/dist/mermaid.esm.min.mjs";
mermaid.initialize({});</script></body>
</html>