<!DOCTYPE html>
<html lang="en">
<head>
  
  
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    
    
    <link rel="canonical" href="https://booiljung.github.io/robot/autonomous_robot_with_humble_fastlivo_mid360/chapter_02/0202/">
    <link rel="shortcut icon" href="../../../../img/favicon.ico">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" />
    <title>LiDAR 기반의 자율 주행 기술 개요 - 실험 도서관</title>
    <link href="../../../../css/bootstrap-3.3.7.min.css" rel="stylesheet">
    <link href="../../../../css/font-awesome-4.7.0.css" rel="stylesheet">
    <link href="../../../../css/base.css" rel="stylesheet">
    <link rel="stylesheet" href="../../../../css/highlight.css">
    <link href="../../../../css/custom.css" rel="stylesheet">
    <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.3.0/respond.min.js"></script>
    <![endif]-->

    <script src="../../../../js/jquery-3.2.1.min.js"></script>
    <script src="../../../../js/bootstrap-3.3.7.min.js"></script>
    <script src="../../../../js/highlight.pack.js"></script>
    
    <base target="_top">
    <script>
      var base_url = '../../../..';
      var is_top_frame = false;
        
        var pageToc = [
          {title: "LiDAR\uc758 \uc6d0\ub9ac", url: "#_top", children: [
          ]},
          {title: "LiDAR\uc758 \ud2b9\uc9d5", url: "#lidar_1", children: [
          ]},
          {title: "LiDAR SLAM\uc758 \uac1c\ub150", url: "#lidar-slam", children: [
          ]},
          {title: "LiDAR \ub370\uc774\ud130 \ucc98\ub9ac", url: "#lidar_2", children: [
          ]},
          {title: "3D \ud3ec\uc778\ud2b8 \ud074\ub77c\uc6b0\ub4dc", url: "#3d", children: [
          ]},
          {title: "\uc790\uc728 \uc8fc\ud589\uc5d0\uc11c\uc758 LiDAR \uc751\uc6a9", url: "#lidar_3", children: [
          ]},
          {title: "LiDAR\uc758 \uc7a5\ub2e8\uc810", url: "#lidar_4", children: [
              {title: "LiDAR\uc758 \uc7a5\uc810", url: "#lidar_5" },
              {title: "LiDAR\uc758 \ub2e8\uc810", url: "#lidar_6" },
          ]},
          {title: "LiDAR \ub370\uc774\ud130\uc758 \ud45c\ud604 \ubc0f \ud65c\uc6a9", url: "#lidar_7", children: [
              {title: "\ud3ec\uc778\ud2b8 \ud074\ub77c\uc6b0\ub4dc\uc758 \uc88c\ud45c\uacc4", url: "#_1" },
              {title: "\ud3ec\uc778\ud2b8 \ud074\ub77c\uc6b0\ub4dc\uc758 \uc815\ud569(Registration)", url: "#registration" },
          ]},
          {title: "LiDAR SLAM\uc758 \uad6c\uc131 \uc694\uc18c", url: "#lidar-slam_1", children: [
          ]},
          {title: "LiDAR \uae30\ubc18 SLAM\uc758 \uc8fc\uc694 \uc54c\uace0\ub9ac\uc998", url: "#lidar-slam_2", children: [
              {title: "1. Iterative Closest Point (ICP)", url: "#1-iterative-closest-point-icp" },
              {title: "2. NDT (Normal Distributions Transform)", url: "#2-ndt-normal-distributions-transform" },
              {title: "3. Graph-Based SLAM", url: "#3-graph-based-slam" },
              {title: "4. LOAM (Lidar Odometry and Mapping)", url: "#4-loam-lidar-odometry-and-mapping" },
          ]},
          {title: "LiDAR SLAM\uc758 \ucd5c\uc2e0 \ub3d9\ud5a5", url: "#lidar-slam_3", children: [
              {title: "1. \ub525\ub7ec\ub2dd \uae30\ubc18 SLAM", url: "#1-slam" },
              {title: "2. \uba40\ud2f0\uc13c\uc11c \uc735\ud569 SLAM", url: "#2-slam" },
              {title: "3. \uc2e4\uc2dc\uac04 \ucd5c\uc801\ud654 \uae30\ubc95", url: "#3" },
              {title: "4. Sparse vs. Dense SLAM", url: "#4-sparse-vs-dense-slam" },
          ]},
          {title: "LiDAR SLAM\uc758 \uc801\uc6a9 \uc0ac\ub840", url: "#lidar-slam_4", children: [
              {title: "1. \uc790\uc728 \uc8fc\ud589 \ucc28\ub7c9", url: "#1" },
              {title: "2. \uc2e4\ub0b4 \uc790\uc728 \uc8fc\ud589 \ub85c\ubd07", url: "#2" },
              {title: "3. \ub4dc\ub860 \ubc0f \ubb34\uc778 \ud56d\uacf5\uae30(UAV)", url: "#3-uav" },
          ]},
          {title: "LiDAR SLAM\uc758 \ubbf8\ub798 \uc804\ub9dd", url: "#lidar-slam_5", children: [
              {title: "\uc13c\uc11c \uae30\uc220\uc758 \ubc1c\uc804", url: "#_9" },
              {title: "\ub525\ub7ec\ub2dd\uacfc\uc758 \uc735\ud569", url: "#_10" },
              {title: "\uba40\ud2f0\uc13c\uc11c \uc735\ud569\uc758 \ud655\ub300", url: "#_11" },
          ]},
        ];

    </script>
    <script src="../../../../js/base.js"></script>
      <script src="../../../../js/google_analytics.js"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML"></script>
      <script src="https://www.googletagmanager.com/gtag/js?id=G-3F4LHCTF88"></script> 
</head>

<body>
<script>
if (is_top_frame) { $('body').addClass('wm-top-page'); }
</script>



<div class="container-fluid wm-page-content">
  <a name="_top"></a>
    

    
    
      
    

  <div class="row wm-article-nav-buttons" role="navigation" aria-label="navigation">
    
    <div class="wm-article-nav pull-right">
      <a href="../0203/" class="btn btn-xs btn-default pull-right">
        Next
        <i class="fa fa-chevron-right" aria-hidden="true"></i>
      </a>
      <a href="../0203/" class="btn btn-xs btn-link">
        FAST-LIVO 알고리즘 개요
      </a>
    </div>
    
    <div class="wm-article-nav">
      <a href="../0201/" class="btn btn-xs btn-default pull-left">
        <i class="fa fa-chevron-left" aria-hidden="true"></i>
        Previous</a><a href="../0201/" class="btn btn-xs btn-link">
        LiDAR SLAM의 기본 개념
      </a>
    </div>
    
  </div>

    

    <p>LiDAR(Light Detection and Ranging)는 레이저 펄스를 이용해 주변 환경의 거리를 측정하고, 이를 통해 3D 지도를 구축하는 기술로, 자율 주행 시스템에서 중요한 역할을 한다. 특히, SLAM(Simultaneous Localization and Mapping)과 같은 알고리즘을 통해 로봇이 스스로 자신의 위치를 추정하고 환경을 인식할 수 있게 한다.</p>
<h2 id="lidar">LiDAR의 원리</h2>
<p>LiDAR는 레이저를 발사하고 그 빛이 물체에 반사되어 되돌아오는 시간을 측정하여 거리를 계산한다. 이 거리는 다음 식을 통해 계산된다:</p>
<div class="arithmatex">
<div class="MathJax_Preview">
d = \frac{c \cdot t}{2}
</div>
<script type="math/tex; mode=display">
d = \frac{c \cdot t}{2}
</script>
</div>
<p>여기서,<br />
<span class="arithmatex"><span class="MathJax_Preview">d</span><script type="math/tex">d</script></span>는 측정된 거리,<br />
<span class="arithmatex"><span class="MathJax_Preview">c</span><script type="math/tex">c</script></span>는 빛의 속도 (<span class="arithmatex"><span class="MathJax_Preview">\approx 3 \times 10^8 \, \text{m/s}</span><script type="math/tex">\approx 3 \times 10^8 \, \text{m/s}</script></span>),<br />
<span class="arithmatex"><span class="MathJax_Preview">t</span><script type="math/tex">t</script></span>는 레이저가 발사되어 되돌아오기까지의 시간이다.</p>
<p>LiDAR는 매우 높은 정확도로 환경의 포인트 클라우드를 생성하며, 이를 바탕으로 로봇은 주변의 3D 지도를 실시간으로 만들 수 있다.</p>
<h2 id="lidar_1">LiDAR의 특징</h2>
<p>LiDAR는 다양한 장점과 특징을 가지고 있다:</p>
<ul>
<li><strong>정확한 거리 측정</strong>: 광학 센서를 사용하여 매우 정확한 거리 측정이 가능하다.</li>
<li><strong>넓은 시야각</strong>: 360도 회전을 통해 광범위한 환경을 스캔할 수 있다.</li>
<li><strong>고해상도</strong>: 많은 포인트를 빠르게 측정해 고해상도의 환경 정보를 제공한다.</li>
<li><strong>실시간 데이터 수집</strong>: 자율 주행 상황에서 실시간으로 데이터를 수집하고 처리할 수 있다.</li>
</ul>
<p>이러한 특징 덕분에 LiDAR는 자율 주행 차량이나 로봇의 SLAM(Simultaneous Localization and Mapping) 구현에 필수적인 기술로 자리 잡고 있다.</p>
<h2 id="lidar-slam">LiDAR SLAM의 개념</h2>
<p>SLAM은 로봇이 처음 보는 환경에서 이동하면서 자신의 위치를 추정하고, 동시에 그 환경의 지도를 작성하는 문제를 해결하는 알고리즘이다. SLAM은 크게 두 가지 중요한 과정으로 나눌 수 있다:</p>
<ol>
<li><strong>로봇 위치 추정(Localization)</strong>: 로봇이 현재 환경에서 자신의 위치를 실시간으로 추정한다.</li>
<li><strong>지도 작성(Mapping)</strong>: 로봇이 환경의 3D 지도를 작성하고 이를 업데이트한다.</li>
</ol>
<p>이를 통해 자율 주행 로봇은 GPS가 없는 환경에서도 자신이 어디에 있는지 인식하고 목적지로 향할 수 있다.</p>
<p>LiDAR를 활용한 SLAM 알고리즘에서는 환경의 포인트 클라우드 데이터를 바탕으로 로봇의 위치를 추정하고, 3D 지도를 만들어 나가는 과정이 반복된다. SLAM에서 LiDAR가 중요한 이유는, 카메라나 다른 센서보다 더 정밀하고 안정적으로 환경의 3D 구조를 파악할 수 있기 때문이다.</p>
<h2 id="lidar_2">LiDAR 데이터 처리</h2>
<p>LiDAR는 초당 수십만 개의 포인트 데이터를 수집하며, 이를 효율적으로 처리하기 위해 다양한 알고리즘이 사용된다. 가장 일반적으로 사용되는 데이터 처리 과정은 다음과 같다:</p>
<ol>
<li><strong>포인트 클라우드 필터링</strong>: 수집된 포인트 클라우드는 노이즈와 불필요한 데이터를 포함할 수 있다. 이를 필터링해 유효한 데이터만을 남기는 과정이다.</li>
<li><strong>특징 추출(Feature Extraction)</strong>: 포인트 클라우드에서 로봇이 유의미하게 인식할 수 있는 특징을 추출한다. 이 특징은 보통 키포인트(Keypoint)나 표면 특징(Surface Feature)으로 나뉜다.</li>
<li><strong>매칭(Matching)</strong>: 추출된 특징을 이전 프레임의 데이터와 매칭시켜 로봇의 이동 경로를 계산한다. 이를 통해 로봇이 어느 방향으로 얼마만큼 이동했는지를 알 수 있다.</li>
</ol>
<p>포인트 클라우드를 처리하는 알고리즘은 보통 매 프레임마다 실행되며, 자율 주행 로봇의 실시간 주행 성능을 크게 좌우한다.</p>
<h2 id="3d">3D 포인트 클라우드</h2>
<p>LiDAR는 3D 공간에서 여러 포인트들의 집합인 포인트 클라우드를 생성한다. 포인트 클라우드 데이터는 로봇의 환경을 3차원으로 표현하는 중요한 자료가 된다. 이 포인트 클라우드는 수학적으로 다음과 같이 표현될 수 있다:</p>
<div class="arithmatex">
<div class="MathJax_Preview">
\mathbf{P} = \{\mathbf{p}_1, \mathbf{p}_2, \dots, \mathbf{p}_n\}
</div>
<script type="math/tex; mode=display">
\mathbf{P} = \{\mathbf{p}_1, \mathbf{p}_2, \dots, \mathbf{p}_n\}
</script>
</div>
<p>여기서,<br />
<span class="arithmatex"><span class="MathJax_Preview">\mathbf{P}</span><script type="math/tex">\mathbf{P}</script></span>는 포인트 클라우드,<br />
<span class="arithmatex"><span class="MathJax_Preview">\mathbf{p}_i = (x_i, y_i, z_i)</span><script type="math/tex">\mathbf{p}_i = (x_i, y_i, z_i)</script></span>는 각 포인트의 3차원 좌표를 의미한다.</p>
<p>이러한 포인트 클라우드는 SLAM 알고리즘의 입력으로 사용되며, 매 프레임마다 업데이트된다. 이를 통해 로봇은 3D 환경에서 자신의 위치와 지도를 동시에 추정할 수 있다.</p>
<h2 id="lidar_3">자율 주행에서의 LiDAR 응용</h2>
<p>LiDAR는 자율 주행 차량의 인식 시스템에서 핵심적인 역할을 한다. 자율 주행 시스템에서 LiDAR는 주변 환경의 물체를 감지하고, 그 거리와 속도를 계산하는 데 사용된다. 이러한 정보는 주로 다음과 같은 목적으로 사용된다:</p>
<ul>
<li><strong>장애물 회피</strong>: LiDAR를 통해 자율 주행 로봇은 주변의 장애물을 실시간으로 감지하고 이를 피하는 경로를 계산할 수 있다.</li>
<li><strong>차선 인식 및 유지</strong>: 도로에서 자율 주행 차량은 LiDAR를 통해 도로의 구조와 차선을 인식하고, 이를 기반으로 안정적인 주행을 이어나갈 수 있다.</li>
<li><strong>동적 객체 추적</strong>: 자율 주행 중 주변의 차량, 보행자 등의 움직임을 추적하고 이를 예측하여 안전한 경로를 계산하는 데 사용된다.</li>
</ul>
<p>LiDAR는 이러한 정보를 제공하며, 이를 통해 자율 주행 시스템은 더욱 정확하고 안전한 주행을 가능하게 한다.</p>
<h2 id="lidar_4">LiDAR의 장단점</h2>
<p>LiDAR는 자율 주행에 있어 많은 이점을 제공하지만, 동시에 한계점도 존재한다. 이를 이해하는 것은 SLAM 구현 시 고려해야 할 중요한 요소이다.</p>
<h3 id="lidar_5">LiDAR의 장점</h3>
<ol>
<li><strong>높은 정확도</strong>: LiDAR는 빛을 이용해 정확한 거리 측정이 가능하므로, 다른 센서보다 더 정확하게 3D 지형을 인식할 수 있다.</li>
<li><strong>넓은 시야각</strong>: 일반적으로 360도 회전 가능한 LiDAR 센서는 넓은 범위를 빠르게 스캔할 수 있어, 주위의 장애물과 지형을 실시간으로 파악하는 데 유리하다.</li>
<li><strong>나쁜 조명 환경에서도 성능 유지</strong>: LiDAR는 빛을 직접 발사하고 그 반사를 측정하기 때문에, 어두운 환경에서도 정확한 데이터 수집이 가능하다. 이는 카메라 기반 센서들이 낮은 조도에서 성능이 떨어지는 문제를 보완한다.</li>
<li><strong>객체 인식 및 추적 용이</strong>: 실시간으로 주변 환경을 3D로 인식하고, 이를 통해 동적 객체(다른 차량, 보행자 등)를 추적할 수 있는 능력이 있다.</li>
</ol>
<h3 id="lidar_6">LiDAR의 단점</h3>
<ol>
<li><strong>비용</strong>: 고성능 LiDAR는 여전히 가격이 매우 높다. 자율 주행을 위해서는 다수의 LiDAR 센서가 필요할 수 있기 때문에, 시스템 전체 비용을 크게 증가시킬 수 있다.</li>
<li><strong>날씨의 영향</strong>: LiDAR는 비, 눈, 먼지와 같은 기상 조건에 영향을 받을 수 있다. 예를 들어, 눈이 많이 내리거나 비가 심하게 내리는 경우에는 레이저의 반사가 왜곡되어 정확도가 떨어질 수 있다.</li>
<li><strong>데이터 처리량</strong>: LiDAR는 초당 수십만에서 수백만 개의 데이터를 생성하므로, 이를 실시간으로 처리하기 위한 고성능 컴퓨팅 자원이 필요하다. 특히, 대규모 포인트 클라우드를 처리하는 알고리즘의 최적화가 필수적이다.</li>
<li><strong>짧은 거리 감지</strong>: LiDAR는 일정 거리 이상에서는 레이저의 에너지가 약해져 정확한 측정이 어려워진다. 장거리 감지의 경우 카메라나 레이더와 같은 센서와의 조합이 필요하다.</li>
</ol>
<h2 id="lidar_7">LiDAR 데이터의 표현 및 활용</h2>
<p>LiDAR로부터 얻어진 포인트 클라우드 데이터는 환경의 공간적 정보를 나타낸다. 이를 다양한 형식으로 표현하고 활용할 수 있다.</p>
<h3 id="_1">포인트 클라우드의 좌표계</h3>
<p>LiDAR로 측정된 포인트 클라우드 데이터는 특정 좌표계를 기반으로 한다. 일반적으로 자율 주행 시스템에서는 차량 고유의 좌표계를 사용한다. 이때, 포인트 클라우드는 다음과 같은 변환 과정을 거쳐 다른 좌표계로 변환될 수 있다.</p>
<p>포인트 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{p}_i = (x_i, y_i, z_i)</span><script type="math/tex">\mathbf{p}_i = (x_i, y_i, z_i)</script></span>가 다른 좌표계로 변환되는 과정은 3D 변환 행렬 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{T}</span><script type="math/tex">\mathbf{T}</script></span>을 이용하여 다음과 같이 표현된다:</p>
<div class="arithmatex">
<div class="MathJax_Preview">
\mathbf{p}'_i = \mathbf{T} \cdot \mathbf{p}_i
</div>
<script type="math/tex; mode=display">
\mathbf{p}'_i = \mathbf{T} \cdot \mathbf{p}_i
</script>
</div>
<p>여기서,<br />
<span class="arithmatex"><span class="MathJax_Preview">\mathbf{p}'_i</span><script type="math/tex">\mathbf{p}'_i</script></span>는 변환된 좌표계에서의 포인트,<br />
<span class="arithmatex"><span class="MathJax_Preview">\mathbf{T}</span><script type="math/tex">\mathbf{T}</script></span>는 회전과 평행 이동을 포함하는 변환 행렬이다.</p>
<div class="arithmatex">
<div class="MathJax_Preview">
\mathbf{T} = \begin{bmatrix} 
R &amp; \mathbf{t} \\
0 &amp; 1 
\end{bmatrix}
</div>
<script type="math/tex; mode=display">
\mathbf{T} = \begin{bmatrix} 
R & \mathbf{t} \\
0 & 1 
\end{bmatrix}
</script>
</div>
<p>여기서,<br />
<span class="arithmatex"><span class="MathJax_Preview">\mathbf{R}</span><script type="math/tex">\mathbf{R}</script></span>은 회전 행렬,<br />
<span class="arithmatex"><span class="MathJax_Preview">\mathbf{t}</span><script type="math/tex">\mathbf{t}</script></span>는 평행 이동 벡터이다.</p>
<h3 id="registration">포인트 클라우드의 정합(Registration)</h3>
<p>LiDAR SLAM에서는 연속적인 프레임의 포인트 클라우드를 정합(Registration)하는 과정이 필요하다. 이를 통해 로봇은 이동 경로를 추적하고, 환경의 변화를 반영한 지도를 지속적으로 업데이트할 수 있다.</p>
<p>포인트 클라우드 정합은 일반적으로 두 포인트 클라우드 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{P}_A</span><script type="math/tex">\mathbf{P}_A</script></span>와 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{P}_B</span><script type="math/tex">\mathbf{P}_B</script></span> 사이의 최적의 변환 행렬 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{T}</span><script type="math/tex">\mathbf{T}</script></span>를 찾는 문제로 정의된다. 이를 수학적으로 표현하면 다음과 같다:</p>
<div class="arithmatex">
<div class="MathJax_Preview">
\min_{\mathbf{T}} \sum_{i} \| \mathbf{p}_{A_i} - \mathbf{T} \cdot \mathbf{p}_{B_i} \|^2
</div>
<script type="math/tex; mode=display">
\min_{\mathbf{T}} \sum_{i} \| \mathbf{p}_{A_i} - \mathbf{T} \cdot \mathbf{p}_{B_i} \|^2
</script>
</div>
<p>여기서,<br />
<span class="arithmatex"><span class="MathJax_Preview">\mathbf{p}_{A_i}</span><script type="math/tex">\mathbf{p}_{A_i}</script></span>와 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{p}_{B_i}</span><script type="math/tex">\mathbf{p}_{B_i}</script></span>는 각 포인트 클라우드에서 대응하는 포인트들이다.</p>
<p>이 과정은 주로 ICP(Iterative Closest Point) 알고리즘을 통해 이루어진다. ICP 알고리즘은 다음과 같은 단계로 진행된다:</p>
<ol>
<li>두 포인트 클라우드에서 가장 가까운 포인트들 간의 대응 관계를 찾는다.</li>
<li>그 대응 관계를 바탕으로 변환 행렬 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{T}</span><script type="math/tex">\mathbf{T}</script></span>를 추정한다.</li>
<li>추정된 변환을 적용한 후 오차가 수렴할 때까지 반복한다.</li>
</ol>
<p>이 과정에서 발생하는 오차는 로봇의 이동 및 지도 작성 성능에 영향을 미치기 때문에, 이를 최소화하기 위한 최적화 기법이 사용된다.</p>
<h2 id="lidar-slam_1">LiDAR SLAM의 구성 요소</h2>
<p>LiDAR를 기반으로 한 SLAM 시스템은 크게 몇 가지 주요 구성 요소로 나뉜다:</p>
<ol>
<li><strong>센서 데이터 수집</strong>: LiDAR로부터 포인트 클라우드 데이터를 실시간으로 수집한다.</li>
<li><strong>전처리(Preprocessing)</strong>: 수집된 데이터에서 노이즈를 제거하고, 필터링을 통해 유의미한 데이터를 추출한다.</li>
<li><strong>특징 추출 및 매칭</strong>: 각 프레임에서 추출된 특징을 바탕으로 이전 프레임과의 매칭을 수행하여 로봇의 이동 경로를 추정한다.</li>
<li><strong>지도 작성(Mapping)</strong>: 매칭 결과를 바탕으로 환경의 3D 지도를 작성하고 이를 지속적으로 업데이트한다.</li>
<li><strong>위치 추정(Localization)</strong>: 로봇의 현재 위치를 실시간으로 추정한다.</li>
</ol>
<p>이러한 과정들은 매우 복잡하고 많은 계산 자원이 필요하다. 이를 최적화하기 위해 다양한 기법들이 연구되고 있으며, 특히 LiDAR의 데이터 처리 성능을 높이기 위한 많은 알고리즘들이 제안되고 있다.</p>
<h2 id="lidar-slam_2">LiDAR 기반 SLAM의 주요 알고리즘</h2>
<p>LiDAR 기반 SLAM에서는 다양한 알고리즘이 사용되며, 각각의 알고리즘은 특정한 문제 해결에 중점을 둔다. 다음은 LiDAR SLAM에서 주로 사용되는 주요 알고리즘들이다.</p>
<h3 id="1-iterative-closest-point-icp">1. Iterative Closest Point (ICP)</h3>
<p>ICP(Iterative Closest Point)는 가장 널리 사용되는 포인트 클라우드 정합(Registration) 알고리즘 중 하나이다. 앞서 언급한 것처럼, 두 포인트 클라우드 간의 대응 관계를 찾아서 변환 행렬을 계산하고, 이를 반복적으로 업데이트하여 두 데이터 세트를 정합시킨다.</p>
<h4 id="icp">ICP 알고리즘의 절차</h4>
<p>ICP 알고리즘의 절차는 다음과 같다:</p>
<ol>
<li><strong>초기화</strong>: 두 포인트 클라우드 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{P}_A</span><script type="math/tex">\mathbf{P}_A</script></span>와 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{P}_B</span><script type="math/tex">\mathbf{P}_B</script></span>가 주어진다. 초기 변환 행렬 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{T}_0</span><script type="math/tex">\mathbf{T}_0</script></span>는 보통 항등행렬로 시작된다.</li>
<li><strong>대응점 찾기</strong>: <span class="arithmatex"><span class="MathJax_Preview">\mathbf{P}_A</span><script type="math/tex">\mathbf{P}_A</script></span>의 각 포인트에 대해 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{P}_B</span><script type="math/tex">\mathbf{P}_B</script></span>에서 가장 가까운 포인트를 찾는다. 이는 유클리드 거리 기준으로 계산된다.</li>
<li><strong>변환 행렬 계산</strong>: 대응점 쌍을 기반으로 변환 행렬 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{T}</span><script type="math/tex">\mathbf{T}</script></span>를 계산한다. 이는 보통 최소자승법을 통해 해결된다.</li>
<li><strong>적용 및 반복</strong>: 계산된 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{T}</span><script type="math/tex">\mathbf{T}</script></span>를 적용하여 포인트 클라우드를 변환하고, 오차가 수렴할 때까지 이 과정을 반복한다.</li>
</ol>
<p>ICP는 매우 강력한 알고리즘이지만, 초기값에 민감하고 지역 최적화에 빠질 수 있는 단점이 있다. 이를 개선하기 위해 다양한 변형된 ICP 알고리즘이 제안되었다.</p>
<h3 id="2-ndt-normal-distributions-transform">2. NDT (Normal Distributions Transform)</h3>
<p>NDT(Normal Distributions Transform)는 3D 환경에서의 정합을 위해 포인트 클라우드를 확률 분포로 변환하는 방법을 사용한다. 각 포인트 클라우드를 지역적으로 구획하여 그 구획 내의 점들의 확률 밀도를 계산하고, 그 분포를 바탕으로 정합을 수행한다.</p>
<h4 id="ndt">NDT의 주요 특징</h4>
<ul>
<li><strong>포인트 분포 사용</strong>: 단일 포인트 대신, 각 구역에서 점들의 밀도 분포를 계산하므로, 노이즈에 강하고 빠른 수렴을 보인다.</li>
<li><strong>고속 수렴</strong>: ICP와 달리, 초기값에 덜 민감하며, 초기 값이 부정확하더라도 더 빠르게 수렴하는 경향이 있다.</li>
<li><strong>복잡한 환경에 적합</strong>: 복잡한 3D 환경에서도 비교적 좋은 성능을 보여준다.</li>
</ul>
<p>NDT는 SLAM 시스템에서 LiDAR 포인트 클라우드를 안정적으로 정합하는 데 유용한 방법으로 사용된다.</p>
<h3 id="3-graph-based-slam">3. Graph-Based SLAM</h3>
<p>그래프 기반 SLAM은 로봇의 위치와 그 위치에서 수집된 센서 데이터를 그래프 형태로 모델링하는 방법이다. 여기서 각 노드는 로봇의 위치를 나타내고, 엣지는 로봇의 두 위치 간의 상대적인 이동(변환)을 나타낸다. 이 그래프에서 각 노드와 엣지의 관계를 최적화하여 가장 일관된 경로와 지도를 찾는 것이 목표이다.</p>
<h4 id="slam">그래프 기반 SLAM의 과정</h4>
<ol>
<li><strong>그래프 구성</strong>: 로봇의 위치를 나타내는 노드와, 두 위치 간의 변환을 나타내는 엣지를 생성한다.</li>
<li><strong>루프 클로징(Loop Closing)</strong>: 로봇이 이미 방문한 위치에 다시 도달했을 때, 이를 감지하여 그래프에 루프를 추가하고, 이를 통해 전체 그래프를 최적화한다.</li>
<li><strong>최적화</strong>: 그래프 내의 노드 간 관계를 기반으로 위치 추정과 맵의 일관성을 동시에 최적화한다. 이는 보통 비선형 최소자승법을 사용하여 해결된다.</li>
</ol>
<p>그래프 기반 SLAM은 대규모 환경에서 특히 효과적이며, 복잡한 지도 작성과 정확한 위치 추정이 가능하다. 하지만 계산 비용이 높아 최적화 기법의 성능이 SLAM의 효율성을 좌우한다.</p>
<h3 id="4-loam-lidar-odometry-and-mapping">4. LOAM (Lidar Odometry and Mapping)</h3>
<p>LOAM은 LiDAR 데이터만을 이용해 로봇의 위치 추정(Odometry)과 맵핑(Mapping)을 동시에 수행하는 알고리즘이다. LOAM의 가장 큰 특징은 시간 상에서 분리된 두 가지 작업을 병렬로 수행하여, 높은 속도와 정확도를 동시에 달성하는 것이다.</p>
<h4 id="loam">LOAM의 작동 방식</h4>
<ol>
<li><strong>특징 추출</strong>: 입력된 LiDAR 포인트 클라우드에서 곡률이 높은 특징을 추출한다. 이는 로봇의 이동에 대한 민감도가 높은 점들로, 주로 경계선이나 모서리에서 추출된다.</li>
<li><strong>LiDAR Odometry</strong>: 추출된 특징점들 간의 상대적인 변환을 계산하여 로봇의 짧은 구간에서의 이동을 추정한다.</li>
<li><strong>맵 업데이트</strong>: 동시에 로봇의 이동 경로를 기반으로 전체 맵을 점진적으로 업데이트한다. 이 과정에서 특징점들을 사용하여 주변 환경을 효율적으로 표현한다.</li>
</ol>
<p>LOAM은 빠르고 정확한 LiDAR 기반 SLAM을 구현하기 위해 설계되었으며, 자율 주행차와 같은 실시간 시스템에 적합하다.</p>
<h2 id="lidar-slam_3">LiDAR SLAM의 최신 동향</h2>
<p>LiDAR SLAM 분야는 빠르게 발전하고 있으며, 다양한 최신 기술들이 등장하고 있다. 이러한 기술들은 LiDAR 데이터의 처리 효율성을 높이거나, 기존 알고리즘의 한계를 극복하는 데 초점을 맞추고 있다.</p>
<h3 id="1-slam">1. 딥러닝 기반 SLAM</h3>
<p>최근 딥러닝을 활용한 SLAM 알고리즘이 활발히 연구되고 있다. 특히, LiDAR 데이터를 처리하는데 있어, 딥러닝 모델을 적용하면 포인트 클라우드에서 더 효율적으로 특징을 추출하고 정합하는 것이 가능하다.</p>
<ul>
<li><strong>학습 기반 포인트 클라우드 특징 추출</strong>: 기존 알고리즘은 주로 수동으로 설계된 특징 추출 방법을 사용했지만, 딥러닝을 이용하면 더 강력하고 일반화된 특징을 학습할 수 있다.</li>
<li><strong>End-to-End SLAM 시스템</strong>: 일부 연구에서는 LiDAR 데이터를 입력으로 받아, 위치 추정과 맵핑을 직접적으로 수행하는 End-to-End SLAM 시스템을 개발하고 있다. 이는 기존의 복잡한 파이프라인을 간소화할 수 있다.</li>
</ul>
<h3 id="2-slam">2. 멀티센서 융합 SLAM</h3>
<p>LiDAR와 카메라, IMU(관성 측정 장치) 등을 결합한 멀티센서 융합 SLAM 시스템이 주목받고 있다. 각 센서는 서로의 약점을 보완할 수 있어, 보다 정밀하고 안정적인 SLAM을 구현할 수 있다.</p>
<ul>
<li><strong>LiDAR와 카메라 융합</strong>: 카메라는 장거리 인식과 객체 식별에 유리하고, LiDAR는 짧은 거리에서 정확한 3D 인식을 제공한다. 이 두 센서를 결합하면, 더 풍부한 환경 정보와 함께 정밀한 위치 추정이 가능하다.</li>
<li><strong>IMU 통합</strong>: IMU 데이터를 활용하면 빠른 움직임이나 LiDAR 데이터만으로는 추정이 어려운 복잡한 환경에서의 위치 추정을 보완할 수 있다.</li>
</ul>
<h3 id="3">3. 실시간 최적화 기법</h3>
<p>LiDAR 기반 SLAM은 많은 계산을 필요로 하므로 실시간 처리가 필수적이다. 이를 위해 최근에는 효율적인 최적화 기법과 병렬 처리 기술이 SLAM에 적용되고 있다.</p>
<h4 id="_2">실시간 최적화</h4>
<p>실시간 SLAM에서는 위치 추정과 지도 작성이 동시에 이루어져야 하므로 계산 비용을 최소화하면서 정확도를 유지하는 최적화 기법이 중요하다. 특히, 다음과 같은 최적화 기법이 널리 사용된다:</p>
<ul>
<li>
<p><strong>그래디언트 기반 최적화(Gradient-Based Optimization)</strong>: 포인트 클라우드 정합과 맵 업데이트 과정에서 발생하는 에러를 최소화하기 위해, 각 변수에 대한 그래디언트를 계산하여 점진적으로 최적의 해를 찾아가는 방법이다.</p>
</li>
<li>
<p><strong>Gauss-Newton 및 Levenberg-Marquardt 알고리즘</strong>: 비선형 최소자승 문제를 해결하는 알고리즘으로, SLAM 최적화에 자주 사용된다. 이들은 SLAM에서 발생하는 복잡한 관계식들을 해결하는 데 적합하다.</p>
</li>
<li>
<p><strong>Ceres Solver</strong>: Google에서 개발한 비선형 최적화 라이브러리로, LiDAR SLAM의 그래프 기반 최적화에 자주 활용된다. 고성능의 최적화 기능을 제공하며, 실시간 SLAM에 적용할 수 있을 만큼 빠르다.</p>
</li>
</ul>
<h4 id="gpu">병렬 처리 및 GPU 가속</h4>
<p>LiDAR SLAM에서 대규모 데이터 처리 속도를 높이기 위해 병렬 처리 및 GPU 가속이 자주 사용된다. 특히 포인트 클라우드 데이터는 병렬 처리가 용이한 구조를 가지고 있기 때문에, 이를 GPU에서 처리하면 실시간 성능을 크게 향상시킬 수 있다.</p>
<ul>
<li><strong>CUDA 및 OpenCL</strong>: 포인트 클라우드 필터링, 특징 추출, 매칭 등의 계산 과정을 병렬로 처리하기 위해 GPU 프로그래밍 언어인 CUDA나 OpenCL이 사용된다.</li>
<li><strong>ROS2와 병렬 처리</strong>: ROS2의 멀티스레딩과 비동기 통신을 통해 SLAM 시스템의 병렬 처리 성능을 향상시킬 수 있다. 특히 LiDAR 데이터의 수집과 처리, 최적화 등을 병렬로 처리하는 구조를 설계하면 실시간 성능을 극대화할 수 있다.</li>
</ul>
<h3 id="4-sparse-vs-dense-slam">4. Sparse vs. Dense SLAM</h3>
<p>LiDAR SLAM에서는 포인트 클라우드 데이터를 얼마나 세밀하게 처리할 것인지에 따라 Sparse(희소)와 Dense(밀집) 접근 방식으로 나뉜다.</p>
<h4 id="sparse-slam">Sparse SLAM</h4>
<p>Sparse SLAM은 포인트 클라우드 전체에서 중요한 특징점들만을 추출하고, 이들만을 이용해 SLAM을 수행하는 방식이다. 이는 계산 비용을 크게 줄이면서도 충분히 정확한 SLAM을 구현할 수 있다는 장점이 있다.</p>
<ul>
<li><strong>특징점 기반 처리</strong>: 주로 경계선, 모서리와 같은 특징적인 점들을 사용하여 로봇의 위치와 맵을 추정한다. 이는 SLAM의 속도와 효율성을 높이는 데 도움이 된다.</li>
<li><strong>사용 예</strong>: LOAM과 같은 알고리즘은 Sparse 방식으로 LiDAR 데이터를 처리하여, 고속의 SLAM 구현을 가능하게 한다.</li>
</ul>
<h4 id="dense-slam">Dense SLAM</h4>
<p>Dense SLAM은 포인트 클라우드의 모든 데이터를 활용하여 매우 세밀한 지도를 작성하고 위치를 추정하는 방식이다. 이는 계산 비용이 크지만, 더 정확하고 자세한 3D 지도를 제공할 수 있다.</p>
<ul>
<li><strong>고해상도 지도 작성</strong>: Dense SLAM에서는 포인트 클라우드의 모든 점들을 사용하여 고해상도의 3D 맵을 생성한다. 이를 통해 복잡한 환경에서도 정확한 SLAM이 가능하다.</li>
<li><strong>사용 예</strong>: 고해상도의 3D 맵이 요구되는 로봇이나 자율 주행 차량의 환경 인식에서 Dense SLAM이 유용하다. 특히, 복잡한 도시 환경이나 건물 내부와 같이 세밀한 정보가 필요한 상황에서 사용된다.</li>
</ul>
<h2 id="lidar-slam_4">LiDAR SLAM의 적용 사례</h2>
<p>LiDAR SLAM은 다양한 자율 주행 시스템과 로봇 공학에서 실용적으로 사용되고 있다. 다음은 주요 적용 사례들이다.</p>
<h3 id="1">1. 자율 주행 차량</h3>
<p>LiDAR SLAM은 자율 주행 차량에서 가장 널리 사용되는 SLAM 기술 중 하나이다. 차량의 정확한 위치 추정과 함께, 주변 환경의 실시간 3D 맵을 구축하여 장애물을 인식하고 안전한 주행 경로를 계산하는 데 사용된다.</p>
<h4 id="_3">주요 기능</h4>
<ul>
<li><strong>차선 및 도로 구조 인식</strong>: LiDAR를 이용해 도로의 3D 구조와 차선을 인식하고, 이를 기반으로 안전한 경로를 설정한다.</li>
<li><strong>동적 객체 감지 및 추적</strong>: 주변의 다른 차량, 보행자, 자전거 등 동적 객체를 추적하고, 이를 회피하는 주행 경로를 실시간으로 계산한다.</li>
<li><strong>GPS 대체</strong>: 터널이나 GPS 신호가 약한 지역에서도 LiDAR SLAM을 통해 차량의 위치를 정확하게 추정할 수 있다.</li>
</ul>
<h4 id="_4">실제 사례</h4>
<p>Waymo, Uber, Tesla와 같은 자율 주행 기술을 개발하는 회사들은 LiDAR 기반 SLAM을 자율 주행 차량에 적용하고 있다. 이들 시스템은 복잡한 도시 환경에서도 LiDAR SLAM을 이용해 자율 주행 기능을 구현하고 있다.</p>
<h3 id="2">2. 실내 자율 주행 로봇</h3>
<p>LiDAR SLAM은 실내 자율 주행 로봇에서도 많이 사용된다. 실내 환경에서는 GPS 신호가 작동하지 않기 때문에, 로봇이 자신의 위치를 실시간으로 추정하고 주위 환경의 지도를 생성할 수 있는 LiDAR SLAM이 필수적이다.</p>
<h4 id="_5">주요 기능</h4>
<ul>
<li><strong>장애물 회피 및 경로 계획</strong>: LiDAR SLAM을 통해 로봇은 실내의 장애물을 감지하고, 이를 피할 수 있는 최적의 경로를 계산한다.</li>
<li><strong>자동 매핑</strong>: 새로운 실내 환경에서 로봇이 스스로 3D 지도를 작성하고, 그 지도를 활용하여 경로를 최적화할 수 있다.</li>
</ul>
<h4 id="_6">실제 사례</h4>
<p>창고나 공장 내에서 사용되는 물류 로봇, 청소 로봇, 안내 로봇 등에서 LiDAR SLAM이 적용되고 있다. 예를 들어, Amazon의 물류 로봇은 창고 내부의 3D 지도를 작성하고, 이를 기반으로 자율적으로 물건을 운반하는 기능을 수행한다.</p>
<h3 id="3-uav">3. 드론 및 무인 항공기(UAV)</h3>
<p>LiDAR SLAM은 드론과 같은 무인 항공기에서도 사용된다. 특히, 복잡한 실외 환경에서 드론이 스스로 비행 경로를 설정하고, 장애물을 피하는 데 유용하다.</p>
<h4 id="_7">주요 기능</h4>
<ul>
<li><strong>고도 및 장애물 인식</strong>: 드론이 비행 중에 LiDAR SLAM을 통해 자신의 고도와 주변의 장애물을 인식하고, 안전한 비행 경로를 유지할 수 있다.</li>
<li><strong>실시간 맵핑</strong>: 드론은 LiDAR 데이터를 기반으로 비행 중 실시간으로 3D 지도를 생성할 수 있다. 이는 탐사, 구조 활동, 농업 등 다양한 분야에서 활용된다.</li>
</ul>
<h4 id="_8">실제 사례</h4>
<p>LiDAR SLAM을 적용한 드론은 자연재해 이후의 피해 지역을 3D로 스캔하여 구조 작업을 지원하거나, 농업 분야에서 지형 지도를 작성하여 작물 관리에 활용된다.</p>
<h2 id="lidar-slam_5">LiDAR SLAM의 미래 전망</h2>
<p>LiDAR SLAM은 앞으로도 자율 주행 및 로봇 기술에서 중요한 역할을 할 것으로 기대된다. 특히, 센서의 성능 향상, 더 빠른 계산 능력, 인공지능과의 융합을 통해 SLAM 기술이 더욱 발전할 것이다.</p>
<h3 id="_9">센서 기술의 발전</h3>
<p>LiDAR 센서의 해상도, 범위, 비용이 지속적으로 개선되면서 SLAM 시스템의 성능 또한 크게 향상될 것으로 기대된다. 특히, 소형화된 저비용 LiDAR 센서가 개발되면 더 많은 애플리케이션에서 LiDAR SLAM을 활용할 수 있게 될 것이다.</p>
<h3 id="_10">딥러닝과의 융합</h3>
<p>딥러닝 기술이 발전하면서 SLAM에서의 데이터 처리와 특징 추출 과정에 혁신이 일어날 수 있다. 특히, 자율 주행 차량이나 로봇이 복잡한 환경에서도 더 높은 정확도와 안정성을 유지하면서 위치를 추정할 수 있을 것이다.</p>
<h3 id="_11">멀티센서 융합의 확대</h3>
<p>LiDAR와 다른 센서들 간의 융합이 더 발전하여, 자율 주행 차량이나 로봇이 다양한 환경에서 더 안전하고 효율적으로 동작할 수 있게 될 것이다. 특히, LiDAR, 카메라, 레이더, IMU 등 여러 센서를 결합한 SLAM 시스템은 GPS가 없는 환경에서도 높은 신뢰성을 제공할 것으로 기대된다.</p>

  <br>
    

    
    
      
    

  <div class="row wm-article-nav-buttons" role="navigation" aria-label="navigation">
    
    <div class="wm-article-nav pull-right">
      <a href="../0203/" class="btn btn-xs btn-default pull-right">
        Next
        <i class="fa fa-chevron-right" aria-hidden="true"></i>
      </a>
      <a href="../0203/" class="btn btn-xs btn-link">
        FAST-LIVO 알고리즘 개요
      </a>
    </div>
    
    <div class="wm-article-nav">
      <a href="../0201/" class="btn btn-xs btn-default pull-left">
        <i class="fa fa-chevron-left" aria-hidden="true"></i>
        Previous</a><a href="../0201/" class="btn btn-xs btn-link">
        LiDAR SLAM의 기본 개념
      </a>
    </div>
    
  </div>

    <br>
</div>

<footer class="container-fluid wm-page-content">
  <p>Documentation built with <a href="https://www.mkdocs.org/">MkDocs</a> using <a href="https://github.com/gristlabs/mkdocs-windmill">Windmill</a> theme by Grist Labs.</p>
</footer>

</body>
</html>