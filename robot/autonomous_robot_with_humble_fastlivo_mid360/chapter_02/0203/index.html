<!DOCTYPE html>

<html lang="en">
<head>
<meta charset="utf-8"/>
<meta content="IE=edge" http-equiv="X-UA-Compatible"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<link href="https://booiljung.github.io/robot/autonomous_robot_with_humble_fastlivo_mid360/chapter_02/0203/" rel="canonical"/>
<link href="../../../../img/favicon.ico" rel="shortcut icon"/>
<meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport">
<title>FAST-LIVO 알고리즘 개요 - 실험 도서관</title>
<link href="../../../../css/bootstrap-3.3.7.min.css" rel="stylesheet"/>
<link href="../../../../css/font-awesome-4.7.0.css" rel="stylesheet"/>
<link href="../../../../css/base.css" rel="stylesheet"/>
<link href="../../../../css/highlight.css" rel="stylesheet"/>
<link href="../../../../css/custom.css" rel="stylesheet"/>
<!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
<!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.3.0/respond.min.js"></script>
    <![endif]-->
<script src="../../../../js/jquery-3.2.1.min.js"></script>
<script src="../../../../js/bootstrap-3.3.7.min.js"></script>
<script src="../../../../js/highlight.pack.js"></script>
<base target="_top"/>
<script>
      var base_url = '../../../..';
      var is_top_frame = false;
        
        var pageToc = [
          {title: "1. LiDAR \ubc0f Visual Inertial Odometry\uc758 \uacb0\ud569", url: "#_top", children: [
          ]},
          {title: "2. \uc54c\uace0\ub9ac\uc998\uc758 \uae30\ubcf8 \uad6c\uc870", url: "#2", children: [
          ]},
          {title: "3. \ud504\ub860\ud2b8\uc5d4\ub4dc: LiDAR \uae30\ubc18 \ud2b9\uc9d5 \ucd94\ucd9c", url: "#3-lidar", children: [
          ]},
          {title: "4. LiDAR Odometry", url: "#4-lidar-odometry", children: [
          ]},
          {title: "5. \ubc31\uc5d4\ub4dc: \ucd5c\uc801\ud654 \uae30\ubc18 \uc704\uce58 \ucd94\uc815", url: "#5", children: [
          ]},
          {title: "6. VIO (Visual Inertial Odometry)\uc640 LiDAR Odometry \uacb0\ud569", url: "#6-vio-visual-inertial-odometry-lidar-odometry", children: [
          ]},
          {title: "7. \ube44\ub3d9\uae30\uc801 \uc13c\uc11c \ub370\uc774\ud130 \ud1b5\ud569", url: "#7", children: [
          ]},
          {title: "8. \ucd5c\uc801\ud654 \ubb38\uc81c \uc815\uc758", url: "#8", children: [
          ]},
          {title: "9. FAST-LIVO\uc758 \uc2dc\uac04 \ubcf5\uc7a1\ub3c4\uc640 \uc131\ub2a5 \ucd5c\uc801\ud654", url: "#9-fast-livo", children: [
          ]},
          {title: "10. LiDAR, VIO, IMU \ub370\uc774\ud130\uc758 \uc735\ud569\uc744 \uc704\ud55c \uc815\ud569 \uae30\ubc95", url: "#10-lidar-vio-imu", children: [
              {title: "LiDAR\uc640 IMU \ub370\uc774\ud130 \uc815\ud569", url: "#lidar-imu" },
              {title: "LiDAR\uc640 VIO \ub370\uc774\ud130 \uc815\ud569", url: "#lidar-vio" },
          ]},
          {title: "11. FAST-LIVO\uc758 \ube44\uc120\ud615 \ucd5c\uc801\ud654 \ubc29\ubc95", url: "#11-fast-livo", children: [
          ]},
          {title: "12. FAST-LIVO\uc758 \ubd88\ud655\uc2e4\uc131 \ubaa8\ub378\ub9c1", url: "#12-fast-livo", children: [
          ]},
          {title: "13. \uc2dc\uac04 \ubcf4\uc815(Time Calibration)\uacfc \uc2dc\uac04 \uc624\ucc28 \ucc98\ub9ac", url: "#13-time-calibration", children: [
          ]},
          {title: "14. IMU\uc758 \ub4dc\ub9ac\ud504\ud2b8 \ubcf4\uc815", url: "#14-imu", children: [
          ]},
          {title: "15. FAST-LIVO\uc5d0\uc11c\uc758 \ub370\uc774\ud130 \uc735\ud569 \ud504\ub808\uc784\uc6cc\ud06c", url: "#15-fast-livo", children: [
              {title: "\uac00\uc911\uce58 \uae30\ubc18 \uc13c\uc11c \uc735\ud569", url: "#_1" },
              {title: "\ud655\ub960\uc801 \uc13c\uc11c \uc735\ud569", url: "#_2" },
          ]},
          {title: "16. SLAM\uacfc \ube44\uc2b7\ud55c \ud655\ub960\uc801 \uc9c0\ub3c4 \uc791\uc131 \uacfc\uc815", url: "#16-slam", children: [
          ]},
          {title: "17. FAST-LIVO\uc758 \ub8e8\ud504 \ud074\ub85c\uc800(Loop Closure) \uae30\ubc95", url: "#17-fast-livo-loop-closure", children: [
          ]},
          {title: "18. FAST-LIVO\uc758 \ubd84\uc0b0 \ucc98\ub9ac \uad6c\uc870", url: "#18-fast-livo", children: [
              {title: "\uba40\ud2f0 \uc2a4\ub808\ub4dc \uae30\ubc18 \ucc98\ub9ac", url: "#_3" },
              {title: "\ub370\uc774\ud130 \ud30c\uc774\ud504\ub77c\uc778", url: "#_4" },
          ]},
          {title: "19. FAST-LIVO\uc758 \ud655\uc7a5\uc131", url: "#19-fast-livo", children: [
              {title: "\uc13c\uc11c \ucd94\uac00\uc640 \ud655\uc7a5", url: "#_5" },
              {title: "\uc774\ub3d9 \ub85c\ubd07 \ubc0f \ub4dc\ub860\uc5d0\uc758 \uc801\uc6a9", url: "#_6" },
          ]},
        ];

    </script>
<script src="../../../../js/base.js"></script>
<script src="../../../../js/google_analytics.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML"></script>
<script src="https://www.googletagmanager.com/gtag/js?id=G-3F4LHCTF88"></script>
</meta></head>
<body>
<script>
if (is_top_frame) { $('body').addClass('wm-top-page'); }
</script>
<div class="container-fluid wm-page-content">
<a name="_top"></a>
<div aria-label="navigation" class="row wm-article-nav-buttons" role="navigation">
<div class="wm-article-nav pull-right">
<a class="btn btn-xs btn-default pull-right" href="../0204/">
        Next
        <i aria-hidden="true" class="fa fa-chevron-right"></i>
</a>
<a class="btn btn-xs btn-link" href="../0204/">
        FAST-LIVO의 장점과 한계
      </a>
</div>
<div class="wm-article-nav">
<a class="btn btn-xs btn-default pull-left" href="../0202/">
<i aria-hidden="true" class="fa fa-chevron-left"></i>
        Previous</a><a class="btn btn-xs btn-link" href="../0202/">
        LiDAR 기반의 자율 주행 기술 개요
      </a>
</div>
</div>
<h3 id="1-lidar-visual-inertial-odometry">1. LiDAR 및 Visual Inertial Odometry의 결합</h3>
<p>FAST-LIVO(Fast LiDAR Inertial Visual Odometry)는 LiDAR SLAM과 VIO(Visual Inertial Odometry)를 결합하여 더욱 정밀한 자율 주행 로봇의 위치 추정을 수행하는 알고리즘이다. 이 알고리즘은 LiDAR 센서의 정밀한 거리 정보와 카메라와 IMU(Inertial Measurement Unit)의 관성 정보를 결합하여 로봇의 위치와 자세(orientation)를 추정한다. SLAM 문제는 기본적으로 로봇이 미지의 환경에서 이동하면서 자신의 위치와 주변 환경의 지도를 동시에 추정하는 문제를 다루며, FAST-LIVO는 이러한 SLAM 문제를 해결하기 위해 설계된 알고리즘 중 하나이다.</p>
<h3 id="2">2. 알고리즘의 기본 구조</h3>
<p>FAST-LIVO는 LiDAR 데이터를 기반으로 한 Odometry와 VIO 데이터를 결합하여 로봇의 위치를 추정한다. FAST-LIVO는 두 가지 주요 단계를 포함한다:</p>
<ol>
<li>
<p><strong>프론트엔드</strong>: LiDAR 데이터를 통해 3D 지형 정보와 로봇의 상대적 이동을 계산하는 단계이다. 여기서 FAST-LIVO는 FAST(Feature from Accelerated Segment Test)를 사용하여 특징점을 추출하고, 이를 LiDAR와 IMU 데이터를 결합하여 로봇의 움직임을 추정한다.</p>
</li>
<li>
<p><strong>백엔드</strong>: LiDAR, VIO, IMU 데이터를 결합하여 로봇의 전역적인 위치 추정을 하는 단계이다. 최적화 알고리즘을 통해 로봇의 위치와 자세를 지속적으로 업데이트한다.</p>
</li>
</ol>
<h3 id="3-lidar">3. 프론트엔드: LiDAR 기반 특징 추출</h3>
<p>FAST-LIVO에서 프론트엔드의 핵심은 LiDAR 데이터를 처리하여 특징점을 추출하는 것이다. LiDAR 데이터는 3D 포인트 클라우드를 형성하며, 이 포인트 클라우드에서 FAST 알고리즘을 사용하여 특징점을 추출하게 된다. 이러한 특징점은 이후의 위치 추정에 중요한 역할을 하며, 로봇이 이동할 때마다 갱신된다.</p>
<p>특징점 추출을 통해 얻어진 포인트 클라우드는 다음과 같은 수식으로 표현될 수 있다:</p>
<div class="arithmatex">
<div class="MathJax_Preview">
\mathbf{p}_i = \begin{bmatrix} x_i \\ y_i \\ z_i \end{bmatrix}
</div>
<script type="math/tex; mode=display">
\mathbf{p}_i = \begin{bmatrix} x_i \\ y_i \\ z_i \end{bmatrix}
</script>
</div>
<p>여기서 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{p}_i</span><script type="math/tex">\mathbf{p}_i</script></span>는 포인트 클라우드에서 <span class="arithmatex"><span class="MathJax_Preview">i</span><script type="math/tex">i</script></span>번째 점의 3D 좌표를 나타내며, <span class="arithmatex"><span class="MathJax_Preview">x_i</span><script type="math/tex">x_i</script></span>, <span class="arithmatex"><span class="MathJax_Preview">y_i</span><script type="math/tex">y_i</script></span>, <span class="arithmatex"><span class="MathJax_Preview">z_i</span><script type="math/tex">z_i</script></span>는 해당 점의 각 좌표축 성분이다.</p>
<h3 id="4-lidar-odometry">4. LiDAR Odometry</h3>
<p>LiDAR Odometry는 주어진 두 시점에서의 LiDAR 포인트 클라우드를 비교하여 로봇의 상대적인 움직임을 계산한다. 이를 위해 두 시점의 포인트 클라우드를 정렬하는 작업이 필요하며, 이를 수학적으로 설명하면 다음과 같다.</p>
<p>주어진 두 시점에서의 포인트 클라우드 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{P}_1</span><script type="math/tex">\mathbf{P}_1</script></span>와 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{P}_2</span><script type="math/tex">\mathbf{P}_2</script></span>가 있을 때, 이 둘을 정렬하여 최적의 변환 행렬 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{T}</span><script type="math/tex">\mathbf{T}</script></span>를 찾는다. 이 변환 행렬 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{T}</span><script type="math/tex">\mathbf{T}</script></span>는 회전 행렬 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{R}</span><script type="math/tex">\mathbf{R}</script></span>과 평행 이동 벡터 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{t}</span><script type="math/tex">\mathbf{t}</script></span>로 구성된다:</p>
<div class="arithmatex">
<div class="MathJax_Preview">
\mathbf{T} = \begin{bmatrix} \mathbf{R} &amp; \mathbf{t} \\ 0 &amp; 1 \end{bmatrix}
</div>
<script type="math/tex; mode=display">
\mathbf{T} = \begin{bmatrix} \mathbf{R} & \mathbf{t} \\ 0 & 1 \end{bmatrix}
</script>
</div>
<p>여기서, <span class="arithmatex"><span class="MathJax_Preview">\mathbf{R}</span><script type="math/tex">\mathbf{R}</script></span>은 <span class="arithmatex"><span class="MathJax_Preview">3 \times 3</span><script type="math/tex">3 \times 3</script></span> 회전 행렬이고, <span class="arithmatex"><span class="MathJax_Preview">\mathbf{t}</span><script type="math/tex">\mathbf{t}</script></span>는 <span class="arithmatex"><span class="MathJax_Preview">3 \times 1</span><script type="math/tex">3 \times 1</script></span> 이동 벡터이다. 두 시점의 포인트 클라우드가 주어졌을 때, 변환 행렬 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{T}</span><script type="math/tex">\mathbf{T}</script></span>를 통해 시점 <span class="arithmatex"><span class="MathJax_Preview">1</span><script type="math/tex">1</script></span>의 포인트 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{p}_1</span><script type="math/tex">\mathbf{p}_1</script></span>이 시점 <span class="arithmatex"><span class="MathJax_Preview">2</span><script type="math/tex">2</script></span>의 포인트 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{p}_2</span><script type="math/tex">\mathbf{p}_2</script></span>와 일치하도록 변환할 수 있다:</p>
<div class="arithmatex">
<div class="MathJax_Preview">
\mathbf{p}_2 = \mathbf{T} \mathbf{p}_1
</div>
<script type="math/tex; mode=display">
\mathbf{p}_2 = \mathbf{T} \mathbf{p}_1
</script>
</div>
<p>이 과정을 통해 로봇의 상대적인 위치 변화를 계산할 수 있다.</p>
<h3 id="5">5. 백엔드: 최적화 기반 위치 추정</h3>
<p>FAST-LIVO의 백엔드에서는 LiDAR Odometry로 얻은 상대적인 위치 정보와 VIO에서 얻은 관성 정보를 결합하여 최종적인 로봇의 위치를 추정한다. 이 과정은 최적화 문제로 표현되며, 목적 함수는 각 센서에서 얻은 정보 간의 잔차를 최소화하는 방향으로 정의된다.</p>
<p>최적화 문제는 일반적으로 다음과 같은 형태로 정의된다:</p>
<div class="arithmatex">
<div class="MathJax_Preview">
\min_{\mathbf{x}} \sum_{i} \left\| \mathbf{z}_i - h(\mathbf{x}_i) \right\|^2
</div>
<script type="math/tex; mode=display">
\min_{\mathbf{x}} \sum_{i} \left\| \mathbf{z}_i - h(\mathbf{x}_i) \right\|^2
</script>
</div>
<p>여기서 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{z}_i</span><script type="math/tex">\mathbf{z}_i</script></span>는 <span class="arithmatex"><span class="MathJax_Preview">i</span><script type="math/tex">i</script></span>번째 센서로부터 얻은 측정값이고, <span class="arithmatex"><span class="MathJax_Preview">h(\mathbf{x}_i)</span><script type="math/tex">h(\mathbf{x}_i)</script></span>는 상태 변수 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{x}_i</span><script type="math/tex">\mathbf{x}_i</script></span>에 대한 측정 함수이다. 잔차 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{z}_i - h(\mathbf{x}_i)</span><script type="math/tex">\mathbf{z}_i - h(\mathbf{x}_i)</script></span>를 최소화하는 방향으로 최적화를 수행하게 된다. </p>
<p>최적화 과정에서 중요한 부분은 IMU 데이터를 활용한 자세 변화 추정이다. IMU는 가속도와 각속도를 측정하며, 이를 통해 로봇의 회전과 이동을 계산할 수 있다. IMU의 관성 측정값 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{a}</span><script type="math/tex">\mathbf{a}</script></span>와 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{\omega}</span><script type="math/tex">\mathbf{\omega}</script></span>는 다음과 같이 로봇의 움직임을 설명한다:</p>
<div class="arithmatex">
<div class="MathJax_Preview">
\mathbf{v}_{t+1} = \mathbf{v}_t + \Delta t (\mathbf{a}_t - \mathbf{g})
</div>
<script type="math/tex; mode=display">
\mathbf{v}_{t+1} = \mathbf{v}_t + \Delta t (\mathbf{a}_t - \mathbf{g})
</script>
</div>
<div class="arithmatex">
<div class="MathJax_Preview">
\mathbf{\theta}_{t+1} = \mathbf{\theta}_t + \Delta t \mathbf{\omega}_t
</div>
<script type="math/tex; mode=display">
\mathbf{\theta}_{t+1} = \mathbf{\theta}_t + \Delta t \mathbf{\omega}_t
</script>
</div>
<p>여기서 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{v}_t</span><script type="math/tex">\mathbf{v}_t</script></span>는 <span class="arithmatex"><span class="MathJax_Preview">t</span><script type="math/tex">t</script></span>시점의 속도, <span class="arithmatex"><span class="MathJax_Preview">\mathbf{a}_t</span><script type="math/tex">\mathbf{a}_t</script></span>는 가속도, <span class="arithmatex"><span class="MathJax_Preview">\mathbf{\omega}_t</span><script type="math/tex">\mathbf{\omega}_t</script></span>는 각속도, <span class="arithmatex"><span class="MathJax_Preview">\mathbf{\theta}_t</span><script type="math/tex">\mathbf{\theta}_t</script></span>는 자세, <span class="arithmatex"><span class="MathJax_Preview">\mathbf{g}</span><script type="math/tex">\mathbf{g}</script></span>는 중력 가속도를 나타낸다.</p>
<h3 id="6-vio-visual-inertial-odometry-lidar-odometry">6. VIO (Visual Inertial Odometry)와 LiDAR Odometry 결합</h3>
<p>FAST-LIVO의 주요 혁신 중 하나는 VIO와 LiDAR Odometry를 결합하여 보다 정밀한 위치 추정을 가능하게 한다는 점이다. VIO는 카메라와 IMU 데이터를 사용하여 로봇의 움직임을 추정하는 방식으로, LiDAR Odometry와 상호 보완적인 특성을 갖는다. LiDAR는 거리 기반의 정보로 환경의 3D 지형을 잘 파악하는 반면, VIO는 주변의 시각적 특징을 기반으로 비교적 높은 빈도로 자세 정보를 제공한다.</p>
<p>VIO는 카메라 이미지에서 특징점(Feature Point)을 추출하여 이를 추적한다. IMU는 가속도 및 각속도 데이터를 제공하여, 카메라의 특징점 추적과 IMU 데이터를 결합하여 로봇의 자세 및 위치 변화를 추정한다. VIO의 기본적인 추정 모델은 다음과 같이 수학적으로 표현된다:</p>
<p>카메라에서 특정 시점 <span class="arithmatex"><span class="MathJax_Preview">t</span><script type="math/tex">t</script></span>에 포착한 3D 포인트 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{X}_w</span><script type="math/tex">\mathbf{X}_w</script></span>의 월드 좌표는 다음과 같이 표현된다:</p>
<div class="arithmatex">
<div class="MathJax_Preview">
\mathbf{X}_w = \mathbf{R}_t \mathbf{X}_c + \mathbf{t}_t
</div>
<script type="math/tex; mode=display">
\mathbf{X}_w = \mathbf{R}_t \mathbf{X}_c + \mathbf{t}_t
</script>
</div>
<p>여기서, 
- <span class="arithmatex"><span class="MathJax_Preview">\mathbf{R}_t</span><script type="math/tex">\mathbf{R}_t</script></span>는 월드 좌표계에서 카메라 좌표계로 변환하는 <span class="arithmatex"><span class="MathJax_Preview">3 \times 3</span><script type="math/tex">3 \times 3</script></span> 회전 행렬,
- <span class="arithmatex"><span class="MathJax_Preview">\mathbf{t}_t</span><script type="math/tex">\mathbf{t}_t</script></span>는 카메라의 위치를 나타내는 <span class="arithmatex"><span class="MathJax_Preview">3 \times 1</span><script type="math/tex">3 \times 1</script></span> 이동 벡터,
- <span class="arithmatex"><span class="MathJax_Preview">\mathbf{X}_c</span><script type="math/tex">\mathbf{X}_c</script></span>는 카메라 좌표계에서의 3D 포인트이다.</p>
<p>VIO는 이러한 특징점 기반의 위치 변화를 지속적으로 추적하며, IMU에서 제공되는 관성 정보와 융합하여 최적화한다. 이를 통해 VIO는 상대적인 위치 변화를 매우 정밀하게 추정할 수 있다.</p>
<h3 id="7">7. 비동기적 센서 데이터 통합</h3>
<p>FAST-LIVO에서 중요한 또 다른 부분은 비동기적인 센서 데이터를 효과적으로 통합하는 방법이다. LiDAR, 카메라, IMU는 각기 다른 주기로 데이터를 수집하는데, 이를 일관된 시간 축에서 결합하는 것이 매우 중요하다.</p>
<p>FAST-LIVO는 주로 IMU 데이터를 기준으로 하여 다른 센서 데이터를 동기화한다. IMU는 고주파수로 데이터를 수집하는데, 이를 기준으로 LiDAR와 카메라의 데이터를 시간 축 상에서 보간(interpolation)하여 통합한다. 이는 다음과 같은 기본적인 수식으로 설명할 수 있다.</p>
<p>IMU의 고주파수 데이터를 기반으로 두 시점 <span class="arithmatex"><span class="MathJax_Preview">t_1</span><script type="math/tex">t_1</script></span>과 <span class="arithmatex"><span class="MathJax_Preview">t_2</span><script type="math/tex">t_2</script></span>에서의 상태 변화는 다음과 같이 표현된다:</p>
<div class="arithmatex">
<div class="MathJax_Preview">
\mathbf{x}(t_2) = \mathbf{x}(t_1) + \int_{t_1}^{t_2} f(\mathbf{u}(t)) dt
</div>
<script type="math/tex; mode=display">
\mathbf{x}(t_2) = \mathbf{x}(t_1) + \int_{t_1}^{t_2} f(\mathbf{u}(t)) dt
</script>
</div>
<p>여기서, 
- <span class="arithmatex"><span class="MathJax_Preview">\mathbf{x}(t)</span><script type="math/tex">\mathbf{x}(t)</script></span>는 상태 벡터(위치 및 속도 등),
- <span class="arithmatex"><span class="MathJax_Preview">\mathbf{u}(t)</span><script type="math/tex">\mathbf{u}(t)</script></span>는 IMU에서 측정된 입력(가속도 및 각속도)이다.</p>
<p>LiDAR와 카메라 데이터는 해당 시간 간격에서 선형 보간 또는 상관 관계를 이용한 시간 보정을 통해 IMU 데이터와 결합된다. 이를 통해 각 센서 간의 비동기성을 최소화하고, 일관된 정보로 위치를 추정할 수 있다.</p>
<h3 id="8">8. 최적화 문제 정의</h3>
<p>FAST-LIVO는 최종적으로 LiDAR, VIO, IMU 데이터를 기반으로 전역적인 위치 추정을 수행하는 최적화 문제를 정의한다. 이 최적화 문제는 센서 데이터 간의 일관성을 최대화하는 방향으로 구성되며, 목표는 각 센서로부터 얻은 측정값과 추정값 간의 차이를 최소화하는 것이다.</p>
<p>최적화 문제의 일반적인 형태는 다음과 같이 정의될 수 있다:</p>
<div class="arithmatex">
<div class="MathJax_Preview">
\min_{\mathbf{X}} \sum_{i=1}^{N} \left\| \mathbf{z}_i^{LiDAR} - h_{LiDAR}(\mathbf{X}_i) \right\|^2 + \sum_{j=1}^{M} \left\| \mathbf{z}_j^{VIO} - h_{VIO}(\mathbf{X}_j) \right\|^2
</div>
<script type="math/tex; mode=display">
\min_{\mathbf{X}} \sum_{i=1}^{N} \left\| \mathbf{z}_i^{LiDAR} - h_{LiDAR}(\mathbf{X}_i) \right\|^2 + \sum_{j=1}^{M} \left\| \mathbf{z}_j^{VIO} - h_{VIO}(\mathbf{X}_j) \right\|^2
</script>
</div>
<p>여기서,
- <span class="arithmatex"><span class="MathJax_Preview">\mathbf{z}_i^{LiDAR}</span><script type="math/tex">\mathbf{z}_i^{LiDAR}</script></span>와 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{z}_j^{VIO}</span><script type="math/tex">\mathbf{z}_j^{VIO}</script></span>는 각각 LiDAR와 VIO로부터 얻은 측정값,
- <span class="arithmatex"><span class="MathJax_Preview">h_{LiDAR}(\mathbf{X}_i)</span><script type="math/tex">h_{LiDAR}(\mathbf{X}_i)</script></span>와 <span class="arithmatex"><span class="MathJax_Preview">h_{VIO}(\mathbf{X}_j)</span><script type="math/tex">h_{VIO}(\mathbf{X}_j)</script></span>는 각각 상태 변수 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{X}</span><script type="math/tex">\mathbf{X}</script></span>에 따른 LiDAR 및 VIO 모델이다.</p>
<p>이 최적화 문제는 각 센서로부터 얻은 정보들이 상호 보완적으로 사용되도록 설계되며, 잔차(residual)를 최소화하는 방식으로 풀린다.</p>
<h3 id="9-fast-livo">9. FAST-LIVO의 시간 복잡도와 성능 최적화</h3>
<p>FAST-LIVO는 실시간으로 동작해야 하기 때문에, 시간 복잡도 또한 중요한 요소로 작용한다. 특히 LiDAR 포인트 클라우드의 처리와 특징점 추출, IMU 데이터와의 융합 과정에서 많은 계산 자원이 요구된다.</p>
<p>FAST-LIVO는 이러한 계산 자원을 최소화하기 위해 다음과 같은 최적화 기법을 사용한다:</p>
<ol>
<li>
<p><strong>포인트 클라우드 다운샘플링</strong>: LiDAR로부터 얻은 포인트 클라우드를 일정한 간격으로 다운샘플링하여 처리량을 줄이다.</p>
</li>
<li>
<p><strong>이벤트 기반 IMU 데이터 처리</strong>: IMU 데이터는 고주파수로 들어오기 때문에, 불필요한 데이터를 제외하고 중요한 이벤트에 집중하여 처리하는 방식으로 연산량을 줄이다.</p>
</li>
<li>
<p><strong>프레임 간 간격 최적화</strong>: VIO와 LiDAR 간의 프레임 간격을 조정하여 실시간 처리 성능을 최적화한다. 필요 없는 프레임을 생략하여 계산을 경량화할 수 있다.</p>
</li>
</ol>
<p>FAST-LIVO의 이러한 최적화 기법들은 실시간 자율 주행 로봇에 적합한 성능을 제공하며, 특히 자원이 제한된 환경에서 효율적으로 작동하도록 설계되었다.</p>
<h3 id="10-lidar-vio-imu">10. LiDAR, VIO, IMU 데이터의 융합을 위한 정합 기법</h3>
<p>FAST-LIVO에서 LiDAR, VIO, IMU 데이터를 효과적으로 융합하기 위해 다양한 정합(registration) 기법을 사용한다. 이러한 기법들은 각 센서가 제공하는 데이터의 상관관계를 최대한 활용하여, 더 정확한 위치 추정을 가능하게 한다.</p>
<h4 id="lidar-imu">LiDAR와 IMU 데이터 정합</h4>
<p>LiDAR Odometry로 얻어진 상대적인 움직임 정보는 IMU 데이터를 기반으로 보정된다. 이를 통해 IMU가 제공하는 고주파수의 자세 정보를 LiDAR 데이터에 반영하여, LiDAR 측정의 불확실성을 줄이고 보다 안정적인 추정을 수행한다.</p>
<p>LiDAR와 IMU의 정합은 다음과 같이 수학적으로 표현될 수 있다. IMU가 제공하는 가속도 정보 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{a}</span><script type="math/tex">\mathbf{a}</script></span>와 각속도 정보 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{\omega}</span><script type="math/tex">\mathbf{\omega}</script></span>를 기반으로, 현재 시점에서의 로봇의 회전 변환 행렬 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{R}_t</span><script type="math/tex">\mathbf{R}_t</script></span>와 속도 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{v}_t</span><script type="math/tex">\mathbf{v}_t</script></span>를 계산한다:</p>
<div class="arithmatex">
<div class="MathJax_Preview">
\mathbf{v}_{t+1} = \mathbf{v}_t + \Delta t (\mathbf{a}_t - \mathbf{g})
</div>
<script type="math/tex; mode=display">
\mathbf{v}_{t+1} = \mathbf{v}_t + \Delta t (\mathbf{a}_t - \mathbf{g})
</script>
</div>
<div class="arithmatex">
<div class="MathJax_Preview">
\mathbf{R}_{t+1} = \mathbf{R}_t \exp(\Delta t \mathbf{\omega}_t)
</div>
<script type="math/tex; mode=display">
\mathbf{R}_{t+1} = \mathbf{R}_t \exp(\Delta t \mathbf{\omega}_t)
</script>
</div>
<p>여기서, <span class="arithmatex"><span class="MathJax_Preview">\mathbf{g}</span><script type="math/tex">\mathbf{g}</script></span>는 중력 가속도, <span class="arithmatex"><span class="MathJax_Preview">\exp(\Delta t \mathbf{\omega}_t)</span><script type="math/tex">\exp(\Delta t \mathbf{\omega}_t)</script></span>는 각속도를 기반으로 한 로봇의 회전 변환이다. LiDAR에서 추정된 이동 벡터와 회전 행렬을 IMU의 계산 값과 결합하여 보정된 위치 추정을 얻는다.</p>
<h4 id="lidar-vio">LiDAR와 VIO 데이터 정합</h4>
<p>LiDAR 데이터는 로봇의 위치 변화를 3D 공간에서 정확히 측정하지만, 실시간으로 얻은 VIO 데이터와 비교적 낮은 주파수로 제공되는 경우가 많다. 이를 해결하기 위해 LiDAR Odometry와 VIO 데이터를 상호 보완적으로 결합하여, 두 센서 간의 차이를 보완하는 방식으로 동작한다.</p>
<p>VIO 데이터에서 얻은 위치 및 자세 변환은 다음과 같은 형태로 정의된다:</p>
<div class="arithmatex">
<div class="MathJax_Preview">
\mathbf{T}_t^{VIO} = \begin{bmatrix} \mathbf{R}_t^{VIO} &amp; \mathbf{t}_t^{VIO} \\ 0 &amp; 1 \end{bmatrix}
</div>
<script type="math/tex; mode=display">
\mathbf{T}_t^{VIO} = \begin{bmatrix} \mathbf{R}_t^{VIO} & \mathbf{t}_t^{VIO} \\ 0 & 1 \end{bmatrix}
</script>
</div>
<p>이와 같이, VIO 데이터는 회전 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{R}_t^{VIO}</span><script type="math/tex">\mathbf{R}_t^{VIO}</script></span>와 이동 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{t}_t^{VIO}</span><script type="math/tex">\mathbf{t}_t^{VIO}</script></span>을 포함한 4x4 변환 행렬로 표현되며, LiDAR에서 추정된 변환 행렬과 결합된다.</p>
<p>LiDAR와 VIO 간의 정합은 다음과 같은 형태로 잔차를 정의하여 최적화할 수 있다:</p>
<div class="arithmatex">
<div class="MathJax_Preview">
\mathbf{r}_t = \mathbf{T}_t^{LiDAR} - \mathbf{T}_t^{VIO}
</div>
<script type="math/tex; mode=display">
\mathbf{r}_t = \mathbf{T}_t^{LiDAR} - \mathbf{T}_t^{VIO}
</script>
</div>
<p>이때 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{T}_t^{LiDAR}</span><script type="math/tex">\mathbf{T}_t^{LiDAR}</script></span>는 LiDAR로 추정된 변환 행렬을 나타내며, <span class="arithmatex"><span class="MathJax_Preview">\mathbf{T}_t^{VIO}</span><script type="math/tex">\mathbf{T}_t^{VIO}</script></span>는 VIO에서 얻은 변환 행렬이다. 잔차 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{r}_t</span><script type="math/tex">\mathbf{r}_t</script></span>를 최소화하는 방향으로 최적화를 수행하여 두 센서 간의 데이터 정합을 최적화한다.</p>
<h3 id="11-fast-livo">11. FAST-LIVO의 비선형 최적화 방법</h3>
<p>FAST-LIVO는 비선형 최적화 문제를 해결하기 위해 주로 비선형 최소제곱(NLS, Nonlinear Least Squares) 기법을 사용한다. 이는 센서 데이터의 불확실성을 최소화하고, 각 센서가 제공하는 측정값과 추정값 간의 차이를 줄이기 위한 목적으로 사용된다.</p>
<p>NLS 문제는 일반적으로 다음과 같은 형태로 정의된다:</p>
<div class="arithmatex">
<div class="MathJax_Preview">
\min_{\mathbf{x}} \sum_{i} \left\| \mathbf{z}_i - h(\mathbf{x}_i) \right\|^2
</div>
<script type="math/tex; mode=display">
\min_{\mathbf{x}} \sum_{i} \left\| \mathbf{z}_i - h(\mathbf{x}_i) \right\|^2
</script>
</div>
<p>여기서,
- <span class="arithmatex"><span class="MathJax_Preview">\mathbf{z}_i</span><script type="math/tex">\mathbf{z}_i</script></span>는 측정된 데이터,
- <span class="arithmatex"><span class="MathJax_Preview">h(\mathbf{x}_i)</span><script type="math/tex">h(\mathbf{x}_i)</script></span>는 상태 변수 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{x}_i</span><script type="math/tex">\mathbf{x}_i</script></span>에 대한 모델 함수이다.</p>
<p>FAST-LIVO에서 사용되는 비선형 최적화 기법으로는 <strong>Gauss-Newton</strong> 또는 <strong>Levenberg-Marquardt</strong> 알고리즘이 주로 사용된다. 이러한 기법들은 센서 데이터 간의 잔차를 반복적으로 계산하고, 잔차를 최소화하는 방향으로 상태 변수를 갱신한다.</p>
<h3 id="12-fast-livo">12. FAST-LIVO의 불확실성 모델링</h3>
<p>FAST-LIVO는 센서로부터 얻어진 데이터의 불확실성을 고려하여 최적화를 수행한다. LiDAR, VIO, IMU 각각의 센서 데이터는 일정 수준의 노이즈와 불확실성을 포함하고 있으며, 이를 정확하게 모델링하는 것이 중요하다.</p>
<p>각 센서의 불확실성은 일반적으로 다음과 같은 공분산 행렬 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{Q}_i</span><script type="math/tex">\mathbf{Q}_i</script></span>로 모델링된다:</p>
<div class="arithmatex">
<div class="MathJax_Preview">
\mathbf{Q}_i = \text{cov}(\mathbf{z}_i)
</div>
<script type="math/tex; mode=display">
\mathbf{Q}_i = \text{cov}(\mathbf{z}_i)
</script>
</div>
<p>여기서 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{Q}_i</span><script type="math/tex">\mathbf{Q}_i</script></span>는 센서 측정값 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{z}_i</span><script type="math/tex">\mathbf{z}_i</script></span>의 불확실성을 나타내는 공분산 행렬이다. FAST-LIVO는 이러한 공분산 행렬을 기반으로 센서 데이터의 신뢰도를 계산하고, 최적화 과정에서 가중치로 반영한다. 예를 들어, IMU는 일반적으로 고주파수의 자세 변화를 제공하지만 노이즈가 상대적으로 많기 때문에, LiDAR 데이터에 비해 더 낮은 가중치를 부여하는 방식으로 처리된다.</p>
<h3 id="13-time-calibration">13. 시간 보정(Time Calibration)과 시간 오차 처리</h3>
<p>FAST-LIVO는 다양한 센서 데이터를 융합하여 로봇의 위치를 추정하므로, 각 센서 간의 시간 오차(time delay)가 위치 추정 정확도에 미치는 영향을 줄이기 위한 시간 보정 기법이 필수적이다. 시간 보정은 특히 LiDAR, 카메라, IMU와 같은 서로 다른 주기로 데이터를 수집하는 센서들의 경우 중요하게 다루어져야 한다.</p>
<p>FAST-LIVO에서는 시간 보정을 위해 IMU 데이터를 기준으로 다른 센서들의 데이터를 시간 축에서 보간하거나, 예측 모델을 사용하여 시간 오차를 수정한다. 이러한 시간 보정 기법은 센서 간의 동기화를 최대한 정확하게 맞추는 데 중요한 역할을 한다.</p>
<p>이 과정을 수학적으로 설명하면, 주어진 두 시점에서 센서 A와 센서 B의 측정값이 각각 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{z}_A(t)</span><script type="math/tex">\mathbf{z}_A(t)</script></span>와 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{z}_B(t + \Delta t)</span><script type="math/tex">\mathbf{z}_B(t + \Delta t)</script></span>로 제공될 때, 시간 오차 <span class="arithmatex"><span class="MathJax_Preview">\Delta t</span><script type="math/tex">\Delta t</script></span>를 최소화하는 방향으로 보정한다. </p>
<div class="arithmatex">
<div class="MathJax_Preview">
\min_{\Delta t} \left\| \mathbf{z}_A(t) - \mathbf{z}_B(t + \Delta t) \right\|
</div>
<script type="math/tex; mode=display">
\min_{\Delta t} \left\| \mathbf{z}_A(t) - \mathbf{z}_B(t + \Delta t) \right\|
</script>
</div>
<p>이 최적화 문제를 풀어 시간 오차를 최소화한 뒤, 센서 데이터를 융합하여 보다 정밀한 위치 추정을 수행한다.</p>
<h3 id="14-imu">14. IMU의 드리프트 보정</h3>
<p>IMU(Inertial Measurement Unit)는 FAST-LIVO의 핵심적인 센서 중 하나로, 가속도와 각속도 정보를 제공하여 로봇의 움직임을 추적하는데 중요한 역할을 한다. 그러나 IMU는 시간이 지남에 따라 드리프트(Drift) 현상이 발생하여 측정값이 점점 부정확해지는 경향이 있다. 이를 보정하지 않으면 IMU만으로는 신뢰할 수 있는 위치 추정을 할 수 없다.</p>
<p>IMU 드리프트는 가속도와 각속도 측정에서 누적 오차가 발생하면서 시간이 지남에 따라 위치와 자세의 추정이 왜곡되는 현상이다. 이를 해결하기 위해 FAST-LIVO는 다른 센서(LiDAR 및 카메라)의 데이터를 사용하여 IMU의 드리프트를 보정한다. </p>
<p>IMU 드리프트 보정 과정은 크게 두 가지 방법으로 이루어진다:</p>
<ol>
<li><strong>LiDAR 및 VIO 기반 보정</strong>: LiDAR 및 VIO에서 얻은 상대적인 움직임 정보는 IMU에서 측정된 움직임과 비교된다. 이 비교를 통해 IMU에서 발생한 드리프트를 확인하고, 보정이 이루어진다. 수학적으로는 다음과 같이 표현할 수 있다.</li>
</ol>
<div class="arithmatex">
<div class="MathJax_Preview">
   \mathbf{x}_t^{\text{corrected}} = \mathbf{x}_t^{\text{IMU}} + \mathbf{\delta x}_t
</div>
<script type="math/tex; mode=display">
   \mathbf{x}_t^{\text{corrected}} = \mathbf{x}_t^{\text{IMU}} + \mathbf{\delta x}_t
</script>
</div>
<p>여기서 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{x}_t^{\text{IMU}}</span><script type="math/tex">\mathbf{x}_t^{\text{IMU}}</script></span>는 IMU로부터 추정된 위치 및 자세이고, <span class="arithmatex"><span class="MathJax_Preview">\mathbf{\delta x}_t</span><script type="math/tex">\mathbf{\delta x}_t</script></span>는 LiDAR 및 VIO로부터 계산된 보정 값이다. 이 보정 값은 IMU의 드리프트를 상쇄하는 방향으로 추가된다.</p>
<ol>
<li><strong>상태 변수의 확장</strong>: FAST-LIVO는 IMU의 드리프트를 상태 변수의 확장 형태로 모델링한다. 즉, IMU의 드리프트를 하나의 변수로 보고 이를 상태 추정 과정에서 추정한다. IMU 드리프트는 점진적으로 축적되기 때문에, 확장된 상태 공간에서 드리프트를 지속적으로 추적하며 보정하는 방식이다.</li>
</ol>
<p>확장된 상태 변수 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{X}_t</span><script type="math/tex">\mathbf{X}_t</script></span>는 다음과 같이 표현될 수 있다:</p>
<div class="arithmatex">
<div class="MathJax_Preview">
   \mathbf{X}_t = \begin{bmatrix} \mathbf{p}_t \\ \mathbf{v}_t \\ \mathbf{R}_t \\ \mathbf{b}_a \\ \mathbf{b}_\omega \end{bmatrix}
</div>
<script type="math/tex; mode=display">
   \mathbf{X}_t = \begin{bmatrix} \mathbf{p}_t \\ \mathbf{v}_t \\ \mathbf{R}_t \\ \mathbf{b}_a \\ \mathbf{b}_\omega \end{bmatrix}
</script>
</div>
<p>여기서, 
   - <span class="arithmatex"><span class="MathJax_Preview">\mathbf{p}_t</span><script type="math/tex">\mathbf{p}_t</script></span>는 로봇의 위치, 
   - <span class="arithmatex"><span class="MathJax_Preview">\mathbf{v}_t</span><script type="math/tex">\mathbf{v}_t</script></span>는 속도, 
   - <span class="arithmatex"><span class="MathJax_Preview">\mathbf{R}_t</span><script type="math/tex">\mathbf{R}_t</script></span>는 회전 행렬, 
   - <span class="arithmatex"><span class="MathJax_Preview">\mathbf{b}_a</span><script type="math/tex">\mathbf{b}_a</script></span>와 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{b}_\omega</span><script type="math/tex">\mathbf{b}_\omega</script></span>는 각각 가속도와 각속도의 바이어스(드리프트)를 나타낸다.</p>
<p>상태 공간에 바이어스 변수 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{b}_a</span><script type="math/tex">\mathbf{b}_a</script></span>와 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{b}_\omega</span><script type="math/tex">\mathbf{b}_\omega</script></span>를 포함시킴으로써, IMU의 드리프트를 지속적으로 추정하고 보정할 수 있다.</p>
<h3 id="15-fast-livo">15. FAST-LIVO에서의 데이터 융합 프레임워크</h3>
<p>FAST-LIVO에서 LiDAR, VIO, IMU 데이터를 융합하는 과정은 주로 <strong>비율가중합(Weighted Fusion)</strong> 방식으로 이루어진다. 각 센서가 제공하는 데이터는 불확실성에 따라 가중치가 부여되며, 이 가중치를 기반으로 융합이 이루어진다. 이 과정은 각 센서의 장단점을 보완하여 더욱 정밀한 위치 추정을 가능하게 한다.</p>
<h4 id="_1">가중치 기반 센서 융합</h4>
<p>각 센서의 데이터는 불확실성을 반영한 가중치 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{W}_i</span><script type="math/tex">\mathbf{W}_i</script></span>가 부여된다. 이 가중치는 해당 센서 데이터의 신뢰도를 나타내며, LiDAR, VIO, IMU 데이터가 상호 보완적으로 결합된다. 가중치 기반 융합은 다음과 같은 수식으로 표현된다:</p>
<div class="arithmatex">
<div class="MathJax_Preview">
\mathbf{X}_t = \sum_{i} \mathbf{W}_i \mathbf{X}_t^i
</div>
<script type="math/tex; mode=display">
\mathbf{X}_t = \sum_{i} \mathbf{W}_i \mathbf{X}_t^i
</script>
</div>
<p>여기서,
- <span class="arithmatex"><span class="MathJax_Preview">\mathbf{X}_t</span><script type="math/tex">\mathbf{X}_t</script></span>는 최종 융합된 위치 및 자세 추정 값,
- <span class="arithmatex"><span class="MathJax_Preview">\mathbf{X}_t^i</span><script type="math/tex">\mathbf{X}_t^i</script></span>는 각 센서(i: LiDAR, VIO, IMU)로부터 얻어진 추정 값,
- <span class="arithmatex"><span class="MathJax_Preview">\mathbf{W}_i</span><script type="math/tex">\mathbf{W}_i</script></span>는 각 센서의 불확실성에 반비례하는 가중치이다.</p>
<p>이 과정에서 각 센서가 제공하는 정보의 신뢰도가 다르게 반영되며, 불확실성이 큰 센서 데이터는 적은 비중으로, 신뢰도가 높은 센서 데이터는 더 큰 비중으로 융합된다.</p>
<h4 id="_2">확률적 센서 융합</h4>
<p>FAST-LIVO는 또한 확률적 모델을 기반으로 각 센서의 데이터를 결합한다. 각 센서로부터 얻은 측정값은 확률 분포로 모델링되며, 이를 기반으로 상태 변수를 추정한다. 확률적 센서 융합은 일반적으로 <strong>베이지안 필터링</strong> 기법을 사용하여 수행되며, 이는 다음과 같은 형태로 표현된다:</p>
<div class="arithmatex">
<div class="MathJax_Preview">
p(\mathbf{X}_t | \mathbf{Z}_t) = \frac{p(\mathbf{Z}_t | \mathbf{X}_t) p(\mathbf{X}_{t-1})}{p(\mathbf{Z}_t)}
</div>
<script type="math/tex; mode=display">
p(\mathbf{X}_t | \mathbf{Z}_t) = \frac{p(\mathbf{Z}_t | \mathbf{X}_t) p(\mathbf{X}_{t-1})}{p(\mathbf{Z}_t)}
</script>
</div>
<p>여기서,
- <span class="arithmatex"><span class="MathJax_Preview">p(\mathbf{X}_t | \mathbf{Z}_t)</span><script type="math/tex">p(\mathbf{X}_t | \mathbf{Z}_t)</script></span>는 주어진 센서 측정값 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{Z}_t</span><script type="math/tex">\mathbf{Z}_t</script></span>에 대한 상태 변수 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{X}_t</span><script type="math/tex">\mathbf{X}_t</script></span>의 사후 확률 분포,
- <span class="arithmatex"><span class="MathJax_Preview">p(\mathbf{Z}_t | \mathbf{X}_t)</span><script type="math/tex">p(\mathbf{Z}_t | \mathbf{X}_t)</script></span>는 측정 모델(센서 데이터가 주어진 상태에서의 확률),
- <span class="arithmatex"><span class="MathJax_Preview">p(\mathbf{X}_{t-1})</span><script type="math/tex">p(\mathbf{X}_{t-1})</script></span>는 이전 시점에서의 상태 추정 값이다.</p>
<p>FAST-LIVO는 이러한 베이지안 필터링 과정을 통해 각 센서 데이터를 융합하며, 이를 통해 보다 신뢰할 수 있는 위치 추정을 수행한다.</p>
<h3 id="16-slam">16. SLAM과 비슷한 확률적 지도 작성 과정</h3>
<p>FAST-LIVO는 SLAM 문제를 해결하기 위해 지도 작성(map building)을 수행하며, 이 과정은 주로 LiDAR 데이터를 기반으로 한다. 지도 작성은 환경의 구조를 이해하고 로봇의 위치를 지속적으로 추정하기 위한 중요한 요소이다. </p>
<p>LiDAR로부터 수집된 포인트 클라우드는 환경의 3D 모델을 생성하는 데 사용되며, 이 3D 모델은 로봇이 이동할 때 계속해서 업데이트된다. FAST-LIVO에서는 LiDAR 데이터를 기반으로 한 3D 포인트 클라우드 맵을 작성하며, 이 지도는 다음과 같이 수학적으로 표현될 수 있다:</p>
<div class="arithmatex">
<div class="MathJax_Preview">
\mathbf{M}_t = \mathbf{M}_{t-1} \cup \mathbf{P}_t
</div>
<script type="math/tex; mode=display">
\mathbf{M}_t = \mathbf{M}_{t-1} \cup \mathbf{P}_t
</script>
</div>
<p>여기서,
- <span class="arithmatex"><span class="MathJax_Preview">\mathbf{M}_t</span><script type="math/tex">\mathbf{M}_t</script></span>는 시점 <span class="arithmatex"><span class="MathJax_Preview">t</span><script type="math/tex">t</script></span>에서의 지도(맵),
- <span class="arithmatex"><span class="MathJax_Preview">\mathbf{P}_t</span><script type="math/tex">\mathbf{P}_t</script></span>는 시점 <span class="arithmatex"><span class="MathJax_Preview">t</span><script type="math/tex">t</script></span>에서 LiDAR로부터 새롭게 얻은 포인트 클라우드 데이터이다.</p>
<p>새로운 포인트 클라우드는 기존 지도에 통합되며, 이를 통해 환경의 정확한 모델을 작성한다.</p>
<p>지도 작성 과정은 로봇이 이동하면서 얻은 포인트 클라우드를 정렬하고, 중복된 정보를 제거하는 방식으로 진행된다. 이 과정에서 <strong>ICP(Iterative Closest Point)</strong> 알고리즘과 같은 정합 기법이 사용된다. ICP 알고리즘은 두 포인트 클라우드를 비교하여, 최적의 회전 및 평행 이동 변환을 계산하여 정렬한다.</p>
<p>지도 작성은 또한 로봇의 위치 추정과 상호작용하며, SLAM 문제의 본질인 위치 추정과 환경 모델링을 동시에 해결한다. </p>
<h3 id="17-fast-livo-loop-closure">17. FAST-LIVO의 루프 클로저(Loop Closure) 기법</h3>
<p>FAST-LIVO에서 중요한 또 하나의 개념은 <strong>루프 클로저(Loop Closure)</strong>이다. 루프 클로저는 로봇이 이미 지나갔던 경로를 다시 통과할 때 발생하는 현상으로, SLAM 시스템에서는 이러한 반복적인 경로를 인식하여 로봇의 위치 추정 오차를 줄이는 데 중요한 역할을 한다. 루프 클로저가 적절히 처리되면, 오랜 시간 동안 축적된 위치 추정의 드리프트를 줄일 수 있다.</p>
<p>루프 클로저 과정은 다음과 같은 단계로 이루어진다:</p>
<ol>
<li>
<p><strong>루프 감지</strong>: 로봇이 이미 지나갔던 위치를 다시 방문했음을 감지한다. 이 과정에서 로봇의 현재 위치와 과거의 위치 간의 유사성을 비교하여, 두 위치가 동일한 환경에 있다는 사실을 확인한다. 이를 위해 LiDAR 데이터나 카메라 영상에서 얻은 특징점을 비교한다.</p>
</li>
<li>
<p><strong>정합(Alignment)</strong>: 감지된 루프 클로저 지점을 기준으로 로봇의 현재 위치와 과거 위치 간의 변환을 계산한다. 이 단계에서 주로 <strong>ICP(Iterative Closest Point)</strong> 알고리즘이나 <strong>RANSAC</strong> 같은 알고리즘을 사용하여, 두 지점 간의 최적의 변환 행렬을 찾는다.</p>
</li>
</ol>
<p>이 변환 행렬은 다음과 같이 표현될 수 있다:</p>
<div class="arithmatex">
<div class="MathJax_Preview">
   \mathbf{T}_{LC} = \begin{bmatrix} \mathbf{R}_{LC} &amp; \mathbf{t}_{LC} \\ 0 &amp; 1 \end{bmatrix}
</div>
<script type="math/tex; mode=display">
   \mathbf{T}_{LC} = \begin{bmatrix} \mathbf{R}_{LC} & \mathbf{t}_{LC} \\ 0 & 1 \end{bmatrix}
</script>
</div>
<p>여기서, <span class="arithmatex"><span class="MathJax_Preview">\mathbf{T}_{LC}</span><script type="math/tex">\mathbf{T}_{LC}</script></span>는 루프 클로저 변환 행렬, <span class="arithmatex"><span class="MathJax_Preview">\mathbf{R}_{LC}</span><script type="math/tex">\mathbf{R}_{LC}</script></span>는 회전 행렬, <span class="arithmatex"><span class="MathJax_Preview">\mathbf{t}_{LC}</span><script type="math/tex">\mathbf{t}_{LC}</script></span>는 평행 이동 벡터이다.</p>
<ol>
<li><strong>그래프 최적화</strong>: 루프 클로저에서 얻어진 변환을 SLAM 시스템의 그래프에 반영하여, 전역적으로 로봇의 위치 추정을 최적화한다. 이를 위해 <strong>포즈 그래프(Pose Graph)</strong> 기반 최적화 기법을 사용하며, 이 과정은 다음과 같은 형태의 최적화 문제로 표현된다.</li>
</ol>
<p>포즈 그래프에서 각 노드는 로봇의 위치(포즈)를 나타내며, 엣지는 서로 다른 시점에서의 위치 변환을 나타낸다. 루프 클로저에 의해 새롭게 발견된 변환 엣지 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{T}_{LC}</span><script type="math/tex">\mathbf{T}_{LC}</script></span>는 기존 그래프에 추가되고, 다음 최적화 문제가 정의된다:</p>
<div class="arithmatex">
<div class="MathJax_Preview">
   \min_{\mathbf{X}} \sum_{(i,j) \in \mathcal{E}} \left\| \mathbf{T}_{ij} - f(\mathbf{X}_i, \mathbf{X}_j) \right\|^2
</div>
<script type="math/tex; mode=display">
   \min_{\mathbf{X}} \sum_{(i,j) \in \mathcal{E}} \left\| \mathbf{T}_{ij} - f(\mathbf{X}_i, \mathbf{X}_j) \right\|^2
</script>
</div>
<p>여기서,
   - <span class="arithmatex"><span class="MathJax_Preview">\mathbf{X}_i</span><script type="math/tex">\mathbf{X}_i</script></span>와 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{X}_j</span><script type="math/tex">\mathbf{X}_j</script></span>는 그래프에서 각각 노드 <span class="arithmatex"><span class="MathJax_Preview">i</span><script type="math/tex">i</script></span>와 <span class="arithmatex"><span class="MathJax_Preview">j</span><script type="math/tex">j</script></span>의 위치(포즈),
   - <span class="arithmatex"><span class="MathJax_Preview">\mathbf{T}_{ij}</span><script type="math/tex">\mathbf{T}_{ij}</script></span>는 노드 <span class="arithmatex"><span class="MathJax_Preview">i</span><script type="math/tex">i</script></span>와 <span class="arithmatex"><span class="MathJax_Preview">j</span><script type="math/tex">j</script></span> 간의 변환 행렬,
   - <span class="arithmatex"><span class="MathJax_Preview">\mathcal{E}</span><script type="math/tex">\mathcal{E}</script></span>는 그래프 상에서 정의된 엣지들의 집합이다.</p>
<p>이 최적화 과정을 통해, 로봇의 과거 위치와 현재 위치를 일관성 있게 연결하며, 루프 클로저를 통해 위치 추정 오차를 감소시킨다.</p>
<h3 id="18-fast-livo">18. FAST-LIVO의 분산 처리 구조</h3>
<p>FAST-LIVO는 실시간으로 동작해야 하기 때문에, 센서 데이터의 처리를 효율적으로 분산하여 계산하는 구조가 필수적이다. 이를 위해 FAST-LIVO는 다중 스레드(Multi-threading)나 분산 처리 기법을 활용하여 각 센서의 데이터를 병렬적으로 처리하고, 최적화 과정도 효율적으로 분할하여 수행한다.</p>
<h4 id="_3">멀티 스레드 기반 처리</h4>
<p>FAST-LIVO는 LiDAR, VIO, IMU 데이터를 각각 별도의 스레드에서 처리한다. 이 스레드 간의 데이터 흐름은 다음과 같은 형태로 이루어진다:</p>
<ul>
<li><strong>LiDAR 스레드</strong>: LiDAR 데이터의 포인트 클라우드를 수집하고, 이를 처리하여 특징점 추출과 Odometry 계산을 수행한다.</li>
<li><strong>VIO 스레드</strong>: 카메라 영상과 IMU 데이터를 기반으로 VIO 처리를 수행하며, IMU의 자세 추정과 카메라 특징점 추적을 통해 위치 변화를 계산한다.</li>
<li><strong>IMU 스레드</strong>: IMU 데이터를 고주파수로 처리하여 가속도 및 각속도 정보를 수집하고, 이를 기반으로 로봇의 자세 변화를 계산한다.</li>
</ul>
<p>이렇게 각 스레드에서 독립적으로 데이터를 처리한 후, 최종적으로 위치 추정 단계에서 모든 데이터를 통합한다. 이 구조는 실시간 시스템에서 필수적인 낮은 지연 시간을 보장하면서도 각 센서의 데이터를 효율적으로 처리할 수 있도록 설계되었다.</p>
<h4 id="_4">데이터 파이프라인</h4>
<p>FAST-LIVO는 각 센서로부터 수집된 데이터를 처리하기 위한 <strong>데이터 파이프라인</strong>을 구축한다. 이 파이프라인은 센서 데이터의 입력에서부터 최종적인 위치 추정까지의 흐름을 정의하며, 주어진 자율 주행 로봇의 상황에 맞게 최적화된다. 파이프라인의 구조는 다음과 같다:</p>
<div class="mermaid">graph TD
    A[LiDAR Data] --&gt; B[LiDAR Odometry]
    C[IMU Data] --&gt; D[IMU Integration]
    E[Camera Data] --&gt; F[VIO Processing]
    B --&gt; G[Sensor Fusion]
    D --&gt; G
    F --&gt; G
    G --&gt; H[Global Pose Estimation]
</div>
<p>이 파이프라인을 통해 LiDAR, IMU, 카메라 데이터가 서로 다른 스레드에서 처리되면서 최종적으로 융합되어 로봇의 위치와 자세를 추정한다.</p>
<h3 id="19-fast-livo">19. FAST-LIVO의 확장성</h3>
<p>FAST-LIVO는 다양한 로봇 플랫폼에서 적용 가능하도록 설계되었으며, 여러 가지 센서 구성에서도 유연하게 동작할 수 있는 확장성을 가지고 있다. FAST-LIVO는 센서 수가 늘어나거나, 더 고도화된 센서가 추가되더라도 쉽게 통합할 수 있는 구조로 설계되었다.</p>
<h4 id="_5">센서 추가와 확장</h4>
<p>FAST-LIVO는 새로운 센서를 추가하거나 기존 센서의 데이터를 확장할 때, 간단한 모듈 확장을 통해 이를 지원한다. 예를 들어, 더 높은 해상도를 제공하는 LiDAR 센서를 추가하거나, 여러 대의 카메라를 결합한 스테레오 카메라 시스템을 추가하는 경우에도 쉽게 적용할 수 있다.</p>
<p>새로운 센서가 추가되면, 해당 센서로부터 얻어진 데이터는 기존의 센서 융합 파이프라인에 추가되며, 기존의 최적화 과정에 새로운 센서의 측정값을 반영하는 방식으로 동작한다.</p>
<h4 id="_6">이동 로봇 및 드론에의 적용</h4>
<p>FAST-LIVO는 지상 이동 로봇뿐만 아니라 드론과 같은 공중 로봇에도 적용될 수 있도록 설계되었다. 드론의 경우 IMU의 정보가 더욱 중요한 역할을 하며, FAST-LIVO는 이러한 다양한 플랫폼에 맞게 센서 융합 알고리즘을 조정할 수 있다.</p>
<p>예를 들어, 드론에서는 고도 변화가 중요한 정보가 되기 때문에 LiDAR와 IMU 간의 데이터 융합이 더 긴밀하게 이루어지며, 이를 통해 3D 공간에서의 정밀한 위치 추정이 가능해진다.</p>
<br/>
<div aria-label="navigation" class="row wm-article-nav-buttons" role="navigation">
<div class="wm-article-nav pull-right">
<a class="btn btn-xs btn-default pull-right" href="../0204/">
        Next
        <i aria-hidden="true" class="fa fa-chevron-right"></i>
</a>
<a class="btn btn-xs btn-link" href="../0204/">
        FAST-LIVO의 장점과 한계
      </a>
</div>
<div class="wm-article-nav">
<a class="btn btn-xs btn-default pull-left" href="../0202/">
<i aria-hidden="true" class="fa fa-chevron-left"></i>
        Previous</a><a class="btn btn-xs btn-link" href="../0202/">
        LiDAR 기반의 자율 주행 기술 개요
      </a>
</div>
</div>
<br/>
</div>
<footer class="container-fluid wm-page-content">
<p>Documentation built with <a href="https://www.mkdocs.org/">MkDocs</a> using <a href="https://github.com/gristlabs/mkdocs-windmill">Windmill</a> theme by Grist Labs.</p>
</footer>
<script type="module">import mermaid from "https://unpkg.com/mermaid@10.4.0/dist/mermaid.esm.min.mjs";
mermaid.initialize({});</script></body>
</html>