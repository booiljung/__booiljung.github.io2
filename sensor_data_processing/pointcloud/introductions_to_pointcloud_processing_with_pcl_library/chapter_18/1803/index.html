<!DOCTYPE html>
<html lang="en">
<head>
  
  
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    
    
    <link rel="canonical" href="https://booiljung.github.io/sensor_data_processing/pointcloud/introductions_to_pointcloud_processing_with_pcl_library/chapter_18/1803/">
    <link rel="shortcut icon" href="../../../../../img/favicon.ico">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" />
    <title>머신러닝 기반의 클러스터링과 분류 - 소프트웨어 융합</title>
    <link href="../../../../../css/bootstrap-3.3.7.min.css" rel="stylesheet">
    <link href="../../../../../css/font-awesome-4.7.0.css" rel="stylesheet">
    <link href="../../../../../css/base.css" rel="stylesheet">
    <link rel="stylesheet" href="../../../../../css/highlight.css">
    <link href="../../../../../css/custom.css" rel="stylesheet">
    <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.3.0/respond.min.js"></script>
    <![endif]-->

    <script src="../../../../../js/jquery-3.2.1.min.js"></script>
    <script src="../../../../../js/bootstrap-3.3.7.min.js"></script>
    <script src="../../../../../js/highlight.pack.js"></script>
    
    <base target="_top">
    <script>
      var base_url = '../../../../..';
      var is_top_frame = false;
        
        var pageToc = [
          {title: "\ud074\ub7ec\uc2a4\ud130\ub9c1 \uae30\ubc95", url: "#_top", children: [
              {title: "K-\ud3c9\uade0 \ud074\ub7ec\uc2a4\ud130\ub9c1 (K-Means Clustering)", url: "#k-k-means-clustering" },
              {title: "DBSCAN (Density-Based Spatial Clustering of Applications with Noise)", url: "#dbscan-density-based-spatial-clustering-of-applications-with-noise" },
              {title: "GMM (Gaussian Mixture Model)", url: "#gmm-gaussian-mixture-model" },
          ]},
          {title: "\ubd84\ub958 \uae30\ubc95", url: "#_2", children: [
              {title: "SVM (Support Vector Machine)", url: "#svm-support-vector-machine" },
              {title: "Random Forest", url: "#random-forest" },
              {title: "\ub525\ub7ec\ub2dd \uae30\ubc18 \ubd84\ub958", url: "#_3" },
          ]},
          {title: "\ud2b9\uc131 \ucd94\ucd9c\uacfc \uc804\ucc98\ub9ac", url: "#_4", children: [
              {title: "\uc804\ucc98\ub9ac \ub2e8\uacc4", url: "#_5" },
          ]},
          {title: "\ud074\ub7ec\uc2a4\ud130\ub9c1\uacfc \ubd84\ub958\uc758 \uc751\uc6a9 \uc0ac\ub840", url: "#_6", children: [
              {title: "\uc790\uc728\uc8fc\ud589\ucc28", url: "#_7" },
              {title: "\uac74\ucd95 \ubc0f \ud1a0\ubaa9 \uacf5\ud559", url: "#_8" },
              {title: "\ub85c\ubd07 \uacf5\ud559", url: "#_9" },
              {title: "\uc758\ub8cc \uc601\uc0c1 \ucc98\ub9ac", url: "#_10" },
          ]},
          {title: "\ud074\ub7ec\uc2a4\ud130\ub9c1\uacfc \ubd84\ub958\ub97c \uc704\ud55c \uc131\ub2a5 \ud3c9\uac00 \uc9c0\ud45c", url: "#_11", children: [
              {title: "\ud074\ub7ec\uc2a4\ud130\ub9c1 \uc131\ub2a5 \ud3c9\uac00", url: "#_12" },
              {title: "\ubd84\ub958 \uc131\ub2a5 \ud3c9\uac00", url: "#_13" },
          ]},
        ];

    </script>
    <script src="../../../../../js/base.js"></script>
      <script src="../../../../../js/google_analytics.js"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML"></script>
      <script src="https://www.googletagmanager.com/gtag/js?id=G-3F4LHCTF88"></script> 
</head>

<body>
<script>
if (is_top_frame) { $('body').addClass('wm-top-page'); }
</script>



<div class="container-fluid wm-page-content">
  <a name="_top"></a>
    

    
    
      
    

  <div class="row wm-article-nav-buttons" role="navigation" aria-label="navigation">
    
    <div class="wm-article-nav pull-right">
      <a href="../1804/" class="btn btn-xs btn-default pull-right">
        Next
        <i class="fa fa-chevron-right" aria-hidden="true"></i>
      </a>
      <a href="../1804/" class="btn btn-xs btn-link">
        PCL과 AI의 통합 활용 사례
      </a>
    </div>
    
    <div class="wm-article-nav">
      <a href="../1802/" class="btn btn-xs btn-default pull-left">
        <i class="fa fa-chevron-left" aria-hidden="true"></i>
        Previous</a><a href="../1802/" class="btn btn-xs btn-link">
        신경망을 활용한 객체 인식
      </a>
    </div>
    
  </div>

    

    <p>머신러닝을 활용한 클러스터링과 분류는 포인트 클라우드 데이터 처리에서 매우 중요한 역할을 한다. 이를 통해 포인트 클라우드 상의 객체들을 자동으로 그룹화하거나 특정 클래스에 할당하는 작업이 가능해진다. 이러한 기법은 특히 대용량의 포인트 클라우드를 실시간으로 처리하거나 자동화된 분석이 필요한 응용에서 유용하다.</p>
<h3 id="_1">클러스터링 기법</h3>
<p>클러스터링은 레이블이 없는 데이터를 바탕으로 유사한 포인트들을 그룹화하는 비지도 학습 방법이다. 포인트 클라우드에서의 클러스터링은 3차원 공간에서의 밀집도, 거리를 기반으로 하며, 대표적인 알고리즘으로는 K-평균 클러스터링, DBSCAN, 그리고 Gaussian Mixture Model (GMM) 등이 있다.</p>
<h4 id="k-k-means-clustering">K-평균 클러스터링 (K-Means Clustering)</h4>
<p>K-평균 클러스터링은 미리 정해진 <span class="arithmatex"><span class="MathJax_Preview">K</span><script type="math/tex">K</script></span> 개의 군집 중심을 기준으로 포인트들을 할당하는 방식이다. 포인트 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{p}_i</span><script type="math/tex">\mathbf{p}_i</script></span>에 대해 <span class="arithmatex"><span class="MathJax_Preview">K</span><script type="math/tex">K</script></span>개의 중심 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{c}_k</span><script type="math/tex">\mathbf{c}_k</script></span>와의 유클리드 거리를 계산하고, 가장 가까운 중심에 포인트를 할당하는 과정을 반복하여 수렴한다.</p>
<p>목표 함수는 다음과 같다:</p>
<div class="arithmatex">
<div class="MathJax_Preview">
J = \sum_{i=1}^{N} \sum_{k=1}^{K} r_{ik} \|\mathbf{p}_i - \mathbf{c}_k\|^2
</div>
<script type="math/tex; mode=display">
J = \sum_{i=1}^{N} \sum_{k=1}^{K} r_{ik} \|\mathbf{p}_i - \mathbf{c}_k\|^2
</script>
</div>
<p>여기서 <span class="arithmatex"><span class="MathJax_Preview">r_{ik}</span><script type="math/tex">r_{ik}</script></span>는 포인트 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{p}_i</span><script type="math/tex">\mathbf{p}_i</script></span>가 클러스터 <span class="arithmatex"><span class="MathJax_Preview">k</span><script type="math/tex">k</script></span>에 속하는지 여부를 나타내는 바이너리 변수이다. K-평균 클러스터링은 반복적으로 포인트와 군집 중심 간의 거리를 최소화하는 방식으로 작동한다.</p>
<p>그러나 K-평균 클러스터링은 초기 군집 중심의 위치에 매우 민감하며, 구형으로 클러스터가 형성되는 것을 가정하므로, 비구형의 클러스터가 많은 포인트 클라우드에서는 성능이 떨어질 수 있다.</p>
<h4 id="dbscan-density-based-spatial-clustering-of-applications-with-noise">DBSCAN (Density-Based Spatial Clustering of Applications with Noise)</h4>
<p>DBSCAN은 밀집 기반 클러스터링 기법으로, 밀집된 지역을 클러스터로 정의하고, 밀도가 낮은 포인트들을 노이즈로 간주한다. 이 방법은 K-평균과 달리 클러스터의 개수를 미리 정할 필요가 없으며, 비구형 클러스터에도 강한 성능을 발휘한다.</p>
<p>DBSCAN의 주요 파라미터는 두 가지이다:
- <span class="arithmatex"><span class="MathJax_Preview">\epsilon</span><script type="math/tex">\epsilon</script></span>: 클러스터로 간주되는 포인트 간의 최대 거리
- <span class="arithmatex"><span class="MathJax_Preview">\text{minPts}</span><script type="math/tex">\text{minPts}</script></span>: 한 클러스터가 형성되기 위해 필요한 최소 포인트 수</p>
<p>알고리즘은 한 포인트에서 시작하여 <span class="arithmatex"><span class="MathJax_Preview">\epsilon</span><script type="math/tex">\epsilon</script></span> 거리 내에 최소 <span class="arithmatex"><span class="MathJax_Preview">\text{minPts}</span><script type="math/tex">\text{minPts}</script></span> 이상의 포인트가 있을 경우 해당 포인트들을 클러스터로 묶는다. 그 후 인접 포인트들로 클러스터를 확장해 나가는 방식이다. 노이즈 포인트들은 어떤 클러스터에도 속하지 않으며, 이를 통해 복잡한 구조를 가진 포인트 클라우드에서도 유연하게 클러스터를 찾을 수 있다.</p>
<p>DBSCAN의 수학적 설명은 다음과 같다. 두 포인트 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{p}_i</span><script type="math/tex">\mathbf{p}_i</script></span>와 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{p}_j</span><script type="math/tex">\mathbf{p}_j</script></span>가 <span class="arithmatex"><span class="MathJax_Preview">\epsilon</span><script type="math/tex">\epsilon</script></span> 이내에 있을 때:</p>
<div class="arithmatex">
<div class="MathJax_Preview">
\|\mathbf{p}_i - \mathbf{p}_j\| \leq \epsilon
</div>
<script type="math/tex; mode=display">
\|\mathbf{p}_i - \mathbf{p}_j\| \leq \epsilon
</script>
</div>
<p>이 조건을 만족하는 포인트가 <span class="arithmatex"><span class="MathJax_Preview">\text{minPts}</span><script type="math/tex">\text{minPts}</script></span> 이상일 경우, 해당 포인트는 코어 포인트가 되며, 클러스터 확장을 시작한다.</p>
<h4 id="gmm-gaussian-mixture-model">GMM (Gaussian Mixture Model)</h4>
<p>GMM은 데이터가 여러 개의 다변량 정규분포로부터 생성되었다고 가정하여 클러스터링을 수행하는 기법이다. 각 포인트 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{p}_i</span><script type="math/tex">\mathbf{p}_i</script></span>는 여러 개의 가우시안 분포 중 하나로부터 생성되었다고 가정하며, 이는 다음과 같은 혼합 모델로 표현된다:</p>
<div class="arithmatex">
<div class="MathJax_Preview">
p(\mathbf{p}_i) = \sum_{k=1}^{K} \pi_k \mathcal{N}(\mathbf{p}_i | \boldsymbol{\mu}_k, \boldsymbol{\Sigma}_k)
</div>
<script type="math/tex; mode=display">
p(\mathbf{p}_i) = \sum_{k=1}^{K} \pi_k \mathcal{N}(\mathbf{p}_i | \boldsymbol{\mu}_k, \boldsymbol{\Sigma}_k)
</script>
</div>
<p>여기서 <span class="arithmatex"><span class="MathJax_Preview">\pi_k</span><script type="math/tex">\pi_k</script></span>는 혼합 계수이며, <span class="arithmatex"><span class="MathJax_Preview">\mathcal{N}(\mathbf{p}_i | \boldsymbol{\mu}_k, \boldsymbol{\Sigma}_k)</span><script type="math/tex">\mathcal{N}(\mathbf{p}_i | \boldsymbol{\mu}_k, \boldsymbol{\Sigma}_k)</script></span>는 평균 <span class="arithmatex"><span class="MathJax_Preview">\boldsymbol{\mu}_k</span><script type="math/tex">\boldsymbol{\mu}_k</script></span>, 공분산 <span class="arithmatex"><span class="MathJax_Preview">\boldsymbol{\Sigma}_k</span><script type="math/tex">\boldsymbol{\Sigma}_k</script></span>를 가진 가우시안 분포이다. GMM은 EM(Expectation-Maximization) 알고리즘을 통해 각 포인트가 특정 가우시안 분포에 속할 확률을 추정한다.</p>
<p>이러한 방법은 포인트 클라우드에서의 클러스터링 시, 클러스터가 구형이 아닌 다양한 형태일 때 유용하다. 그러나 GMM의 성능은 가우시안 분포의 수와 초기 값 설정에 크게 의존한다.</p>
<h3 id="_2">분류 기법</h3>
<p>포인트 클라우드 분류는 주어진 포인트들이 특정 클래스에 속하는지 여부를 결정하는 작업으로, 주로 지도 학습 기법이 사용된다. 대표적인 알고리즘으로는 Support Vector Machine (SVM), Random Forest, 그리고 최근 많이 사용되는 딥러닝 기반 방법들이 있다.</p>
<h4 id="svm-support-vector-machine">SVM (Support Vector Machine)</h4>
<p>SVM은 포인트 간의 경계면을 정의하여 각 포인트가 속하는 클래스를 결정하는 지도 학습 방법이다. 주어진 학습 데이터 <span class="arithmatex"><span class="MathJax_Preview">(\mathbf{p}_i, y_i)</span><script type="math/tex">(\mathbf{p}_i, y_i)</script></span>에서 <span class="arithmatex"><span class="MathJax_Preview">y_i \in \{-1, 1\}</span><script type="math/tex">y_i \in \{-1, 1\}</script></span>는 포인트의 클래스 레이블을 의미하며, SVM은 두 클래스 간의 최대 마진을 가지는 초평면을 찾는 것이 목표다. 초평면은 다음과 같은 형태로 정의된다:</p>
<div class="arithmatex">
<div class="MathJax_Preview">
\mathbf{w}^T \mathbf{p} + b = 0
</div>
<script type="math/tex; mode=display">
\mathbf{w}^T \mathbf{p} + b = 0
</script>
</div>
<p>여기서 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{w}</span><script type="math/tex">\mathbf{w}</script></span>는 초평면의 법선 벡터, <span class="arithmatex"><span class="MathJax_Preview">b</span><script type="math/tex">b</script></span>는 절편이다. 목표는 초평면을 통해 두 클래스를 분리하되, 마진 <span class="arithmatex"><span class="MathJax_Preview">\frac{2}{\|\mathbf{w}\|}</span><script type="math/tex">\frac{2}{\|\mathbf{w}\|}</script></span>를 최대화하는 것이다. 이를 위해 최적화해야 할 라그랑주 함수는 다음과 같다:</p>
<div class="arithmatex">
<div class="MathJax_Preview">
L(\mathbf{w}, b, \lambda) = \frac{1}{2} \|\mathbf{w}\|^2 - \sum_{i=1}^{N} \lambda_i [y_i (\mathbf{w}^T \mathbf{p}_i + b) - 1]
</div>
<script type="math/tex; mode=display">
L(\mathbf{w}, b, \lambda) = \frac{1}{2} \|\mathbf{w}\|^2 - \sum_{i=1}^{N} \lambda_i [y_i (\mathbf{w}^T \mathbf{p}_i + b) - 1]
</script>
</div>
<p>여기서 <span class="arithmatex"><span class="MathJax_Preview">\lambda_i</span><script type="math/tex">\lambda_i</script></span>는 라그랑주 승수이다. SVM은 주로 2개의 클래스를 분류하지만, 다중 클래스 분류 문제에서도 확장 가능하다. </p>
<h4 id="random-forest">Random Forest</h4>
<p>Random Forest는 앙상블 학습 방법의 하나로, 다수의 의사결정 트리(Decision Trees)를 결합하여 분류 성능을 높이는 방법이다. 이 알고리즘은 데이터의 서브셋을 사용해 여러 개의 결정 트리를 학습한 뒤, 각 트리의 예측 결과를 종합하여 최종 클래스를 결정한다. 랜덤 포레스트는 포인트 클라우드 데이터의 고차원적이고 복잡한 특성을 학습하기에 적합하며, 노이즈에 강하고, 과적합(overfitting)을 방지할 수 있는 장점이 있다.</p>
<p>각 결정 트리에서 사용되는 특징 공간(feature space)은 전체 특징의 일부로 무작위 선택되며, 이를 통해 다양한 트리들이 생성된다. 학습된 트리들은 서로 다른 포인트에 대해 서로 다른 예측을 할 수 있으며, 최종 결정은 다수결 투표 방식으로 이루어진다.</p>
<p>의사결정 트리에서 노드는 포인트 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{p}_i</span><script type="math/tex">\mathbf{p}_i</script></span>가 속하는 클래스 <span class="arithmatex"><span class="MathJax_Preview">y_i</span><script type="math/tex">y_i</script></span>를 결정하는데, 트리의 각 분기는 특징 <span class="arithmatex"><span class="MathJax_Preview">x_j</span><script type="math/tex">x_j</script></span>에 대한 조건을 기반으로 한다. 노드에서의 분기 기준은 엔트로피(entropy)나 지니 계수(Gini impurity)를 최소화하는 방향으로 선택된다. 엔트로피는 다음과 같이 정의된다:</p>
<div class="arithmatex">
<div class="MathJax_Preview">
H(p) = - \sum_{k=1}^{K} p_k \log p_k
</div>
<script type="math/tex; mode=display">
H(p) = - \sum_{k=1}^{K} p_k \log p_k
</script>
</div>
<p>여기서 <span class="arithmatex"><span class="MathJax_Preview">p_k</span><script type="math/tex">p_k</script></span>는 클래스 <span class="arithmatex"><span class="MathJax_Preview">k</span><script type="math/tex">k</script></span>에 속할 확률이다. 지니 계수는 다음과 같다:</p>
<div class="arithmatex">
<div class="MathJax_Preview">
G(p) = 1 - \sum_{k=1}^{K} p_k^2
</div>
<script type="math/tex; mode=display">
G(p) = 1 - \sum_{k=1}^{K} p_k^2
</script>
</div>
<p>Random Forest는 특히 다차원 데이터의 다양한 특성을 잘 반영하기 때문에, 포인트 클라우드 분류에 있어 강력한 성능을 보여준다.</p>
<h4 id="_3">딥러닝 기반 분류</h4>
<p>최근에는 포인트 클라우드 데이터를 처리하기 위해 딥러닝 모델을 사용하는 것이 널리 퍼지고 있다. 특히, PointNet과 같은 신경망 구조는 포인트 클라우드 데이터를 직접적으로 다룰 수 있도록 설계되었다. PointNet은 각 포인트의 위치 정보를 네트워크에 입력으로 주어, 포인트 클라우드 전체를 고려한 글로벌 피처 벡터를 추출하고, 이를 통해 각 포인트가 속하는 클래스를 예측한다.</p>
<p>PointNet의 주요 수식은 다음과 같다. 포인트 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{p}_i \in \mathbb{R}^3</span><script type="math/tex">\mathbf{p}_i \in \mathbb{R}^3</script></span>에 대해, 각 포인트는 신경망의 입력으로 주어지며, 이를 통해 임베딩 벡터 <span class="arithmatex"><span class="MathJax_Preview">f(\mathbf{p}_i)</span><script type="math/tex">f(\mathbf{p}_i)</script></span>가 얻어진다. 이러한 임베딩 벡터들은 max-pooling 연산을 통해 통합되어 글로벌 피처 벡터 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{h}</span><script type="math/tex">\mathbf{h}</script></span>를 생성한다:</p>
<div class="arithmatex">
<div class="MathJax_Preview">
\mathbf{h} = \text{maxpool}(f(\mathbf{p}_1), f(\mathbf{p}_2), \dots, f(\mathbf{p}_N))
</div>
<script type="math/tex; mode=display">
\mathbf{h} = \text{maxpool}(f(\mathbf{p}_1), f(\mathbf{p}_2), \dots, f(\mathbf{p}_N))
</script>
</div>
<p>이 글로벌 피처 벡터 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{h}</span><script type="math/tex">\mathbf{h}</script></span>는 이후 fully connected layer를 거쳐 최종 분류 결과를 출력한다.</p>
<p>PointNet 이후에는 PointNet++와 같은 후속 연구들이 등장하여 포인트 클라우드의 지역적인 구조까지 고려할 수 있는 네트워크 구조가 제안되었다. PointNet++은 포인트들의 밀집도나 지역적 구조에 맞추어 하위 클러스터에서 특징을 추출한 후, 이를 전체 피처로 결합하는 방식이다.</p>
<h3 id="_4">특성 추출과 전처리</h3>
<p>머신러닝에서 포인트 클라우드를 분류하려면, 먼저 적절한 특징을 추출하는 것이 중요하다. 이러한 특징은 포인트 간의 기하학적 관계나 공간적 분포를 나타낼 수 있어야 한다. 일반적인 포인트 클라우드 특징으로는 다음과 같은 것들이 있다:
- <strong>포인트 간의 거리</strong>: 각 포인트 간의 유클리드 거리 계산
- <strong>표면 노멀</strong>: 각 포인트의 주변에서 추정한 표면의 법선 벡터
- <strong>밀도</strong>: 주어진 반경 내에 있는 포인트의 수
- <strong>큐브 내 평균 값</strong>: 포인트 클라우드를 일정한 크기의 그리드로 나누어 각 셀에 속한 포인트들의 평균값</p>
<p>이 외에도, 복잡한 기하학적 관계를 설명할 수 있는 고차원적인 특징들도 사용할 수 있다. 예를 들어, 각 포인트에 대해 local reference frame을 설정하고, 그 좌표를 기준으로 특징을 추출할 수 있다.</p>
<h4 id="_5">전처리 단계</h4>
<p>전처리는 머신러닝 모델의 성능을 크게 좌우하는 중요한 단계이다. 포인트 클라우드를 분류하기 위해서는 데이터의 균일성을 확보하고 노이즈를 제거하는 과정이 필요하다. 전처리 과정은 다음과 같은 작업을 포함할 수 있다:
1. <strong>노이즈 제거</strong>: 이웃 포인트와의 거리가 지나치게 큰 포인트나 밀도가 현저히 낮은 영역에 위치한 포인트들을 제거한다.
2. <strong>정규화</strong>: 포인트 클라우드의 좌표를 일정 범위 내로 정규화하여 학습의 안정성을 높인다.
3. <strong>다운샘플링</strong>: 계산량을 줄이기 위해 포인트 클라우드의 해상도를 낮추거나 중요하지 않은 포인트들을 제거한다.</p>
<p>적절한 전처리 과정을 통해 모델의 학습 성능을 향상시킬 수 있으며, 계산 자원의 효율적인 사용이 가능해진다.</p>
<h3 id="_6">클러스터링과 분류의 응용 사례</h3>
<p>머신러닝 기반 클러스터링과 분류 기법은 다양한 포인트 클라우드 처리 응용 분야에서 활용되고 있다. 아래에서는 몇 가지 주요 응용 사례를 설명한다.</p>
<h4 id="_7">자율주행차</h4>
<p>자율주행차는 라이다(LiDAR) 센서로부터 얻은 포인트 클라우드를 사용하여 주변 환경을 인식한다. 이러한 포인트 클라우드 데이터를 실시간으로 처리하기 위해 클러스터링과 분류가 중요한 역할을 한다. 예를 들어, 차량이나 보행자를 인식하기 위해 DBSCAN과 같은 클러스터링 기법이 사용되며, 분류 알고리즘을 통해 각 객체가 차인지, 사람인지, 혹은 도로의 장애물인지를 구분한다.</p>
<p>라이다 센서에서 생성된 3D 포인트 클라우드는 매우 방대하기 때문에, 실시간 처리의 필요성이 강조된다. 여기서 딥러닝 기반의 분류 모델이 활용되어 객체 인식과 분류 작업을 수행하며, PointNet, PointNet++과 같은 모델들이 많이 사용된다.</p>
<h4 id="_8">건축 및 토목 공학</h4>
<p>건축 및 토목 공학 분야에서는 포인트 클라우드를 사용하여 건물의 구조를 스캔하고, 구조물의 결함을 탐지한다. 이 과정에서 클러스터링 기법은 구조물의 다양한 부분을 그룹화하고, 분류 기법은 각 구조물의 타입이나 손상 정도를 분류하는 데 사용된다.</p>
<p>특히 건물의 파사드를 스캔한 포인트 클라우드를 처리할 때, DBSCAN과 같은 클러스터링 기법을 통해 벽, 창문, 기둥 등 구조 요소들을 자동으로 구분할 수 있다. 이 후, 분류 알고리즘을 적용하여 각 요소가 어떤 형태의 구조물인지 판단할 수 있다. 이러한 자동화된 처리는 대규모 건물 스캔 데이터에서 매우 효율적이다.</p>
<h4 id="_9">로봇 공학</h4>
<p>로봇 공학에서 3D 포인트 클라우드를 사용하여 로봇이 주변 환경을 이해하고 상호작용하는 데에도 클러스터링과 분류가 필수적이다. 특히, 서비스 로봇이나 산업용 로봇은 주변 객체를 인식하고 분류하는 작업이 필요하며, 머신러닝 기반의 기법이 이를 실시간으로 수행할 수 있도록 돕는다.</p>
<p>로봇이 작업 공간에서 객체를 탐지할 때는 포인트 클라우드 기반의 클러스터링 기법을 통해 개별 객체를 분리한 후, 분류 알고리즘을 적용하여 각 객체의 타입을 분류한다. 이를 통해 로봇은 작업을 수행하는 동안 특정 객체에 대해 적절한 조작을 할 수 있게 된다.</p>
<h4 id="_10">의료 영상 처리</h4>
<p>의료 분야에서도 3D 스캔 데이터를 분석할 때 포인트 클라우드 기반 클러스터링과 분류 기법이 사용된다. 예를 들어, MRI나 CT 스캔 데이터를 기반으로 클러스터링 기법을 사용하여 장기와 종양을 구분하고, 분류 기법을 통해 종양의 유형이나 장기의 종류를 판별할 수 있다.</p>
<p>의료 영상 데이터는 매우 복잡하고 고해상도이기 때문에, 포인트 클라우드의 특성을 활용한 머신러닝 기법이 효과적일 수 있다. 특히, 비정형적인 클러스터 구조나 다양한 형상을 가진 장기나 종양에 대해, DBSCAN이나 GMM과 같은 클러스터링 기법이 유연하게 대응할 수 있으며, SVM이나 딥러닝 기반 분류 기법이 이를 정확하게 분류할 수 있다.</p>
<h3 id="_11">클러스터링과 분류를 위한 성능 평가 지표</h3>
<p>머신러닝 기반 클러스터링과 분류 알고리즘의 성능을 평가하기 위해서는 여러 가지 지표들이 사용된다. 특히, 비지도 학습(클러스터링)의 경우에는 사전에 정의된 클래스가 없기 때문에 평가가 어려울 수 있으며, 분류 문제에서는 다양한 성능 측정 방법을 활용할 수 있다.</p>
<h4 id="_12">클러스터링 성능 평가</h4>
<p>클러스터링의 경우, 정답 레이블이 없기 때문에, 알고리즘이 생성한 클러스터의 품질을 평가하는 지표로 다음과 같은 방법들이 사용된다.</p>
<ul>
<li><strong>실루엣 계수 (Silhouette Coefficient)</strong>: 클러스터 내 포인트 간의 유사도와 클러스터 간의 차이를 측정하는 지표이다. 실루엣 계수는 -1에서 1 사이의 값을 가지며, 값이 클수록 클러스터링의 품질이 좋음을 의미한다.</li>
</ul>
<div class="arithmatex">
<div class="MathJax_Preview">
S = \frac{b - a}{\max(a, b)}
</div>
<script type="math/tex; mode=display">
S = \frac{b - a}{\max(a, b)}
</script>
</div>
<p>여기서 <span class="arithmatex"><span class="MathJax_Preview">a</span><script type="math/tex">a</script></span>는 같은 클러스터 내 다른 포인트들과의 평균 거리, <span class="arithmatex"><span class="MathJax_Preview">b</span><script type="math/tex">b</script></span>는 가장 가까운 다른 클러스터 내 포인트들과의 평균 거리이다.</p>
<ul>
<li><strong>Dunn Index</strong>: 클러스터 간의 최소 거리를 클러스터 내의 최대 거리로 나누어, 클러스터가 잘 분리되었는지 평가한다. Dunn Index가 클수록 클러스터링 품질이 좋다.</li>
</ul>
<div class="arithmatex">
<div class="MathJax_Preview">
D = \frac{\min\{d(\mathbf{p}_i, \mathbf{p}_j)\}}{\max\{\delta(\mathbf{c}_k)\}}
</div>
<script type="math/tex; mode=display">
D = \frac{\min\{d(\mathbf{p}_i, \mathbf{p}_j)\}}{\max\{\delta(\mathbf{c}_k)\}}
</script>
</div>
<p>여기서 <span class="arithmatex"><span class="MathJax_Preview">d(\mathbf{p}_i, \mathbf{p}_j)</span><script type="math/tex">d(\mathbf{p}_i, \mathbf{p}_j)</script></span>는 클러스터 간 거리, <span class="arithmatex"><span class="MathJax_Preview">\delta(\mathbf{c}_k)</span><script type="math/tex">\delta(\mathbf{c}_k)</script></span>는 클러스터 <span class="arithmatex"><span class="MathJax_Preview">k</span><script type="math/tex">k</script></span> 내 포인트 간의 최대 거리이다.</p>
<h4 id="_13">분류 성능 평가</h4>
<p>분류 문제의 성능을 평가하기 위해서는 다음과 같은 지표들이 일반적으로 사용된다.</p>
<ul>
<li><strong>정확도 (Accuracy)</strong>: 전체 예측 중에서 정확하게 분류된 데이터의 비율을 나타낸다. 정확도는 간단한 평가 지표이지만, 데이터의 클래스가 불균형할 때 적절하지 않을 수 있다.</li>
</ul>
<div class="arithmatex">
<div class="MathJax_Preview">
\text{Accuracy} = \frac{\text{TP + TN}}{\text{TP + TN + FP + FN}}
</div>
<script type="math/tex; mode=display">
\text{Accuracy} = \frac{\text{TP + TN}}{\text{TP + TN + FP + FN}}
</script>
</div>
<p>여기서 TP(True Positive), TN(True Negative), FP(False Positive), FN(False Negative)는 분류 결과에 따른 각 분류의 수를 의미한다.</p>
<ul>
<li><strong>정밀도 (Precision)</strong>: 양성으로 예측한 결과 중 실제 양성인 비율을 나타낸다.</li>
</ul>
<div class="arithmatex">
<div class="MathJax_Preview">
\text{Precision} = \frac{\text{TP}}{\text{TP + FP}}
</div>
<script type="math/tex; mode=display">
\text{Precision} = \frac{\text{TP}}{\text{TP + FP}}
</script>
</div>
<ul>
<li><strong>재현율 (Recall)</strong>: 실제 양성 중에서 얼마나 많은 데이터가 정확하게 양성으로 분류되었는지를 나타낸다.</li>
</ul>
<div class="arithmatex">
<div class="MathJax_Preview">
\text{Recall} = \frac{\text{TP}}{\text{TP + FN}}
</div>
<script type="math/tex; mode=display">
\text{Recall} = \frac{\text{TP}}{\text{TP + FN}}
</script>
</div>
<ul>
<li><strong>F1 스코어</strong>: 정밀도와 재현율의 조화 평균으로, 두 지표 간의 균형을 측정한다.</li>
</ul>
<div class="arithmatex">
<div class="MathJax_Preview">
F1 = 2 \cdot \frac{\text{Precision} \cdot \text{Recall}}{\text{Precision} + \text{Recall}}
</div>
<script type="math/tex; mode=display">
F1 = 2 \cdot \frac{\text{Precision} \cdot \text{Recall}}{\text{Precision} + \text{Recall}}
</script>
</div>
<p>이러한 평가 지표들은 분류 모델의 성능을 종합적으로 판단하는 데 사용되며, 특히 분류 문제에서 클래스 불균형이 존재하는 경우에는 F1 스코어와 같은 지표가 유용하다.</p>

  <br>
    

    
    
      
    

  <div class="row wm-article-nav-buttons" role="navigation" aria-label="navigation">
    
    <div class="wm-article-nav pull-right">
      <a href="../1804/" class="btn btn-xs btn-default pull-right">
        Next
        <i class="fa fa-chevron-right" aria-hidden="true"></i>
      </a>
      <a href="../1804/" class="btn btn-xs btn-link">
        PCL과 AI의 통합 활용 사례
      </a>
    </div>
    
    <div class="wm-article-nav">
      <a href="../1802/" class="btn btn-xs btn-default pull-left">
        <i class="fa fa-chevron-left" aria-hidden="true"></i>
        Previous</a><a href="../1802/" class="btn btn-xs btn-link">
        신경망을 활용한 객체 인식
      </a>
    </div>
    
  </div>

    <br>
</div>

<footer class="container-fluid wm-page-content">
  <p>Documentation built with <a href="https://www.mkdocs.org/">MkDocs</a> using <a href="https://github.com/gristlabs/mkdocs-windmill">Windmill</a> theme by Grist Labs.</p>
</footer>

</body>
</html>