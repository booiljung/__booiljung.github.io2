<!DOCTYPE html>
<html lang="en">
<head>
  
  
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    
    
    <link rel="canonical" href="https://booiljung.github.io/sensor_data_processing/pointcloud/introduction_to_pointcloud_processing_with_pcl_library/chapter_10/1005/">
    <link rel="shortcut icon" href="../../../../../img/favicon.ico">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" />
    <title>학습 기반 객체 인식 방법 - 실험 도서관</title>
    <link href="../../../../../css/bootstrap-3.3.7.min.css" rel="stylesheet">
    <link href="../../../../../css/font-awesome-4.7.0.css" rel="stylesheet">
    <link href="../../../../../css/base.css" rel="stylesheet">
    <link rel="stylesheet" href="../../../../../css/highlight.css">
    <link href="../../../../../css/custom.css" rel="stylesheet">
    <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.3.0/respond.min.js"></script>
    <![endif]-->

    <script src="../../../../../js/jquery-3.2.1.min.js"></script>
    <script src="../../../../../js/bootstrap-3.3.7.min.js"></script>
    <script src="../../../../../js/highlight.pack.js"></script>
    
    <base target="_top">
    <script>
      var base_url = '../../../../..';
      var is_top_frame = false;
        
        var pageToc = [
          {title: "1. \ub370\uc774\ud130 \uc804\ucc98\ub9ac", url: "#_top", children: [
              {title: "\ud3ec\uc778\ud2b8 \ud074\ub77c\uc6b0\ub4dc \uc815\uaddc\ud654", url: "#_1" },
              {title: "\ub178\uc774\uc988 \uc81c\uac70", url: "#_2" },
          ]},
          {title: "2. \ud2b9\uc9d5 \ucd94\ucd9c", url: "#2", children: [
              {title: "\uae00\ub85c\ubc8c \ud2b9\uc9d5", url: "#_3" },
              {title: "\ub85c\uceec \ud2b9\uc9d5", url: "#_4" },
          ]},
          {title: "3. \ud559\uc2b5 \uc54c\uace0\ub9ac\uc998 \uc120\ud0dd", url: "#3", children: [
              {title: "\uc9c0\ub3c4 \ud559\uc2b5", url: "#_5" },
              {title: "\ube44\uc9c0\ub3c4 \ud559\uc2b5", url: "#_6" },
          ]},
          {title: "4. \ud559\uc2b5 \ubc0f \ud3c9\uac00 \uacfc\uc815", url: "#4", children: [
              {title: "\ub370\uc774\ud130 \ubd84\ud560", url: "#_7" },
              {title: "\uc131\ub2a5 \uc9c0\ud45c", url: "#_8" },
              {title: "\uad50\ucc28 \uac80\uc99d(Cross-Validation)", url: "#cross-validation" },
              {title: "\ud558\uc774\ud37c\ud30c\ub77c\ubbf8\ud130 \ud29c\ub2dd", url: "#_9" },
          ]},
          {title: "5. \uac1d\uccb4 \uc778\uc2dd\uc744 \uc704\ud55c \uc804\uc774 \ud559\uc2b5(Transfer Learning)", url: "#5-transfer-learning", children: [
              {title: "\uc804\uc774 \ud559\uc2b5\uc758 \uac1c\ub150", url: "#_10" },
              {title: "\uc804\uc774 \ud559\uc2b5\uc758 \uc774\uc810", url: "#_11" },
              {title: "\uc804\uc774 \ud559\uc2b5 \uc801\uc6a9 \uc608\uc2dc: PointNet", url: "#pointnet" },
          ]},
          {title: "6. \uac1d\uccb4 \uc778\uc2dd \uc2dc\uc2a4\ud15c\uc758 \ucd5c\uc801\ud654", url: "#6", children: [
              {title: "\uba54\ubaa8\ub9ac \ucd5c\uc801\ud654", url: "#_12" },
              {title: "\uacc4\uc0b0 \ucd5c\uc801\ud654", url: "#_13" },
              {title: "\uc2e4\uc2dc\uac04 \ucc98\ub9ac", url: "#_14" },
          ]},
        ];

    </script>
    <script src="../../../../../js/base.js"></script>
      <script src="../../../../../js/google_analytics.js"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML"></script>
      <script src="https://www.googletagmanager.com/gtag/js?id=G-3F4LHCTF88"></script> 
</head>

<body>
<script>
if (is_top_frame) { $('body').addClass('wm-top-page'); }
</script>



<div class="container-fluid wm-page-content">
  <a name="_top"></a>
    

    
    
      
    

  <div class="row wm-article-nav-buttons" role="navigation" aria-label="navigation">
    
    <div class="wm-article-nav pull-right">
      <a href="../../chapter_11/1101/" class="btn btn-xs btn-default pull-right">
        Next
        <i class="fa fa-chevron-right" aria-hidden="true"></i>
      </a>
      <a href="../../chapter_11/1101/" class="btn btn-xs btn-link">
        SLAM의 기본 개념
      </a>
    </div>
    
    <div class="wm-article-nav">
      <a href="../1004/" class="btn btn-xs btn-default pull-left">
        <i class="fa fa-chevron-left" aria-hidden="true"></i>
        Previous</a><a href="../1004/" class="btn btn-xs btn-link">
        템플릿 매칭과 물체 위치 결정
      </a>
    </div>
    
  </div>

    

    <p>학습 기반 객체 인식 방법은 주로 컴퓨터 비전에서 활용되는 기계 학습 기법을 포인트 클라우드 데이터에 적용하여 특정 객체를 인식하는 기술이다. 이 방법은 객체의 위치나 방향과 무관하게 객체를 인식할 수 있다는 장점이 있다. 학습 기반 객체 인식의 핵심 요소는 크게 데이터 전처리, 특징 추출, 학습 알고리즘 선택, 학습 및 평가 과정으로 나눌 수 있다.</p>
<h3 id="1">1. 데이터 전처리</h3>
<p>포인트 클라우드 데이터를 이용한 객체 인식에서 첫 번째 단계는 데이터를 적절히 전처리하는 것이다. 포인트 클라우드 데이터는 노이즈가 포함될 수 있고, 특정 방향에서만 객체의 일부가 보일 수 있기 때문에 이를 보완하는 처리가 필요하다.</p>
<h4 id="_1">포인트 클라우드 정규화</h4>
<p>포인트 클라우드 데이터는 다양한 스케일과 방향성을 가지므로, 이를 동일한 기준으로 맞추기 위한 정규화(normalization) 과정이 필요하다. 정규화는 주로 데이터의 중심을 원점으로 맞추고, 스케일을 1로 맞추는 방식으로 진행된다. 이를 수학적으로 표현하면 다음과 같다.</p>
<p>포인트 클라우드 데이터를 나타내는 행렬이 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{P} \in \mathbb{R}^{N \times 3}</span><script type="math/tex">\mathbf{P} \in \mathbb{R}^{N \times 3}</script></span>라고 할 때, <span class="arithmatex"><span class="MathJax_Preview">\mathbf{p}_i</span><script type="math/tex">\mathbf{p}_i</script></span>는 <span class="arithmatex"><span class="MathJax_Preview">i</span><script type="math/tex">i</script></span>-번째 포인트를 나타내며, 전체 데이터에 대한 평균은</p>
<div class="arithmatex">
<div class="MathJax_Preview">
\mathbf{\bar{p}} = \frac{1}{N} \sum_{i=1}^{N} \mathbf{p}_i
</div>
<script type="math/tex; mode=display">
\mathbf{\bar{p}} = \frac{1}{N} \sum_{i=1}^{N} \mathbf{p}_i
</script>
</div>
<p>로 계산된다. 이를 통해 모든 포인트를 중심화하는 과정은</p>
<div class="arithmatex">
<div class="MathJax_Preview">
\mathbf{P}' = \mathbf{P} - \mathbf{\bar{p}}
</div>
<script type="math/tex; mode=display">
\mathbf{P}' = \mathbf{P} - \mathbf{\bar{p}}
</script>
</div>
<p>로 나타낼 수 있다. 또한, 각 포인트의 최대 거리 <span class="arithmatex"><span class="MathJax_Preview">d_{\text{max}}</span><script type="math/tex">d_{\text{max}}</script></span>를 구한 후, 이를 1로 정규화하면,</p>
<div class="arithmatex">
<div class="MathJax_Preview">
\mathbf{P}_{\text{norm}} = \frac{\mathbf{P}'}{d_{\text{max}}}
</div>
<script type="math/tex; mode=display">
\mathbf{P}_{\text{norm}} = \frac{\mathbf{P}'}{d_{\text{max}}}
</script>
</div>
<p>와 같은 방식으로 데이터가 정규화된다.</p>
<h4 id="_2">노이즈 제거</h4>
<p>포인트 클라우드는 센서의 오차로 인해 노이즈가 포함될 수 있다. 이를 제거하기 위한 다양한 기법들이 존재하며, 대표적인 방법은 Statistical Outlier Removal(SOR)이다. SOR 알고리즘은 각 포인트에 대해 주변 포인트와의 평균 거리를 계산하고, 이 값이 임계값을 초과하는 포인트들을 노이즈로 간주하여 제거한다. 이 과정은 다음과 같이 요약할 수 있다.</p>
<ol>
<li>각 포인트 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{p}_i</span><script type="math/tex">\mathbf{p}_i</script></span>에 대해 k개의 가까운 이웃을 찾는다.</li>
<li><span class="arithmatex"><span class="MathJax_Preview">i</span><script type="math/tex">i</script></span>-번째 포인트와 k개의 이웃 간의 거리 평균 <span class="arithmatex"><span class="MathJax_Preview">d_i</span><script type="math/tex">d_i</script></span>를 계산한다.</li>
<li>모든 포인트에 대해 평균 거리 <span class="arithmatex"><span class="MathJax_Preview">\{d_i\}_{i=1}^{N}</span><script type="math/tex">\{d_i\}_{i=1}^{N}</script></span>의 분포를 분석하여 임계값을 설정한다.</li>
<li>평균 거리가 임계값을 초과하는 포인트를 제거한다.</li>
</ol>
<p>이 과정은 포인트 클라우드 데이터의 품질을 향상시켜, 객체 인식의 정확도를 높인다.</p>
<h3 id="2">2. 특징 추출</h3>
<p>포인트 클라우드 데이터는 3차원 좌표로 구성되므로, 객체 인식을 위해서는 포인트 클라우드에서 유의미한 특징(feature)을 추출하는 과정이 필요하다. 특징 추출은 주로 로컬(local)과 글로벌(global) 특징으로 나눌 수 있다.</p>
<h4 id="_3">글로벌 특징</h4>
<p>글로벌 특징은 전체 포인트 클라우드를 하나의 벡터로 요약하는 방법이다. 대표적인 글로벌 특징 추출 기법으로는 PointNet, Voxel 기반 특징 추출 방법 등이 있다.</p>
<p><strong>PointNet 기반 특징 추출:</strong>
PointNet은 포인트 클라우드의 개별 포인트들에 대한 특징을 학습하고, 이를 통합하여 객체의 글로벌 특징을 추출하는 네트워크 구조이다. 개별 포인트 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{p}_i</span><script type="math/tex">\mathbf{p}_i</script></span>에 대해 다층 퍼셉트론(MLP)를 적용하여, 포인트별 특징 벡터 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{f}_i</span><script type="math/tex">\mathbf{f}_i</script></span>를 생성한다. 그런 다음, 전체 포인트에 대해 맥스 풀링(max-pooling)을 적용하여 글로벌 특징 벡터를 구한다. 이 과정은 다음 수식으로 요약된다.</p>
<div class="arithmatex">
<div class="MathJax_Preview">
\mathbf{f}_{\text{global}} = \max_{i} \mathbf{f}_i
</div>
<script type="math/tex; mode=display">
\mathbf{f}_{\text{global}} = \max_{i} \mathbf{f}_i
</script>
</div>
<p>이와 같은 방식으로 포인트 클라우드의 구조적 정보를 보존하면서 글로벌 특징을 추출할 수 있다.</p>
<h4 id="_4">로컬 특징</h4>
<p>로컬 특징은 특정 영역이나 부분에서 중요한 정보를 추출하는 방법이다. 이는 주로 물체의 세부적인 형태나 질감 정보를 반영하며, 지역적 정보에 민감하다. 대표적인 로컬 특징 추출 기법으로는 Fast Point Feature Histogram(FPFH)과 Spin Image가 있다.</p>
<p><strong>FPFH 기반 특징 추출:</strong>
FPFH는 포인트 클라우드의 기하학적 특성을 반영하는 로컬 특징을 추출하는 기법으로, 각 포인트의 법선 벡터(normal vector)를 활용한다. FPFH는 다음과 같은 절차를 따른다.</p>
<ol>
<li>각 포인트 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{p}_i</span><script type="math/tex">\mathbf{p}_i</script></span>의 법선 벡터 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{n}_i</span><script type="math/tex">\mathbf{n}_i</script></span>를 계산한다.</li>
<li>가까운 이웃 포인트 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{p}_j</span><script type="math/tex">\mathbf{p}_j</script></span>와 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{n}_j</span><script type="math/tex">\mathbf{n}_j</script></span>를 사용하여 각 포인트 간의 상대적인 기하학적 관계를 나타내는 세 개의 각도 <span class="arithmatex"><span class="MathJax_Preview">\alpha, \phi, \theta</span><script type="math/tex">\alpha, \phi, \theta</script></span>를 계산한다.</li>
<li>각 이웃 관계에 대해 이 각도를 히스토그램으로 표현하여, 포인트의 로컬 특징을 생성한다.</li>
</ol>
<p>FPFH는 주로 물체의 모서리, 곡률이 큰 부분 등에서 유의미한 로컬 특징을 제공하며, 이를 학습 기반 객체 인식에 활용할 수 있다.</p>
<h3 id="3">3. 학습 알고리즘 선택</h3>
<p>포인트 클라우드 데이터에서 추출된 특징을 바탕으로 객체 인식을 수행하기 위해서는 적절한 학습 알고리즘을 선택해야 한다. 학습 알고리즘은 크게 두 가지 범주로 나눌 수 있다: 비지도 학습(unsupervised learning)과 지도 학습(supervised learning).</p>
<h4 id="_5">지도 학습</h4>
<p>지도 학습은 라벨이 있는 학습 데이터를 이용하여 객체를 분류하거나 인식하는 방법이다. 일반적으로 포인트 클라우드에서 객체 인식은 분류(classification) 문제로 다루어지며, 자주 사용되는 지도 학습 알고리즘은 다음과 같다.</p>
<p><strong>서포트 벡터 머신(SVM):</strong></p>
<p>SVM은 고차원의 특징 공간에서 데이터를 선형적으로 분리하는 초평면(hyperplane)을 찾는 알고리즘이다. 포인트 클라우드 데이터를 분류하기 위해 추출된 특징 벡터 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{f} \in \mathbb{R}^d</span><script type="math/tex">\mathbf{f} \in \mathbb{R}^d</script></span>에 대해, SVM은 다음과 같은 최적화 문제를 푼다.</p>
<div class="arithmatex">
<div class="MathJax_Preview">
\min_{\mathbf{w}, b} \frac{1}{2} \|\mathbf{w}\|^2 \quad \text{subject to} \quad y_i(\mathbf{w}^\top \mathbf{f}_i + b) \geq 1, \, i=1,\dots,N
</div>
<script type="math/tex; mode=display">
\min_{\mathbf{w}, b} \frac{1}{2} \|\mathbf{w}\|^2 \quad \text{subject to} \quad y_i(\mathbf{w}^\top \mathbf{f}_i + b) \geq 1, \, i=1,\dots,N
</script>
</div>
<p>여기서 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{w}</span><script type="math/tex">\mathbf{w}</script></span>는 초평면의 노멀 벡터, <span class="arithmatex"><span class="MathJax_Preview">b</span><script type="math/tex">b</script></span>는 편향, <span class="arithmatex"><span class="MathJax_Preview">y_i</span><script type="math/tex">y_i</script></span>는 학습 데이터의 라벨이다. 이 문제를 해결하여 분류 경계를 학습하게 된다.</p>
<p>SVM은 포인트 클라우드 데이터에 대한 학습 성능이 우수하며, 특히 선형적으로 구분 가능한 특징 공간에서 효과적이다. 그러나 포인트 클라우드에서 복잡한 기하학적 형태를 다루기 위해서는 커널 트릭(kernel trick)을 사용하여 비선형 경계를 학습할 수 있다.</p>
<p><strong>결정 트리 및 랜덤 포레스트(Random Forest):</strong></p>
<p>결정 트리는 특징 벡터를 사용하여 데이터를 분류하는 트리 구조의 모델이다. 트리의 각 노드는 특정 특징의 임계값을 기준으로 데이터를 분할하고, 마지막 리프 노드는 클래스 레이블을 할당한다.</p>
<p>랜덤 포레스트는 여러 개의 결정 트리를 학습하고, 각 트리의 예측 결과를 종합하여 최종 결과를 도출하는 앙상블 학습 방법이다. 랜덤 포레스트는 일반적으로 높은 정확도를 제공하며, 포인트 클라우드의 특징이 복잡할 때에도 강건한 성능을 보인다.</p>
<p>랜덤 포레스트에서 각 트리는 독립적으로 학습되며, 예측은 다수결 투표 방식으로 이루어진다. 이 방식은 과적합(overfitting)을 방지하고, 모델의 일반화 성능을 향상시킨다.</p>
<p><strong>신경망 및 딥러닝 기반 방법:</strong></p>
<p>최근에는 신경망을 이용한 딥러닝 기반 방법이 포인트 클라우드 객체 인식에서 널리 사용되고 있다. 특히 Convolutional Neural Network(CNN)를 확장한 3D CNN 또는 PointNet과 같은 모델들이 대표적이다.</p>
<ul>
<li><strong>PointNet:</strong> PointNet은 각 포인트에 독립적으로 학습된 특징을 기반으로 글로벌 특징 벡터를 생성하는 딥러닝 모델이다. 입력 데이터는 포인트 클라우드 좌표이며, 이를 다층 퍼셉트론(MLP)으로 처리하여 포인트별 특징을 학습하고, 전역 맥스 풀링을 통해 전체 포인트 클라우드를 대표하는 특징 벡터를 얻는다.</li>
</ul>
<p>PointNet의 손실 함수는 주로 분류 목적에 따라 교차 엔트로피(cross-entropy)로 정의된다:</p>
<div class="arithmatex">
<div class="MathJax_Preview">
  L = -\sum_{c=1}^{C} y_c \log(\hat{y}_c)
</div>
<script type="math/tex; mode=display">
  L = -\sum_{c=1}^{C} y_c \log(\hat{y}_c)
</script>
</div>
<p>여기서 <span class="arithmatex"><span class="MathJax_Preview">y_c</span><script type="math/tex">y_c</script></span>는 실제 클래스, <span class="arithmatex"><span class="MathJax_Preview">\hat{y}_c</span><script type="math/tex">\hat{y}_c</script></span>는 예측 확률이다.</p>
<ul>
<li><strong>3D CNN:</strong> 포인트 클라우드 데이터를 3차원 격자로 변환한 후, 3D CNN을 이용해 특징을 추출할 수 있다. 이 방식은 2D 이미지에서 사용하는 CNN을 확장한 형태로, 물체의 공간적 구조를 효율적으로 학습할 수 있다. 다만, 포인트 클라우드를 격자로 변환하는 과정에서 데이터가 손실될 수 있다.</li>
</ul>
<h4 id="_6">비지도 학습</h4>
<p>비지도 학습은 라벨이 없는 데이터를 학습하는 방법이다. 포인트 클라우드 데이터에서 비지도 학습을 통해 주로 클러스터링 또는 차원 축소를 수행하여 객체의 구성을 파악할 수 있다.</p>
<p><strong>K-평균 클러스터링(K-Means Clustering):</strong></p>
<p>K-평균 클러스터링은 주어진 데이터 포인트를 <span class="arithmatex"><span class="MathJax_Preview">K</span><script type="math/tex">K</script></span>개의 클러스터로 나누는 알고리즘이다. 포인트 클라우드 데이터를 클러스터링하여 비슷한 구조의 포인트를 그룹화할 수 있으며, 각 클러스터는 특정 객체를 나타낼 수 있다.</p>
<p>K-평균 알고리즘은 다음과 같은 절차로 동작한다:</p>
<ol>
<li>초기 중심 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{\mu}_1, \mathbf{\mu}_2, \dots, \mathbf{\mu}_K</span><script type="math/tex">\mathbf{\mu}_1, \mathbf{\mu}_2, \dots, \mathbf{\mu}_K</script></span>을 랜덤하게 설정한다.</li>
<li>각 포인트 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{p}_i</span><script type="math/tex">\mathbf{p}_i</script></span>를 가장 가까운 중심에 할당한다.</li>
<li>각 클러스터의 중심을 업데이트한다:</li>
</ol>
<div class="arithmatex">
<div class="MathJax_Preview">
\mathbf{\mu}_k = \frac{1}{|C_k|} \sum_{\mathbf{p}_i \in C_k} \mathbf{p}_i
</div>
<script type="math/tex; mode=display">
\mathbf{\mu}_k = \frac{1}{|C_k|} \sum_{\mathbf{p}_i \in C_k} \mathbf{p}_i
</script>
</div>
<ol>
<li>수렴할 때까지 2-3 단계를 반복한다.</li>
</ol>
<p><strong>자기 조직화 지도(SOM, Self-Organizing Map):</strong></p>
<p>SOM은 비지도 학습에서 사용하는 신경망의 한 종류로, 고차원 데이터를 저차원 격자로 사상하여 유사한 데이터 포인트들을 가까운 격자에 배치한다. 포인트 클라우드 데이터를 저차원으로 축소하면서 객체의 형태를 보존하는 데 효과적이다.</p>
<p>SOM의 학습 과정은 경쟁 학습을 기반으로 하며, 각 포인트는 격자 상의 노드에 할당된다. SOM을 통해 포인트 클라우드 데이터의 분포를 시각적으로 분석할 수 있으며, 객체의 군집을 파악하는 데 유용하다.</p>
<h3 id="4">4. 학습 및 평가 과정</h3>
<p>학습 기반 객체 인식에서는 학습 과정과 함께 모델의 성능을 평가하는 과정이 매우 중요하다. 학습 과정에서 모델이 데이터를 잘 학습하고 있는지, 일반화 능력이 뛰어난지를 판단하기 위한 여러 가지 방법들이 있다. 평가 과정에서는 주로 데이터 분할, 성능 지표, 그리고 교차 검증 방법을 사용하여 모델의 성능을 분석한다.</p>
<h4 id="_7">데이터 분할</h4>
<p>모델의 학습과 평가를 위해 데이터는 일반적으로 학습 데이터셋(train set)과 테스트 데이터셋(test set)으로 분할된다. 학습 데이터셋은 모델을 학습시키는 데 사용되고, 테스트 데이터셋은 모델의 성능을 독립적으로 평가하는 데 사용된다. 포인트 클라우드 데이터에서는 학습, 검증, 테스트 데이터의 비율을 적절히 조정하는 것이 중요하다.</p>
<ul>
<li><strong>훈련 데이터(Training Set):</strong> 모델을 학습하는 데 사용되는 데이터로, 전체 데이터의 70%~80% 정도를 차지한다.</li>
<li><strong>검증 데이터(Validation Set):</strong> 모델의 과적합 여부를 점검하고, 하이퍼파라미터를 튜닝하는 데 사용된다. 일반적으로 전체 데이터의 10%~15%가 검증 데이터로 사용된다.</li>
<li><strong>테스트 데이터(Test Set):</strong> 학습이 완료된 후, 모델의 성능을 평가하는 데 사용된다. 전체 데이터의 10%~15%가 테스트 데이터로 할당된다.</li>
</ul>
<h4 id="_8">성능 지표</h4>
<p>객체 인식 모델의 성능을 평가하기 위해 다양한 성능 지표가 사용된다. 이 중에서 가장 널리 사용되는 지표는 정확도(Accuracy), 정밀도(Precision), 재현율(Recall), F1 점수(F1-Score) 등이다.</p>
<ul>
<li><strong>정확도(Accuracy):</strong> 모델이 올바르게 분류한 포인트의 비율을 나타낸다.</li>
</ul>
<div class="arithmatex">
<div class="MathJax_Preview">
\text{Accuracy} = \frac{\text{True Positives} + \text{True Negatives}}{\text{Total Samples}}
</div>
<script type="math/tex; mode=display">
\text{Accuracy} = \frac{\text{True Positives} + \text{True Negatives}}{\text{Total Samples}}
</script>
</div>
<ul>
<li><strong>정밀도(Precision):</strong> 모델이 양성으로 예측한 것들 중에서 실제로 양성인 포인트의 비율을 나타낸다.</li>
</ul>
<div class="arithmatex">
<div class="MathJax_Preview">
\text{Precision} = \frac{\text{True Positives}}{\text{True Positives} + \text{False Positives}}
</div>
<script type="math/tex; mode=display">
\text{Precision} = \frac{\text{True Positives}}{\text{True Positives} + \text{False Positives}}
</script>
</div>
<ul>
<li><strong>재현율(Recall):</strong> 실제 양성인 포인트 중에서 모델이 양성으로 예측한 비율을 나타낸다.</li>
</ul>
<div class="arithmatex">
<div class="MathJax_Preview">
\text{Recall} = \frac{\text{True Positives}}{\text{True Positives} + \text{False Negatives}}
</div>
<script type="math/tex; mode=display">
\text{Recall} = \frac{\text{True Positives}}{\text{True Positives} + \text{False Negatives}}
</script>
</div>
<ul>
<li><strong>F1-Score:</strong> 정밀도와 재현율의 조화 평균으로, 두 지표 간의 균형을 평가한다.</li>
</ul>
<div class="arithmatex">
<div class="MathJax_Preview">
\text{F1-Score} = 2 \cdot \frac{\text{Precision} \cdot \text{Recall}}{\text{Precision} + \text{Recall}}
</div>
<script type="math/tex; mode=display">
\text{F1-Score} = 2 \cdot \frac{\text{Precision} \cdot \text{Recall}}{\text{Precision} + \text{Recall}}
</script>
</div>
<p>이러한 성능 지표를 사용하여 모델이 객체를 얼마나 정확하게 인식하는지를 판단할 수 있으며, 이를 통해 모델의 성능을 개선할 수 있는 지표를 파악할 수 있다.</p>
<h4 id="cross-validation">교차 검증(Cross-Validation)</h4>
<p>모델이 과적합을 방지하고, 일반화 능력을 향상시키기 위해 교차 검증 방법을 사용할 수 있다. 교차 검증은 데이터셋을 여러 번 나누어 학습과 평가를 반복하는 방식이다. 그중 가장 일반적인 방법은 K-폴드 교차 검증(K-Fold Cross Validation)이다.</p>
<p><strong>K-폴드 교차 검증:</strong></p>
<p>K-폴드 교차 검증은 데이터를 K개의 폴드(fold)로 나누어, 각 폴드를 한 번씩 테스트 데이터로 사용하고, 나머지 폴드들은 학습 데이터로 사용하는 방식이다. K-폴드 교차 검증의 과정은 다음과 같다.</p>
<ol>
<li>전체 데이터셋을 K개의 동일한 크기로 분할한다.</li>
<li><span class="arithmatex"><span class="MathJax_Preview">i</span><script type="math/tex">i</script></span>-번째 폴드를 테스트 데이터로 설정하고, 나머지 <span class="arithmatex"><span class="MathJax_Preview">K-1</span><script type="math/tex">K-1</script></span>개의 폴드를 학습 데이터로 사용하여 모델을 학습시킨다.</li>
<li><span class="arithmatex"><span class="MathJax_Preview">i</span><script type="math/tex">i</script></span>-번째 폴드에 대한 성능을 평가한다.</li>
<li>이를 K번 반복하고, K번의 평가 결과를 평균내어 최종 성능 지표로 활용한다.</li>
</ol>
<p>K-폴드 교차 검증은 다음과 같은 장점을 제공한다:
- 과적합을 방지한다.
- 데이터가 불균형할 때도 모델의 성능을 공정하게 평가할 수 있다.
- 평가의 변동성을 줄여, 일반화 성능을 측정하는 데 효과적이다.</p>
<p>K-폴드 교차 검증의 성능 평가 결과는 모델의 일반화 능력을 평가하는 중요한 기준이 되며, 하이퍼파라미터 튜닝이나 모델 선택에 중요한 역할을 한다.</p>
<h4 id="_9">하이퍼파라미터 튜닝</h4>
<p>학습 기반 객체 인식 모델은 여러 하이퍼파라미터에 의해 성능이 좌우된다. 하이퍼파라미터는 모델이 학습되기 전에 설정되며, 학습 과정에서 변경되지 않는 변수들이다. 예를 들어, SVM의 경우에는 커널 함수의 종류와 매개변수(C 값 등), 신경망의 경우에는 학습률(learning rate)이나 은닉층의 개수 등이 있다.</p>
<p>하이퍼파라미터 튜닝의 방법은 크게 두 가지로 나눌 수 있다:</p>
<ul>
<li>
<p><strong>그리드 서치(Grid Search):</strong> 미리 정의된 하이퍼파라미터 후보군에 대해 모든 조합을 시험하는 방법으로, 모델 성능을 최적화하는 조합을 찾는다. 이 방법은 정확하지만 계산 비용이 크다.</p>
</li>
<li>
<p><strong>랜덤 서치(Random Search):</strong> 하이퍼파라미터 공간에서 임의의 값을 선택하여 성능을 평가하는 방법으로, 그리드 서치보다 계산 비용이 적으면서도 비슷한 성능을 낼 수 있다.</p>
</li>
</ul>
<p>하이퍼파라미터 튜닝 후, 교차 검증을 통해 최적의 하이퍼파라미터 조합을 찾아 모델을 최종적으로 설정하게 된다.</p>
<h3 id="5-transfer-learning">5. 객체 인식을 위한 전이 학습(Transfer Learning)</h3>
<p>전이 학습(Transfer Learning)은 기존에 학습된 모델을 다른 문제에 적용하는 방법으로, 특히 학습 데이터가 적거나 새로운 객체 인식을 빠르게 수행해야 하는 경우에 유용하다. 포인트 클라우드 객체 인식에서도 전이 학습을 활용하여 성능을 개선할 수 있다. </p>
<h4 id="_10">전이 학습의 개념</h4>
<p>전이 학습은 크게 두 가지 단계로 나눌 수 있다. 먼저, 대규모 데이터셋에서 일반적인 특징을 학습하는 기초 모델을 학습한다. 그 후, 학습된 모델의 가중치와 구조를 새로운 문제에 맞춰 미세 조정(fine-tuning)하거나, 특정 계층의 파라미터만 학습하는 방식으로 재사용한다.</p>
<p>포인트 클라우드 객체 인식에서 전이 학습을 적용할 때의 일반적인 절차는 다음과 같다:</p>
<ol>
<li><strong>기본 모델 학습:</strong> 대규모 데이터셋(예: ModelNet40, ShapeNet)에서 PointNet 또는 다른 3D 객체 인식 모델을 학습시킨다.</li>
<li><strong>특징 추출:</strong> 학습된 모델의 특정 계층에서 포인트 클라우드의 전역적인 특징을 추출한다.</li>
<li><strong>미세 조정(Fine-tuning):</strong> 새로운 객체 인식 문제에 대해 모델의 마지막 계층을 재학습하거나, 전체 네트워크를 미세 조정한다.</li>
</ol>
<h4 id="_11">전이 학습의 이점</h4>
<p>전이 학습은 다음과 같은 여러 가지 이점을 제공한다:</p>
<ul>
<li><strong>데이터 부족 문제 해결:</strong> 전이 학습은 기존에 학습된 모델을 재활용하므로, 새로운 문제에 사용할 데이터가 적어도 효율적으로 학습할 수 있다. 이는 라벨링 비용을 절감하고, 소규모 데이터셋으로도 성능을 향상시킬 수 있는 장점이 있다.</li>
<li><strong>빠른 학습:</strong> 이미 학습된 특징을 기반으로 하기 때문에, 초기 모델 학습에 비해 학습 시간이 단축된다. 특히, 대규모 데이터셋에서 학습된 모델을 사용할 경우 높은 수준의 일반화 성능을 달성할 수 있다.</li>
<li><strong>성능 향상:</strong> 전이 학습을 통해 모델이 다양한 객체에서 추출된 일반적인 특징을 학습하므로, 새로운 객체 인식 문제에 대해 높은 성능을 기대할 수 있다.</li>
</ul>
<h4 id="pointnet">전이 학습 적용 예시: PointNet</h4>
<p>PointNet과 같은 포인트 클라우드 객체 인식 모델에서 전이 학습은 자주 사용되는 방식이다. PointNet은 포인트별 특징을 학습한 후, 전역적인 특징을 통합하는 구조를 가지고 있기 때문에, 이를 다른 포인트 클라우드 데이터셋에 재사용하는 것이 자연스럽다.</p>
<p>예를 들어, ModelNet40에서 학습된 PointNet 모델을 다른 건물 스캔 데이터셋에 적용하려고 할 때, 모델의 초기 계층을 고정(freeze)하고, 마지막 몇 개의 계층만 재학습(fine-tuning)하여 새로운 데이터에 적응시킬 수 있다. 이때 PointNet의 특징 추출 부분은 원본 상태를 유지하므로, 새로운 데이터에서 빠르게 객체 인식 성능을 확보할 수 있다.</p>
<h3 id="6">6. 객체 인식 시스템의 최적화</h3>
<p>포인트 클라우드 객체 인식 시스템은 학습 및 평가 과정 외에도 여러 최적화 기술을 활용하여 실제 적용 시 성능을 극대화할 수 있다. 특히, 실시간 처리나 대규모 데이터 처리에 적합한 방법을 사용하는 것이 중요하다.</p>
<h4 id="_12">메모리 최적화</h4>
<p>포인트 클라우드 데이터는 매우 큰 메모리 공간을 차지할 수 있기 때문에, 메모리 효율성을 고려한 최적화가 필요하다. 이를 위해 다음과 같은 방법들이 주로 사용된다:</p>
<ul>
<li>
<p><strong>다운샘플링(Downsampling):</strong> 모든 포인트를 사용하지 않고, 샘플링 기법을 통해 데이터를 줄인다. Voxel Grid나 Uniform Sampling을 사용하여 포인트 수를 감소시키면서도 객체의 중요한 특징을 유지할 수 있다.</p>
</li>
<li>
<p><strong>쿼드 트리 및 옥트리 구조:</strong> 쿼드 트리(2D)나 옥트리(3D)와 같은 공간 분할 데이터 구조를 사용하여, 메모리 사용량을 줄이고 검색 및 인식 속도를 향상시킬 수 있다. 옥트리 구조는 특히 포인트 클라우드를 계층적으로 나눠 효율적인 데이터 관리가 가능하다.</p>
</li>
</ul>
<h4 id="_13">계산 최적화</h4>
<p>대규모 포인트 클라우드를 처리할 때는 계산 효율을 극대화하는 것이 필수적이다. 이를 위해 GPU 가속, 분산 처리 및 효율적인 알고리즘 설계가 중요하다.</p>
<ul>
<li>
<p><strong>GPU 가속:</strong> 포인트 클라우드의 특징 추출과 같은 계산량이 많은 작업은 GPU를 사용하여 가속할 수 있다. 특히, 딥러닝 모델에서 사용되는 합성곱 연산은 GPU에서 병렬 처리되어 학습 속도를 크게 향상시킨다.</p>
</li>
<li>
<p><strong>병렬 및 분산 처리:</strong> 대규모 포인트 클라우드를 병렬 처리하거나, 분산 클러스터 환경에서 처리함으로써 데이터 처리 시간을 단축할 수 있다. Apache Spark와 같은 분산 처리 프레임워크를 활용하여 여러 대의 컴퓨터에서 데이터를 동시에 처리할 수 있다.</p>
</li>
</ul>
<h4 id="_14">실시간 처리</h4>
<p>실시간 객체 인식은 자율주행, 로봇공학 등 여러 분야에서 필수적이다. 실시간 처리를 위해서는 높은 처리 속도와 낮은 지연 시간을 제공하는 최적화된 알고리즘이 필요하다.</p>
<ul>
<li>
<p><strong>스트리밍(Stream Processing):</strong> 실시간 데이터는 배치(batch) 방식으로 처리되지 않고, 스트리밍 방식으로 처리된다. 포인트 클라우드 스트리밍은 센서에서 지속적으로 입력되는 데이터를 실시간으로 처리하여 객체를 인식하는 방식으로, 데이터의 흐름을 빠르게 처리하는 것이 중요하다.</p>
</li>
<li>
<p><strong>지연 시간 최적화:</strong> 실시간 시스템에서 지연 시간을 줄이기 위해, 알고리즘의 복잡도를 낮추고, 적응형 필터링(adaptive filtering)과 같은 기법을 사용하여 불필요한 계산을 최소화할 수 있다.</p>
</li>
</ul>

  <br>
    

    
    
      
    

  <div class="row wm-article-nav-buttons" role="navigation" aria-label="navigation">
    
    <div class="wm-article-nav pull-right">
      <a href="../../chapter_11/1101/" class="btn btn-xs btn-default pull-right">
        Next
        <i class="fa fa-chevron-right" aria-hidden="true"></i>
      </a>
      <a href="../../chapter_11/1101/" class="btn btn-xs btn-link">
        SLAM의 기본 개념
      </a>
    </div>
    
    <div class="wm-article-nav">
      <a href="../1004/" class="btn btn-xs btn-default pull-left">
        <i class="fa fa-chevron-left" aria-hidden="true"></i>
        Previous</a><a href="../1004/" class="btn btn-xs btn-link">
        템플릿 매칭과 물체 위치 결정
      </a>
    </div>
    
  </div>

    <br>
</div>

<footer class="container-fluid wm-page-content">
  <p>Documentation built with <a href="https://www.mkdocs.org/">MkDocs</a> using <a href="https://github.com/gristlabs/mkdocs-windmill">Windmill</a> theme by Grist Labs.</p>
</footer>

</body>
</html>