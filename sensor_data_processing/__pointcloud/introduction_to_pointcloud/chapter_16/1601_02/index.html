<!DOCTYPE html>
<html lang="en">
<head>
  
  
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    
    
    <link rel="canonical" href="https://booiljung.github.io/sensor_data_processing/__pointcloud/introduction_to_pointcloud/chapter_16/1601_02/">
    <link rel="shortcut icon" href="../../../../../img/favicon.ico">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" />
    <title>포인트클라우드를 활용한 3D 지도 생성의 개요 - 실험 도서관</title>
    <link href="../../../../../css/bootstrap-3.3.7.min.css" rel="stylesheet">
    <link href="../../../../../css/font-awesome-4.7.0.css" rel="stylesheet">
    <link href="../../../../../css/base.css" rel="stylesheet">
    <link rel="stylesheet" href="../../../../../css/highlight.css">
    <link href="../../../../../css/custom.css" rel="stylesheet">
    <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.3.0/respond.min.js"></script>
    <![endif]-->

    <script src="../../../../../js/jquery-3.2.1.min.js"></script>
    <script src="../../../../../js/bootstrap-3.3.7.min.js"></script>
    <script src="../../../../../js/highlight.pack.js"></script>
    
    <base target="_top">
    <script>
      var base_url = '../../../../..';
      var is_top_frame = false;
        
        var pageToc = [
          {title: "\ub2e4\uc591\ud55c \uc13c\uc11c\uc758 \ub370\uc774\ud130 \uc218\uc9d1 \ubc0f \ud2b9\uc9d5", url: "#_top", children: [
              {title: "LiDAR(Light Detection and Ranging)", url: "#lidarlight-detection-and-ranging" },
              {title: "RGB-D \uce74\uba54\ub77c", url: "#rgb-d" },
              {title: "\uc2a4\ud14c\ub808\uc624 \uce74\uba54\ub77c", url: "#_2" },
              {title: "\ucd08\uc74c\ud30c \uc13c\uc11c", url: "#_3" },
              {title: "\uba40\ud2f0 \uc13c\uc11c \uc735\ud569(Multi-Sensor Fusion)", url: "#multi-sensor-fusion" },
          ]},
        ];

    </script>
    <script src="../../../../../js/base.js"></script>
      <script src="../../../../../js/google_analytics.js"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML"></script>
      <script src="https://www.googletagmanager.com/gtag/js?id=G-3F4LHCTF88"></script> 
</head>

<body>
<script>
if (is_top_frame) { $('body').addClass('wm-top-page'); }
</script>



<div class="container-fluid wm-page-content">
  <a name="_top"></a>
    

    

    <h3 id="_1">다양한 센서의 데이터 수집 및 특징</h3>
<p>포인트클라우드를 활용한 3D 지도 생성을 위해서는 다양한 센서로부터 데이터를 수집하는 것이 필수적이다. 대표적인 센서로는 LiDAR(Light Detection and Ranging), RGB-D 카메라, 스테레오 카메라, 그리고 초음파 센서가 있다. 각각의 센서는 고유한 데이터 형식과 수집 범위를 가지며, 이를 통해 수집된 데이터는 3D 포인트클라우드로 변환된다. 여기에서는 각 센서의 데이터 수집 방식과 특징에 대해 설명한다.</p>
<h4 id="lidarlight-detection-and-ranging">LiDAR(Light Detection and Ranging)</h4>
<p>LiDAR는 레이저 펄스를 발사한 후 그 반사 신호가 센서로 돌아오는 시간을 측정하여 물체까지의 거리를 계산한다. 이 거리 정보는 3D 좌표로 변환되며, 수집된 데이터는 포인트클라우드로 변환된다. LiDAR는 높은 해상도와 장거리 측정이 가능하다는 장점이 있으며, 특히 실외 환경에서 많이 사용된다.<br />
LiDAR의 주요 수집 데이터는 거리 정보로, 이를 통해 좌표 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{p}_i = \begin{bmatrix} x_i \\ y_i \\ z_i \end{bmatrix}</span><script type="math/tex">\mathbf{p}_i = \begin{bmatrix} x_i \\ y_i \\ z_i \end{bmatrix}</script></span>와 같은 3D 포인트를 얻을 수 있다. 각 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{p}_i</span><script type="math/tex">\mathbf{p}_i</script></span>는 레이저가 반사된 물체의 위치를 나타낸다.</p>
<div class="arithmatex">
<div class="MathJax_Preview">
\mathbf{p}_i = \mathbf{r}_i + t
</div>
<script type="math/tex; mode=display">
\mathbf{p}_i = \mathbf{r}_i + t
</script>
</div>
<p>여기서, <span class="arithmatex"><span class="MathJax_Preview">\mathbf{r}_i</span><script type="math/tex">\mathbf{r}_i</script></span>는 센서의 위치, <span class="arithmatex"><span class="MathJax_Preview">t</span><script type="math/tex">t</script></span>는 시간에 따른 이동 변위이다.<br />
LiDAR의 경우 데이터 수집 주기가 빠르고, 수집 범위 내에 매우 정밀한 포인트들을 얻을 수 있는 특징을 가지고 있다. 하지만, LiDAR는 물체의 표면 특성이나 재질에 따라 데이터 수집 성능이 달라질 수 있다.</p>
<h4 id="rgb-d">RGB-D 카메라</h4>
<p>RGB-D 카메라는 컬러 이미지(RGB)와 깊이 정보(Depth)를 함께 제공하는 센서이다. Kinect와 같은 장비가 대표적이며, 주로 실내 환경에서 사용된다. 깊이 정보는 카메라와 물체 사이의 거리를 나타내며, 이를 이용해 3D 포인트를 생성할 수 있다.</p>
<p>RGB-D 카메라는 주로 다음과 같은 데이터를 제공한다:
- 컬러 이미지: <span class="arithmatex"><span class="MathJax_Preview">\mathbf{I}_{\text{RGB}} = \{ (r, g, b) \mid r,g,b \in [0, 255]\}</span><script type="math/tex">\mathbf{I}_{\text{RGB}} = \{ (r, g, b) \mid r,g,b \in [0, 255]\}</script></span>
- 깊이 맵: <span class="arithmatex"><span class="MathJax_Preview">\mathbf{D} = \{ d \mid d \in [0, d_{\max}] \}</span><script type="math/tex">\mathbf{D} = \{ d \mid d \in [0, d_{\max}] \}</script></span></p>
<p>깊이 값 <span class="arithmatex"><span class="MathJax_Preview">d</span><script type="math/tex">d</script></span>를 이용하여 3D 포인트를 계산하는 방식은 다음과 같다:</p>
<div class="arithmatex">
<div class="MathJax_Preview">
\mathbf{p}_i = d_i \mathbf{K}^{-1} \mathbf{x}_i
</div>
<script type="math/tex; mode=display">
\mathbf{p}_i = d_i \mathbf{K}^{-1} \mathbf{x}_i
</script>
</div>
<p>여기서 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{K}</span><script type="math/tex">\mathbf{K}</script></span>는 카메라 내측 파라미터 행렬, <span class="arithmatex"><span class="MathJax_Preview">\mathbf{x}_i</span><script type="math/tex">\mathbf{x}_i</script></span>는 이미지에서의 픽셀 좌표이다. RGB-D 카메라는 저비용으로 3D 데이터를 얻을 수 있지만, 깊이 측정 범위가 제한적이고 실외에서 성능이 저하될 수 있다는 단점이 있다.</p>
<h4 id="_2">스테레오 카메라</h4>
<p>스테레오 카메라는 두 개의 카메라가 일정한 간격을 두고 배치되어 있으며, 두 개의 카메라에서 찍은 이미지를 비교하여 깊이 정보를 추정한다. 스테레오 카메라의 기본 원리는 삼각측량을 기반으로 한다. 두 카메라의 좌표계에서 동일한 물체에 해당하는 픽셀 간의 위치 차이(디스패리티)를 계산하여 깊이를 추정할 수 있다.</p>
<p>스테레오 카메라에서 깊이 <span class="arithmatex"><span class="MathJax_Preview">d_i</span><script type="math/tex">d_i</script></span>는 다음과 같이 계산된다:</p>
<div class="arithmatex">
<div class="MathJax_Preview">
d_i = \frac{fB}{\Delta x_i}
</div>
<script type="math/tex; mode=display">
d_i = \frac{fB}{\Delta x_i}
</script>
</div>
<p>여기서 <span class="arithmatex"><span class="MathJax_Preview">f</span><script type="math/tex">f</script></span>는 카메라의 초점 거리, <span class="arithmatex"><span class="MathJax_Preview">B</span><script type="math/tex">B</script></span>는 두 카메라 간의 간격(베이스라인), <span class="arithmatex"><span class="MathJax_Preview">\Delta x_i</span><script type="math/tex">\Delta x_i</script></span>는 두 이미지 간의 픽셀 좌표 차이이다.<br />
스테레오 카메라는 실내외 환경 모두에서 사용 가능하며, 비교적 낮은 비용으로 구현할 수 있다. 그러나 카메라 간의 정밀한 보정이 필요하며, 복잡한 환경에서는 오차가 발생할 수 있다.</p>
<h4 id="_3">초음파 센서</h4>
<p>초음파 센서는 물체에 초음파를 발사한 후 그 반사 신호가 센서로 돌아오는 시간을 측정하여 거리 정보를 얻는다. 이 방식은 매우 간단하지만, 해상도가 낮고 주로 가까운 거리의 물체를 측정하는 데 적합하다. 주로 로봇이나 자율주행 시스템에서 충돌 방지 목적으로 사용된다.</p>
<p>초음파 센서의 데이터는 다음과 같은 방식으로 포인트클라우드로 변환된다:</p>
<div class="arithmatex">
<div class="MathJax_Preview">
\mathbf{p}_i = \mathbf{v}_s \cdot t_i
</div>
<script type="math/tex; mode=display">
\mathbf{p}_i = \mathbf{v}_s \cdot t_i
</script>
</div>
<p>여기서 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{v}_s</span><script type="math/tex">\mathbf{v}_s</script></span>는 음파의 속도, <span class="arithmatex"><span class="MathJax_Preview">t_i</span><script type="math/tex">t_i</script></span>는 신호가 반사되어 돌아오기까지의 시간이다.</p>
<p>초음파 센서는 저비용으로 간단한 구조의 데이터를 수집할 수 있지만, 해상도가 매우 낮고, 넓은 지역을 커버하기에 부적합하다는 단점이 있다.</p>
<h4 id="multi-sensor-fusion">멀티 센서 융합(Multi-Sensor Fusion)</h4>
<p>포인트클라우드를 활용한 3D 지도 생성 과정에서 하나의 센서만으로는 모든 환경 정보를 완벽하게 수집하기 어렵다. 각 센서는 저마다의 강점과 약점이 있으며, 여러 센서로부터 데이터를 융합함으로써 더 풍부하고 정확한 정보를 얻을 수 있다. 멀티 센서 융합은 이러한 다양한 센서로부터 수집된 데이터를 일관성 있게 통합하여 보다 정밀한 3D 지도를 생성하는 데 중요한 역할을 한다.</p>
<p>멀티 센서 융합은 주로 두 가지 방식으로 이루어진다: 
- <strong>센서 간 데이터 동기화</strong>: 서로 다른 센서에서 수집된 데이터를 시간적, 공간적으로 일치시키는 과정.
- <strong>센서 간 데이터 보정</strong>: 각 센서의 고유한 오차와 노이즈를 줄이기 위한 보정 작업.</p>
<p>여기에서 데이터 동기화와 보정 방법에 대해 간단히 설명한다.</p>
<h5 id="_4">센서 간 데이터 동기화</h5>
<p>센서 간의 데이터를 동기화하는 작업은 3D 지도 생성에서 중요한 부분이다. 특히 LiDAR와 같은 고주파 센서와 카메라와 같은 저주파 센서 간의 데이터 동기화가 필요하다. 센서마다 데이터가 수집되는 주기가 다를 수 있기 때문에, 데이터 수집 시간에 따른 보간법을 사용하여 시간 차이를 줄이거나, 데이터가 불균형하게 들어오는 경우에는 타임 스탬프 기반의 융합 방법이 사용된다. </p>
<p>데이터 동기화는 다음과 같은 방식으로 진행된다:
1. <strong>타임 스탬프 기반 동기화</strong>: 각 데이터가 수집될 때의 타임 스탬프를 기준으로 시간 간격을 최소화한다.<br />
2. <strong>보간법</strong>: 특정 센서의 데이터가 빠를 경우, 느린 센서의 데이터는 보간(interpolation)하여 동기화한다.</p>
<div class="arithmatex">
<div class="MathJax_Preview">
\mathbf{p}_i(t) = \mathbf{p}_i(t_0) + (t - t_0) \cdot \frac{\Delta \mathbf{p}_i}{\Delta t}
</div>
<script type="math/tex; mode=display">
\mathbf{p}_i(t) = \mathbf{p}_i(t_0) + (t - t_0) \cdot \frac{\Delta \mathbf{p}_i}{\Delta t}
</script>
</div>
<p>여기서 <span class="arithmatex"><span class="MathJax_Preview">t_0</span><script type="math/tex">t_0</script></span>는 이전 타임 스탬프, <span class="arithmatex"><span class="MathJax_Preview">t</span><script type="math/tex">t</script></span>는 현재 타임 스탬프, <span class="arithmatex"><span class="MathJax_Preview">\Delta \mathbf{p}_i</span><script type="math/tex">\Delta \mathbf{p}_i</script></span>는 두 시점 사이의 위치 변화이다.</p>
<h5 id="_5">센서 간 데이터 보정</h5>
<p>센서 간 데이터는 수집된 환경, 장비의 배치, 외부 요인 등에 따라 오차가 발생할 수 있다. 따라서 센서 데이터 간의 오차를 줄이기 위해 보정 작업이 필요하다. 이를 위해 주로 <strong>캘리브레이션</strong> 기법이 사용되며, 각 센서 간의 상대적 위치와 방향을 조정하여 일치시킨다. 캘리브레이션은 주로 다음과 같은 방식으로 이루어진다:</p>
<ol>
<li><strong>좌표계 변환</strong>: 각 센서의 좌표계를 통일하여 하나의 참조 좌표계로 변환한다. 이를 위해 다음과 같은 변환 행렬을 적용한다.</li>
</ol>
<div class="arithmatex">
<div class="MathJax_Preview">
\mathbf{T}_{\text{sensor}} = \mathbf{R}_{\text{sensor}} \cdot \mathbf{p}_{\text{sensor}} + \mathbf{t}_{\text{sensor}}
</div>
<script type="math/tex; mode=display">
\mathbf{T}_{\text{sensor}} = \mathbf{R}_{\text{sensor}} \cdot \mathbf{p}_{\text{sensor}} + \mathbf{t}_{\text{sensor}}
</script>
</div>
<p>여기서 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{R}_{\text{sensor}}</span><script type="math/tex">\mathbf{R}_{\text{sensor}}</script></span>는 회전 행렬, <span class="arithmatex"><span class="MathJax_Preview">\mathbf{t}_{\text{sensor}}</span><script type="math/tex">\mathbf{t}_{\text{sensor}}</script></span>는 변환 벡터이다. 이 변환을 통해 모든 센서의 데이터를 하나의 일관된 좌표계로 변환한다.</p>
<ol>
<li><strong>오차 모델링</strong>: 각 센서가 가진 고유한 노이즈와 오차를 모델링하여 보정한다. 이는 수집된 데이터를 여러 차례 반복 측정하여 평균값을 얻거나, 통계적 방법을 이용하여 노이즈를 줄인다.</li>
</ol>
<p>이러한 동기화 및 보정 작업을 통해 다양한 센서로부터 수집된 데이터는 하나의 일관된 3D 포인트클라우드로 통합되며, 이를 기반으로 3D 지도가 생성된다. 이를 통해 보다 정확한 환경 정보를 얻을 수 있다.</p>

  <br>
    

    <br>
</div>

<footer class="container-fluid wm-page-content">
  <p>Documentation built with <a href="https://www.mkdocs.org/">MkDocs</a> using <a href="https://github.com/gristlabs/mkdocs-windmill">Windmill</a> theme by Grist Labs.</p>
</footer>

</body>
</html>