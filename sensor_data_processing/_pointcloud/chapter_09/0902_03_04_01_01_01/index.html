<!DOCTYPE html>

<html lang="en">
<head>
<meta charset="utf-8"/>
<meta content="IE=edge" http-equiv="X-UA-Compatible"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<link href="https://booiljung.github.io/sensor_data_processing/_pointcloud/chapter_09/0902_03_04_01_01_01/" rel="canonical"/>
<link href="../../../../img/favicon.ico" rel="shortcut icon"/>
<meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport">
<title>K-최근접 이웃(KNN) - 실험 도서관</title>
<link href="../../../../css/bootstrap-3.3.7.min.css" rel="stylesheet"/>
<link href="../../../../css/font-awesome-4.7.0.css" rel="stylesheet"/>
<link href="../../../../css/base.css" rel="stylesheet"/>
<link href="../../../../css/highlight.css" rel="stylesheet"/>
<link href="../../../../css/custom.css" rel="stylesheet"/>
<!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
<!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.3.0/respond.min.js"></script>
    <![endif]-->
<script src="../../../../js/jquery-3.2.1.min.js"></script>
<script src="../../../../js/bootstrap-3.3.7.min.js"></script>
<script src="../../../../js/highlight.pack.js"></script>
<base target="_top"/>
<script>
      var base_url = '../../../..';
      var is_top_frame = false;
        
        var pageToc = [
          {title: "K-\ucd5c\uadfc\uc811 \uc774\uc6c3 \ud0d0\uc0c9 \uac1c\uc694", url: "#_top", children: [
          ]},
          {title: "\uc720\ud074\ub9ac\ub4dc \uac70\ub9ac \uacc4\uc0b0", url: "#_1", children: [
          ]},
          {title: "K-\ucd5c\uadfc\uc811 \uc774\uc6c3 \uc54c\uace0\ub9ac\uc998", url: "#k-_1", children: [
          ]},
          {title: "\ud0d0\uc0c9 \uad6c\uc870 \ucd5c\uc801\ud654", url: "#_2", children: [
          ]},
          {title: "KD-\ud2b8\ub9ac \uae30\ubc18 KNN \ud0d0\uc0c9", url: "#kd-knn", children: [
          ]},
          {title: "\uba54\ubaa8\ub9ac \ubc0f \uc131\ub2a5 \uace0\ub824 \uc0ac\ud56d", url: "#_3", children: [
          ]},
          {title: "\ub2e4\uc774\uc5b4\uadf8\ub7a8\uc73c\ub85c \ud45c\ud604\ud55c KNN\uc758 \ud0d0\uc0c9 \uacfc\uc815", url: "#knn", children: [
          ]},
          {title: "K-\ucd5c\uadfc\uc811 \uc774\uc6c3\uc5d0\uc11c\uc758 \uac70\ub9ac \uba54\ud2b8\ub9ad", url: "#k-_2", children: [
              {title: "\ub9e8\ud574\ud2bc \uac70\ub9ac (Manhattan Distance)", url: "#manhattan-distance" },
              {title: "\ub9c8\ud560\ub77c\ub178\ube44\uc2a4 \uac70\ub9ac (Mahalanobis Distance)", url: "#mahalanobis-distance" },
              {title: "\ucca8\ub450\uac70\ub9ac (Chebyshev Distance)", url: "#chebyshev-distance" },
          ]},
          {title: "K \uac12 \uc120\ud0dd", url: "#k", children: [
          ]},
          {title: "\ud6a8\uc728\uc801\uc778 KNN \uad6c\ud604\uc744 \uc704\ud55c \ucd5c\uc801\ud654 \uae30\uc220", url: "#knn_1", children: [
          ]},
        ];

    </script>
<script src="../../../../js/base.js"></script>
<script src="../../../../js/google_analytics.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML"></script>
<script src="https://www.googletagmanager.com/gtag/js?id=G-3F4LHCTF88"></script>
</meta></head>
<body>
<script>
if (is_top_frame) { $('body').addClass('wm-top-page'); }
</script>
<div class="container-fluid wm-page-content">
<a name="_top"></a>
<h3 id="k-">K-최근접 이웃 탐색 개요</h3>
<p>K-최근접 이웃(K-Nearest Neighbors, KNN) 알고리즘은 포인트클라우드 데이터에서 각 포인트에 대해 가장 가까운 <strong>K</strong>개의 이웃 포인트를 탐색하는 과정이다. 이 방법은 포인트의 국지적 특성을 계산할 때 많이 사용되며, 특히 FPFH(Fast Point Feature Histograms) 정렬 과정에서 중요한 역할을 한다.</p>
<p>포인트클라우드에서 각 포인트 <strong>p</strong>에 대해, <strong>K</strong>개의 가장 가까운 이웃 포인트를 탐색하는 방식은 주로 거리 기반 메트릭을 활용하여 이루어진다. 일반적으로 유클리드 거리( <span class="arithmatex"><span class="MathJax_Preview">\text{Euclidean Distance}</span><script type="math/tex">\text{Euclidean Distance}</script></span> )가 사용되며, 이는 두 포인트 간의 거리를 계산하는 데 있어 가장 보편적이고 효율적인 방법이다. </p>
<h3 id="_1">유클리드 거리 계산</h3>
<p>두 포인트 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{p}_i = (x_i, y_i, z_i)</span><script type="math/tex">\mathbf{p}_i = (x_i, y_i, z_i)</script></span>와 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{p}_j = (x_j, y_j, z_j)</span><script type="math/tex">\mathbf{p}_j = (x_j, y_j, z_j)</script></span>가 있을 때, 이들 사이의 유클리드 거리는 다음과 같이 정의된다:</p>
<div class="arithmatex">
<div class="MathJax_Preview">
d(\mathbf{p}_i, \mathbf{p}_j) = \sqrt{(x_j - x_i)^2 + (y_j - y_i)^2 + (z_j - z_i)^2}
</div>
<script type="math/tex; mode=display">
d(\mathbf{p}_i, \mathbf{p}_j) = \sqrt{(x_j - x_i)^2 + (y_j - y_i)^2 + (z_j - z_i)^2}
</script>
</div>
<p>여기서 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{p}_i</span><script type="math/tex">\mathbf{p}_i</script></span>는 탐색 중인 포인트이며, <span class="arithmatex"><span class="MathJax_Preview">\mathbf{p}_j</span><script type="math/tex">\mathbf{p}_j</script></span>는 후보 이웃 포인트이다. 이 거리를 기준으로 하여 포인트 <strong>p</strong>에 가장 가까운 <strong>K</strong>개의 이웃을 찾는다.</p>
<h3 id="k-_1">K-최근접 이웃 알고리즘</h3>
<p>KNN 알고리즘의 기본적인 절차는 다음과 같다:</p>
<ol>
<li><strong>포인트 기준 설정:</strong> 포인트클라우드 내에서 기준 포인트 <strong>p</strong>를 선택한다.</li>
<li><strong>거리 계산:</strong> 기준 포인트 <strong>p</strong>와 나머지 모든 포인트 간의 거리를 계산한다. 
   이때 사용하는 거리는 주로 유클리드 거리이며, 경우에 따라 다른 거리 함수도 사용할 수 있다.</li>
<li><strong>가장 가까운 K개의 포인트 선택:</strong> 계산된 거리 중 가장 작은 값부터 순서대로 <strong>K</strong>개의 포인트를 선택한다.</li>
<li><strong>이웃 정보 저장:</strong> 선택된 <strong>K</strong>개의 이웃 포인트는 포인트 <strong>p</strong>의 국지적 정보를 제공하기 때문에, FPFH 계산 등에 활용된다.</li>
</ol>
<p>이 과정은 포인트클라우드의 각 포인트마다 반복되며, 전체 클라우드에 대해 포인트마다 <strong>K</strong>개의 가장 가까운 이웃이 선택된다.</p>
<h3 id="_2">탐색 구조 최적화</h3>
<p>KNN 탐색은 포인트클라우드와 같은 대용량 데이터에서 계산 비용이 매우 높을 수 있다. 따라서 효율적인 탐색을 위해 다양한 공간 분할 구조가 사용된다. 대표적인 방법은 KD-트리(K-Dimensional Tree)이다. KD-트리는 고차원 공간을 분할하여 포인트들 사이의 이웃 관계를 빠르게 탐색할 수 있도록 최적화된 자료 구조이다.</p>
<h3 id="kd-knn">KD-트리 기반 KNN 탐색</h3>
<p>KD-트리를 사용하여 K-최근접 이웃을 탐색하는 과정은 다음과 같이 요약된다:</p>
<ol>
<li><strong>트리 생성:</strong> 주어진 포인트클라우드를 기반으로 KD-트리를 구축한다. 이 트리는 각 차원에 대해 포인트들을 분할하여 저장한다.</li>
<li><strong>트리 탐색:</strong> KD-트리를 탐색하여 기준 포인트 <strong>p</strong>에 대해 가장 가까운 <strong>K</strong>개의 포인트를 찾는다. 이 탐색 과정은 트리의 분할 구조를 이용하여 효율적으로 이루어진다.</li>
<li><strong>K-최근접 이웃 반환:</strong> 탐색 결과로 가장 가까운 <strong>K</strong>개의 이웃을 반환한다.</li>
</ol>
<p>KD-트리를 활용하면 탐색 복잡도가 <strong>O(N \log N)</strong>으로 감소하여, 대용량 포인트클라우드에서도 실시간 성능을 확보할 수 있다. </p>
<h3 id="_3">메모리 및 성능 고려 사항</h3>
<p>K-최근접 이웃 알고리즘은 데이터셋의 크기와 선택한 <strong>K</strong> 값에 따라 메모리 사용량과 성능에 큰 영향을 받는다. 따라서, 최적화된 탐색 알고리즘과 적절한 <strong>K</strong> 값을 선택하는 것이 중요하다. 특히 실시간 응용 프로그램에서는 KD-트리와 같은 구조를 사용하여 성능을 극대화하고, 너무 큰 <strong>K</strong> 값을 피하는 것이 바람직하다.</p>
<h3 id="knn">다이어그램으로 표현한 KNN의 탐색 과정</h3>
<div class="mermaid">graph TD;
    A[포인트클라우드] --&gt; B[기준 포인트 p 설정];
    B --&gt; C[모든 포인트와 거리 계산];
    C --&gt; D[가장 가까운 K개의 이웃 선택];
    D --&gt; E[이웃 정보 저장];
</div>
<h3 id="k-_2">K-최근접 이웃에서의 거리 메트릭</h3>
<p>K-최근접 이웃 탐색에서는 유클리드 거리가 가장 일반적으로 사용되지만, 다른 거리 메트릭도 선택할 수 있다. 포인트클라우드의 성격이나 처리 목적에 따라 다양한 거리 메트릭을 사용할 수 있으며, 이는 <strong>K</strong>개의 이웃 선택 결과에 영향을 미친다.</p>
<h4 id="manhattan-distance">맨해튼 거리 (Manhattan Distance)</h4>
<p>맨해튼 거리는 포인트들 사이의 축 방향 거리 합을 기반으로 계산된다. 이는 유클리드 거리와 달리 대각선 이동을 허용하지 않기 때문에, 그리드 기반 데이터에서 사용되는 경우가 많다. 두 포인트 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{p}_i = (x_i, y_i, z_i)</span><script type="math/tex">\mathbf{p}_i = (x_i, y_i, z_i)</script></span>와 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{p}_j = (x_j, y_j, z_j)</span><script type="math/tex">\mathbf{p}_j = (x_j, y_j, z_j)</script></span> 사이의 맨해튼 거리는 다음과 같이 정의된다:</p>
<div class="arithmatex">
<div class="MathJax_Preview">
d(\mathbf{p}_i, \mathbf{p}_j) = |x_j - x_i| + |y_j - y_i| + |z_j - z_i|
</div>
<script type="math/tex; mode=display">
d(\mathbf{p}_i, \mathbf{p}_j) = |x_j - x_i| + |y_j - y_i| + |z_j - z_i|
</script>
</div>
<p>이 거리는 데이터의 각 축에 대한 이동을 분리하여 계산하므로, 유클리드 거리와는 다른 패턴을 보일 수 있다.</p>
<h4 id="mahalanobis-distance">마할라노비스 거리 (Mahalanobis Distance)</h4>
<p>마할라노비스 거리는 포인트클라우드에서 포인트들 간의 상관관계를 반영한 거리 측정 방법이다. 특히, 데이터가 다차원이고 각 차원 간의 상관관계가 높은 경우 유용하다. 두 포인트 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{p}_i</span><script type="math/tex">\mathbf{p}_i</script></span>와 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{p}_j</span><script type="math/tex">\mathbf{p}_j</script></span> 사이의 마할라노비스 거리는 다음과 같이 정의된다:</p>
<div class="arithmatex">
<div class="MathJax_Preview">
d(\mathbf{p}_i, \mathbf{p}_j) = \sqrt{(\mathbf{p}_i - \mathbf{p}_j)^T \mathbf{S}^{-1} (\mathbf{p}_i - \mathbf{p}_j)}
</div>
<script type="math/tex; mode=display">
d(\mathbf{p}_i, \mathbf{p}_j) = \sqrt{(\mathbf{p}_i - \mathbf{p}_j)^T \mathbf{S}^{-1} (\mathbf{p}_i - \mathbf{p}_j)}
</script>
</div>
<p>여기서 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{S}</span><script type="math/tex">\mathbf{S}</script></span>는 포인트 데이터의 공분산 행렬을 나타낸다. 마할라노비스 거리는 공분산 행렬 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{S}</span><script type="math/tex">\mathbf{S}</script></span>에 따라 변하므로, 데이터의 분포와 밀접한 관계를 가지고 있다.</p>
<h4 id="chebyshev-distance">첨두거리 (Chebyshev Distance)</h4>
<p>첩두거리(Chebyshev Distance)는 두 포인트 간의 최댓값 절대 차이로 정의된다. 이는 포인트들 사이에서 가장 큰 축 방향 차이를 기준으로 거리를 측정하는 방식이다. 두 포인트 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{p}_i = (x_i, y_i, z_i)</span><script type="math/tex">\mathbf{p}_i = (x_i, y_i, z_i)</script></span>와 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{p}_j = (x_j, y_j, z_j)</span><script type="math/tex">\mathbf{p}_j = (x_j, y_j, z_j)</script></span> 사이의 첩두거리는 다음과 같다:</p>
<div class="arithmatex">
<div class="MathJax_Preview">
d(\mathbf{p}_i, \mathbf{p}_j) = \max(|x_j - x_i|, |y_j - y_i|, |z_j - z_i|)
</div>
<script type="math/tex; mode=display">
d(\mathbf{p}_i, \mathbf{p}_j) = \max(|x_j - x_i|, |y_j - y_i|, |z_j - z_i|)
</script>
</div>
<p>이 메트릭은 각 차원에서의 최댓값을 취하는 방식으로 거리를 측정하기 때문에, 다른 거리 메트릭과는 다른 특성을 가진다.</p>
<h3 id="k">K 값 선택</h3>
<p>KNN에서 <strong>K</strong> 값은 매우 중요한 역할을 한다. <strong>K</strong>가 너무 작으면 잡음에 민감해질 수 있고, <strong>K</strong>가 너무 크면 중요한 국지적 특성이 희석될 수 있다. 따라서, <strong>K</strong> 값은 응용 분야와 포인트클라우드의 밀도에 따라 적절하게 설정해야 한다.</p>
<ul>
<li><strong>작은 K 값</strong>: 작은 값의 <strong>K</strong>는 국지적인 특징을 더 잘 반영할 수 있지만, 잡음에 민감하다. 이는 정밀한 영역에서 세밀한 분석이 필요할 때 유리하다.</li>
<li><strong>큰 K 값</strong>: 큰 값의 <strong>K</strong>는 잡음에 덜 민감하지만, 국지적 특성을 희석할 수 있다. 이는 더 넓은 영역에서 포괄적인 분석이 필요할 때 유리하다.</li>
</ul>
<p>적절한 <strong>K</strong> 값의 선택은 실험적인 조정이나 경험적인 데이터에 의존하는 경우가 많으며, 일부 알고리즘에서는 최적의 <strong>K</strong> 값을 자동으로 찾는 방법을 사용하기도 한다.</p>
<h3 id="knn_1">효율적인 KNN 구현을 위한 최적화 기술</h3>
<p>KNN 탐색의 계산 비용을 줄이기 위해 다양한 최적화 기술이 사용된다. 일반적으로 사용되는 KD-트리 외에도 볼록 껍질 알고리즘, 정렬 기반 탐색 등의 방법이 있다. 이러한 기술들은 포인트간 거리 계산의 복잡도를 줄여주며, 특히 대용량 포인트클라우드 데이터에서 중요한 성능 향상을 가져올 수 있다.</p>
<br/>
<br/>
</div>
<footer class="container-fluid wm-page-content">
<p>Documentation built with <a href="https://www.mkdocs.org/">MkDocs</a> using <a href="https://github.com/gristlabs/mkdocs-windmill">Windmill</a> theme by Grist Labs.</p>
</footer>
<script type="module">import mermaid from "https://unpkg.com/mermaid@10.4.0/dist/mermaid.esm.min.mjs";
mermaid.initialize({});</script></body>
</html>