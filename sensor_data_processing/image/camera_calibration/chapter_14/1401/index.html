<!DOCTYPE html>
<html lang="en">
<head>
  
  
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    
    
    <link rel="canonical" href="https://booiljung.github.io/sensor_data_processing/image/camera_calibration/chapter_14/1401/">
    <link rel="shortcut icon" href="../../../../../img/favicon.ico">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" />
    <title>카메라 캘리브레이션의 미래 - 실험 도서관</title>
    <link href="../../../../../css/bootstrap-3.3.7.min.css" rel="stylesheet">
    <link href="../../../../../css/font-awesome-4.7.0.css" rel="stylesheet">
    <link href="../../../../../css/base.css" rel="stylesheet">
    <link rel="stylesheet" href="../../../../../css/highlight.css">
    <link href="../../../../../css/custom.css" rel="stylesheet">
    <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.3.0/respond.min.js"></script>
    <![endif]-->

    <script src="../../../../../js/jquery-3.2.1.min.js"></script>
    <script src="../../../../../js/bootstrap-3.3.7.min.js"></script>
    <script src="../../../../../js/highlight.pack.js"></script>
    
    <base target="_top">
    <script>
      var base_url = '../../../../..';
      var is_top_frame = false;
        
        var pageToc = [
          {title: "1. \ube44\uc804 \uc2dc\uc2a4\ud15c\uc758 \ud655\uc7a5", url: "#_top", children: [
          ]},
          {title: "2. \uc790\ub3d9\ud654\ub41c \uce98\ub9ac\ube0c\ub808\uc774\uc158 \uc2dc\uc2a4\ud15c", url: "#2", children: [
              {title: "\uc790\ub3d9\ud654 \uc54c\uace0\ub9ac\uc998\uc758 \ubc1c\uc804", url: "#_1" },
          ]},
          {title: "3. \uba38\uc2e0\ub7ec\ub2dd \uae30\ubc18\uc758 \uce98\ub9ac\ube0c\ub808\uc774\uc158", url: "#3", children: [
              {title: "\ub124\ud2b8\uc6cc\ud06c \uad6c\uc870", url: "#_2" },
          ]},
          {title: "4. \ube44\uc804 \ud2b8\ub79c\uc2a4\ud3ec\uba38\uc758 \ub3c4\uc785", url: "#4", children: [
              {title: "\ube44\uc804 \ud2b8\ub79c\uc2a4\ud3ec\uba38\uc758 \ud2b9\uc9d5", url: "#_3" },
          ]},
          {title: "5. \uace0\uc815\ubc00 \uce98\ub9ac\ube0c\ub808\uc774\uc158\uc744 \uc704\ud55c \ube44\uc804 \ud2b8\ub79c\uc2a4\ud3ec\uba38", url: "#5", children: [
              {title: "\uc2a4\ud14c\ub808\uc624 \uce74\uba54\ub77c \uc2dc\uc2a4\ud15c\uc5d0\uc11c\uc758 \ud2b8\ub79c\uc2a4\ud3ec\uba38 \uc751\uc6a9", url: "#_4" },
          ]},
          {title: "6. \uc2e4\uc2dc\uac04 \uce98\ub9ac\ube0c\ub808\uc774\uc158", url: "#6", children: [
              {title: "\uc2e4\uc2dc\uac04 \ucd5c\uc801\ud654 \ubc29\ubc95", url: "#_5" },
              {title: "Kalman \ud544\ud130\ub97c \uc774\uc6a9\ud55c \uc2e4\uc2dc\uac04 \uce98\ub9ac\ube0c\ub808\uc774\uc158", url: "#kalman" },
          ]},
          {title: "7. \ub525\ub7ec\ub2dd\uacfc \uce74\uba54\ub77c \uce98\ub9ac\ube0c\ub808\uc774\uc158\uc758 \uc735\ud569", url: "#7", children: [
              {title: "\ud559\uc2b5 \uae30\ubc18 \uc65c\uace1 \ubaa8\ub378", url: "#_6" },
              {title: "\uac15\ud654 \ud559\uc2b5\uc744 \ud1b5\ud55c \uc2e4\uc2dc\uac04 \ubcf4\uc815", url: "#_7" },
          ]},
          {title: "8. \uba40\ud2f0 \uce74\uba54\ub77c \uce98\ub9ac\ube0c\ub808\uc774\uc158", url: "#8", children: [
              {title: "\uce74\uba54\ub77c \ub124\ud2b8\uc6cc\ud06c\uc758 \ucd5c\uc801\ud654", url: "#_8" },
              {title: "\ub2e4\uc911 \ubdf0 \uae30\ud558\ud559\uc758 \ud655\uc7a5", url: "#_9" },
          ]},
          {title: "9. \ud074\ub77c\uc6b0\ub4dc \uae30\ubc18 \uce98\ub9ac\ube0c\ub808\uc774\uc158", url: "#9", children: [
              {title: "\ubd84\uc0b0 \ucef4\ud4e8\ud305\uc744 \uc774\uc6a9\ud55c \ub300\uaddc\ubaa8 \uce98\ub9ac\ube0c\ub808\uc774\uc158", url: "#_10" },
          ]},
        ];

    </script>
    <script src="../../../../../js/base.js"></script>
      <script src="../../../../../js/google_analytics.js"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML"></script>
      <script src="https://www.googletagmanager.com/gtag/js?id=G-3F4LHCTF88"></script> 
</head>

<body>
<script>
if (is_top_frame) { $('body').addClass('wm-top-page'); }
</script>



<div class="container-fluid wm-page-content">
  <a name="_top"></a>
    

    
    
      
    

  <div class="row wm-article-nav-buttons" role="navigation" aria-label="navigation">
    
    <div class="wm-article-nav pull-right">
      <a href="../1402/" class="btn btn-xs btn-default pull-right">
        Next
        <i class="fa fa-chevron-right" aria-hidden="true"></i>
      </a>
      <a href="../1402/" class="btn btn-xs btn-link">
        연구 및 실무에서의 과제
      </a>
    </div>
    
    <div class="wm-article-nav">
      <a href="../../chapter_13/1302/" class="btn btn-xs btn-default pull-left">
        <i class="fa fa-chevron-left" aria-hidden="true"></i>
        Previous</a><a href="../../chapter_13/1302/" class="btn btn-xs btn-link">
        비전 트랜스포머를 이용한 캘리브레이션의 미래
      </a>
    </div>
    
  </div>

    

    <h3 id="1">1. 비전 시스템의 확장</h3>
<p>카메라 캘리브레이션의 발전은 비전 시스템의 역할이 증가함에 따라 더욱 중요해지고 있다. 특히, 다양한 산업 분야에서의 응용은 캘리브레이션 기술의 발전을 요구하고 있다. 로봇 공학, 자율 주행, 증강 현실(AR) 및 가상 현실(VR) 시스템 등에서 카메라의 역할은 단순한 이미지 수집을 넘어서 더 복잡한 분석과 센서 융합을 필요로 한다. 이러한 응용에서 높은 정확도의 캘리브레이션이 필수적이다. </p>
<h3 id="2">2. 자동화된 캘리브레이션 시스템</h3>
<p>현재의 대부분의 캘리브레이션 방법은 수동적인 과정이 포함되어 있어 많은 인력이 필요하다. 이를 해결하기 위해 자동화된 캘리브레이션 시스템이 연구되고 있으며, 특히 반복적인 캘리브레이션 절차를 자동화하여 시스템의 안정성과 정확성을 유지하는 것이 주요 과제가 되고 있다. </p>
<h4 id="_1">자동화 알고리즘의 발전</h4>
<p>자동화된 캘리브레이션은 반복적인 계산 과정을 자동화하는 알고리즘을 필요로 한다. 여기서 중요한 점은 시스템이 외부 환경 변화에 적응하며, 변형된 조건에서도 정확한 파라미터를 추출할 수 있는 능력이다. 이를 위해 머신러닝과 최적화 기법이 도입되고 있다.</p>
<h3 id="3">3. 머신러닝 기반의 캘리브레이션</h3>
<p>최근 연구에서는 딥러닝 및 머신러닝을 이용한 카메라 캘리브레이션 방법이 활발히 연구되고 있다. 기존의 물리 기반 캘리브레이션 방법은 많은 매개변수와 환경 설정이 요구되지만, 딥러닝 기반 방법은 데이터에 의해 학습되므로 더 적은 사전 정보로도 고성능의 캘리브레이션을 수행할 수 있다.</p>
<h4 id="_2">네트워크 구조</h4>
<p>머신러닝을 기반으로 한 캘리브레이션은 주로 CNN(Convolutional Neural Network)을 사용하여 이미지 데이터로부터 중요한 특징을 추출한 후, 이 특징들을 기반으로 카메라의 내부 및 외부 파라미터를 예측하는 방식으로 진행된다. 이 과정에서 사용하는 주요 네트워크는 다음과 같다:</p>
<ul>
<li><strong>ResNet</strong>: 깊은 네트워크 구조를 갖추어 다양한 스케일에서 특징을 추출.</li>
<li><strong>UNet</strong>: 이미지 내에서 국부적인 특징과 전역적인 특징을 결합하여 왜곡 보정 및 파라미터 추정에 사용.</li>
</ul>
<h3 id="4">4. 비전 트랜스포머의 도입</h3>
<p>전통적인 CNN 기반의 네트워크 외에도, 비전 트랜스포머(ViT)가 캘리브레이션 작업에 도입되고 있다. 트랜스포머는 이미지의 공간적인 정보뿐만 아니라 시퀀스의 전역적인 의존성을 효과적으로 학습할 수 있기 때문에, 여러 카메라 시스템에서의 상호 캘리브레이션과 같은 복잡한 작업에서 성능이 우수한다.</p>
<h4 id="_3">비전 트랜스포머의 특징</h4>
<p>비전 트랜스포머는 주로 self-attention 메커니즘을 이용하여 이미지 내의 중요한 정보들을 학습한다. 이는 기존의 CNN보다 더 전역적인 정보를 학습할 수 있으며, 특히 다중 카메라 시스템에서 각 카메라 간의 상호 관계를 더 잘 모델링할 수 있다. </p>
<p>수학적으로, 트랜스포머의 self-attention은 다음과 같이 정의된다:</p>
<div class="arithmatex">
<div class="MathJax_Preview">
\mathbf{Attention}(Q, K, V) = \mathbf{softmax}\left( \frac{QK^T}{\sqrt{d_k}} \right)V
</div>
<script type="math/tex; mode=display">
\mathbf{Attention}(Q, K, V) = \mathbf{softmax}\left( \frac{QK^T}{\sqrt{d_k}} \right)V
</script>
</div>
<p>여기서 <span class="arithmatex"><span class="MathJax_Preview">Q</span><script type="math/tex">Q</script></span>는 쿼리 행렬, <span class="arithmatex"><span class="MathJax_Preview">K</span><script type="math/tex">K</script></span>는 키 행렬, <span class="arithmatex"><span class="MathJax_Preview">V</span><script type="math/tex">V</script></span>는 값 행렬이며, <span class="arithmatex"><span class="MathJax_Preview">d_k</span><script type="math/tex">d_k</script></span>는 차원의 크기이다.</p>
<h3 id="5">5. 고정밀 캘리브레이션을 위한 비전 트랜스포머</h3>
<p>비전 트랜스포머(ViT)의 도입으로 고정밀 캘리브레이션이 가능해지면서 다양한 응용 분야에서 실질적인 이점을 제공하고 있다. 예를 들어, 여러 카메라에서 얻은 영상들을 통합하여 공간적 일관성을 유지하면서 정확한 위치 추정 및 깊이 정보를 추출할 수 있게 된다. 이와 같은 시스템은 자율 주행 차량, 로봇 비전 시스템 등에서 필수적이다.</p>
<h4 id="_4">스테레오 카메라 시스템에서의 트랜스포머 응용</h4>
<p>스테레오 카메라 시스템에서는 두 개 이상의 카메라로부터 입력을 받아 깊이 정보를 계산한다. 여기서 각 카메라의 상호 간섭을 최소화하면서 정밀한 캘리브레이션을 수행해야 한다. 트랜스포머 기반의 모델은 각 카메라의 영상 데이터를 효율적으로 학습하며, 비선형 왜곡을 자동으로 보정할 수 있는 장점을 갖는다.</p>
<p>스테레오 카메라 시스템에서 깊이 추정은 주로 두 카메라 간의 변환 관계를 기반으로 이루어지며, 그 변환은 다음과 같이 나타낼 수 있다:</p>
<div class="arithmatex">
<div class="MathJax_Preview">
\mathbf{X_2} = \mathbf{R} \mathbf{X_1} + \mathbf{T}
</div>
<script type="math/tex; mode=display">
\mathbf{X_2} = \mathbf{R} \mathbf{X_1} + \mathbf{T}
</script>
</div>
<p>여기서 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{X_1}</span><script type="math/tex">\mathbf{X_1}</script></span>과 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{X_2}</span><script type="math/tex">\mathbf{X_2}</script></span>는 각각 첫 번째와 두 번째 카메라 좌표계에서의 점을 나타내며, <span class="arithmatex"><span class="MathJax_Preview">\mathbf{R}</span><script type="math/tex">\mathbf{R}</script></span>은 회전 행렬, <span class="arithmatex"><span class="MathJax_Preview">\mathbf{T}</span><script type="math/tex">\mathbf{T}</script></span>는 변환 벡터이다.</p>
<h3 id="6">6. 실시간 캘리브레이션</h3>
<p>실시간 캘리브레이션은 동적으로 변하는 환경에서 캘리브레이션을 유지할 수 있는 기술이다. 기존의 캘리브레이션 방식은 정적 환경에서 수행되었으나, 자율 주행이나 로봇 비전과 같은 응용에서는 환경이 계속 변화하기 때문에 실시간으로 캘리브레이션이 재조정될 필요가 있다.</p>
<h4 id="_5">실시간 최적화 방법</h4>
<p>실시간 캘리브레이션은 계산 효율성을 극대화하기 위해 최적화 기법을 사용한다. 특히, Levenberg-Marquardt 알고리즘이나 Kalman 필터와 같은 기술이 실시간 시스템에 적합한다.</p>
<p>Levenberg-Marquardt 알고리즘은 비선형 최소제곱 문제를 해결하는 데 사용되며, 실시간 캘리브레이션 과정에서 매우 효과적이다. 알고리즘은 다음과 같은 형태로 최적화된다:</p>
<div class="arithmatex">
<div class="MathJax_Preview">
\mathbf{x}_{k+1} = \mathbf{x}_k - \left( J^T J + \lambda I \right)^{-1} J^T \mathbf{r}
</div>
<script type="math/tex; mode=display">
\mathbf{x}_{k+1} = \mathbf{x}_k - \left( J^T J + \lambda I \right)^{-1} J^T \mathbf{r}
</script>
</div>
<p>여기서 <span class="arithmatex"><span class="MathJax_Preview">J</span><script type="math/tex">J</script></span>는 야코비 행렬, <span class="arithmatex"><span class="MathJax_Preview">\lambda</span><script type="math/tex">\lambda</script></span>는 조정 파라미터, <span class="arithmatex"><span class="MathJax_Preview">\mathbf{r}</span><script type="math/tex">\mathbf{r}</script></span>은 잔여 오차 벡터이다.</p>
<h4 id="kalman">Kalman 필터를 이용한 실시간 캘리브레이션</h4>
<p>Kalman 필터는 시스템 상태를 실시간으로 예측하고, 새로운 측정값이 들어올 때마다 상태를 업데이트하는 방식으로 작동한다. 카메라 캘리브레이션에서는 카메라의 위치와 파라미터를 실시간으로 보정하는 데 유용하다.</p>
<p>Kalman 필터의 기본적인 단계는 다음과 같다:</p>
<ol>
<li><strong>예측 단계</strong>: 상태와 공분산을 예측</li>
</ol>
<div class="arithmatex">
<div class="MathJax_Preview">
\mathbf{\hat{x}}_{k|k-1} = \mathbf{A} \mathbf{\hat{x}}_{k-1|k-1} + \mathbf{B} \mathbf{u}_k
</div>
<script type="math/tex; mode=display">
\mathbf{\hat{x}}_{k|k-1} = \mathbf{A} \mathbf{\hat{x}}_{k-1|k-1} + \mathbf{B} \mathbf{u}_k
</script>
</div>
<div class="arithmatex">
<div class="MathJax_Preview">
\mathbf{P}_{k|k-1} = \mathbf{A} \mathbf{P}_{k-1|k-1} \mathbf{A}^T + \mathbf{Q}
</div>
<script type="math/tex; mode=display">
\mathbf{P}_{k|k-1} = \mathbf{A} \mathbf{P}_{k-1|k-1} \mathbf{A}^T + \mathbf{Q}
</script>
</div>
<ol>
<li><strong>갱신 단계</strong>: 새로운 측정값을 기반으로 상태와 공분산을 업데이트</li>
</ol>
<div class="arithmatex">
<div class="MathJax_Preview">
\mathbf{K}_k = \mathbf{P}_{k|k-1} \mathbf{H}^T \left( \mathbf{H} \mathbf{P}_{k|k-1} \mathbf{H}^T + \mathbf{R} \right)^{-1}
</div>
<script type="math/tex; mode=display">
\mathbf{K}_k = \mathbf{P}_{k|k-1} \mathbf{H}^T \left( \mathbf{H} \mathbf{P}_{k|k-1} \mathbf{H}^T + \mathbf{R} \right)^{-1}
</script>
</div>
<div class="arithmatex">
<div class="MathJax_Preview">
\mathbf{\hat{x}}_{k|k} = \mathbf{\hat{x}}_{k|k-1} + \mathbf{K}_k \left( \mathbf{z}_k - \mathbf{H} \mathbf{\hat{x}}_{k|k-1} \right)
</div>
<script type="math/tex; mode=display">
\mathbf{\hat{x}}_{k|k} = \mathbf{\hat{x}}_{k|k-1} + \mathbf{K}_k \left( \mathbf{z}_k - \mathbf{H} \mathbf{\hat{x}}_{k|k-1} \right)
</script>
</div>
<div class="arithmatex">
<div class="MathJax_Preview">
\mathbf{P}_{k|k} = \left( I - \mathbf{K}_k \mathbf{H} \right) \mathbf{P}_{k|k-1}
</div>
<script type="math/tex; mode=display">
\mathbf{P}_{k|k} = \left( I - \mathbf{K}_k \mathbf{H} \right) \mathbf{P}_{k|k-1}
</script>
</div>
<h3 id="7">7. 딥러닝과 카메라 캘리브레이션의 융합</h3>
<p>딥러닝은 기존의 기하학적 모델링 접근 방식을 넘어 카메라 캘리브레이션의 정확도를 향상시키는 데 기여하고 있다. 이러한 방법론은 방대한 양의 데이터를 통해 학습을 진행하며, 기존의 캘리브레이션 방법이 처리할 수 없는 복잡한 왜곡이나 비선형성을 극복할 수 있는 잠재력을 가지고 있다.</p>
<h4 id="_6">학습 기반 왜곡 모델</h4>
<p>기존의 카메라 왜곡 모델은 수학적으로 정의된 방정식을 기반으로 하지만, 딥러닝 기반 모델은 데이터에서 직접 학습된 왜곡 패턴을 통해 이를 보정할 수 있다. 특히, 왜곡 패턴이 매우 복잡하거나 불규칙적인 경우, 딥러닝 모델은 더욱 유연하게 대처할 수 있다.</p>
<h4 id="_7">강화 학습을 통한 실시간 보정</h4>
<p>강화 학습을 사용하여 실시간 캘리브레이션 보정을 수행하는 접근 방식도 연구되고 있다. 이 방법은 에이전트가 지속적으로 카메라 입력을 통해 환경을 학습하고, 캘리브레이션 파라미터를 실시간으로 조정함으로써 최적의 성능을 유지할 수 있게 한다. 이는 특히 로봇 비전 시스템과 자율 주행 시스템에서 중요한 역할을 할 수 있다.</p>
<h3 id="8">8. 멀티 카메라 캘리브레이션</h3>
<p>캘리브레이션의 미래는 단일 카메라에 국한되지 않고, 다중 카메라 시스템을 효과적으로 조정하는 방법으로 확장되고 있다. 여러 카메라 간의 정확한 관계 설정은 3D 환경의 정밀한 복원과 같은 다양한 응용에 필수적이다.</p>
<h4 id="_8">카메라 네트워크의 최적화</h4>
<p>멀티 카메라 시스템에서는 각 카메라의 위치와 방향뿐만 아니라, 각 카메라 간의 상호 관계를 최적화해야 한다. 이를 위해 다음과 같은 다중 시점 기하학적 관계가 필요하다:</p>
<ul>
<li><strong>기본 행렬</strong>: 두 카메라 간의 대응 관계를 정의하며, 다음과 같은 수식으로 표현된다:</li>
</ul>
<div class="arithmatex">
<div class="MathJax_Preview">
\mathbf{x'}^T \mathbf{F} \mathbf{x} = 0
</div>
<script type="math/tex; mode=display">
\mathbf{x'}^T \mathbf{F} \mathbf{x} = 0
</script>
</div>
<p>여기서 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{F}</span><script type="math/tex">\mathbf{F}</script></span>는 기본 행렬, <span class="arithmatex"><span class="MathJax_Preview">\mathbf{x}</span><script type="math/tex">\mathbf{x}</script></span>와 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{x'}</span><script type="math/tex">\mathbf{x'}</script></span>는 각각 두 카메라에서의 대응 점을 나타낸다.</p>
<ul>
<li><strong>삼각 측량</strong>: 다중 카메라에서의 3D 점을 추정하는 과정으로, 두 카메라 간의 투영 행렬 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{P}_1, \mathbf{P}_2</span><script type="math/tex">\mathbf{P}_1, \mathbf{P}_2</script></span>와 대응 점을 이용하여 다음과 같이 3D 좌표 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{X}</span><script type="math/tex">\mathbf{X}</script></span>를 추정할 수 있다:</li>
</ul>
<div class="arithmatex">
<div class="MathJax_Preview">
\mathbf{x}_i = \mathbf{P}_i \mathbf{X}
</div>
<script type="math/tex; mode=display">
\mathbf{x}_i = \mathbf{P}_i \mathbf{X}
</script>
</div>
<p>여기서 <span class="arithmatex"><span class="MathJax_Preview">i</span><script type="math/tex">i</script></span>는 카메라의 인덱스를 나타낸다.</p>
<h4 id="_9">다중 뷰 기하학의 확장</h4>
<p>멀티 카메라 배열에서 다중 뷰 기하학은 여러 시점에서 수집된 데이터를 통합하여 고정밀 3D 재구성을 가능하게 한다. 이러한 기법은 영상 처리, 영화 제작, 증강 현실 및 가상 현실에서 필수적이다.</p>
<h3 id="9">9. 클라우드 기반 캘리브레이션</h3>
<p>미래의 캘리브레이션 기술은 클라우드 컴퓨팅을 활용하여 더 빠르고 효율적인 방식으로 발전할 것이다. 클라우드 기반 캘리브레이션 시스템은 물리적 제약을 넘어서 다양한 장치 간의 데이터를 수집하고 처리하여 높은 성능의 캘리브레이션을 수행할 수 있다.</p>
<h4 id="_10">분산 컴퓨팅을 이용한 대규모 캘리브레이션</h4>
<p>클라우드 인프라를 통해 대규모 멀티 카메라 시스템의 데이터를 분산 처리하여 캘리브레이션 속도를 향상시킬 수 있다. 이를 통해 많은 카메라가 동시에 작동하는 복잡한 환경에서도 실시간으로 정밀한 캘리브레이션이 가능해진다. </p>

  <br>
    

    
    
      
    

  <div class="row wm-article-nav-buttons" role="navigation" aria-label="navigation">
    
    <div class="wm-article-nav pull-right">
      <a href="../1402/" class="btn btn-xs btn-default pull-right">
        Next
        <i class="fa fa-chevron-right" aria-hidden="true"></i>
      </a>
      <a href="../1402/" class="btn btn-xs btn-link">
        연구 및 실무에서의 과제
      </a>
    </div>
    
    <div class="wm-article-nav">
      <a href="../../chapter_13/1302/" class="btn btn-xs btn-default pull-left">
        <i class="fa fa-chevron-left" aria-hidden="true"></i>
        Previous</a><a href="../../chapter_13/1302/" class="btn btn-xs btn-link">
        비전 트랜스포머를 이용한 캘리브레이션의 미래
      </a>
    </div>
    
  </div>

    <br>
</div>

<footer class="container-fluid wm-page-content">
  <p>Documentation built with <a href="https://www.mkdocs.org/">MkDocs</a> using <a href="https://github.com/gristlabs/mkdocs-windmill">Windmill</a> theme by Grist Labs.</p>
</footer>

</body>
</html>