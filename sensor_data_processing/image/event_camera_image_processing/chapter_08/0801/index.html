<!DOCTYPE html>
<html lang="en">
<head>
  
  
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    
    
    <link rel="canonical" href="https://booiljung.github.io/sensor_data_processing/image/event_camera_image_processing/chapter_08/0801/">
    <link rel="shortcut icon" href="../../../../../img/favicon.ico">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" />
    <title>이벤트 데이터를 위한 딥러닝 모델 - 실험 도서관</title>
    <link href="../../../../../css/bootstrap-3.3.7.min.css" rel="stylesheet">
    <link href="../../../../../css/font-awesome-4.7.0.css" rel="stylesheet">
    <link href="../../../../../css/base.css" rel="stylesheet">
    <link rel="stylesheet" href="../../../../../css/highlight.css">
    <link href="../../../../../css/custom.css" rel="stylesheet">
    <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.3.0/respond.min.js"></script>
    <![endif]-->

    <script src="../../../../../js/jquery-3.2.1.min.js"></script>
    <script src="../../../../../js/bootstrap-3.3.7.min.js"></script>
    <script src="../../../../../js/highlight.pack.js"></script>
    
    <base target="_top">
    <script>
      var base_url = '../../../../..';
      var is_top_frame = false;
        
        var pageToc = [
          {title: "\uc774\ubca4\ud2b8 \uc2a4\ud2b8\ub9bc\uc758 \ud2b9\uc131\uacfc \ub525\ub7ec\ub2dd \ubaa8\ub378 \uc124\uacc4", url: "#_top", children: [
          ]},
          {title: "\uc774\ubca4\ud2b8 \ub370\uc774\ud130 \uc804\ucc98\ub9ac", url: "#_2", children: [
          ]},
          {title: "\uc2dc\uacf5\uac04 \ud2b9\uc9d5 \ucd94\ucd9c", url: "#_3", children: [
              {title: "3D \ucee8\ubcfc\ub8e8\uc158 \ub124\ud2b8\uc6cc\ud06c", url: "#3d" },
          ]},
          {title: "Recurrent Neural Networks (RNN)\uacfc LSTM", url: "#recurrent-neural-networks-rnn-lstm", children: [
          ]},
          {title: "Spiking Neural Networks (SNN)", url: "#spiking-neural-networks-snn", children: [
          ]},
          {title: "Graph Neural Networks (GNN)", url: "#graph-neural-networks-gnn", children: [
              {title: "Graph Attention Networks (GAT)", url: "#graph-attention-networks-gat" },
          ]},
          {title: "4D CNN", url: "#4d-cnn", children: [
          ]},
          {title: "Event-based Transformers", url: "#event-based-transformers", children: [
              {title: "Self-Attention \uba54\ucee4\ub2c8\uc998", url: "#self-attention" },
              {title: "Multi-Head Attention", url: "#multi-head-attention" },
              {title: "Event-based Transformer\uc758 \uc751\uc6a9", url: "#event-based-transformer" },
          ]},
          {title: "Hybrid Models: CNN\uacfc RNN/LSTM\uc758 \uacb0\ud569", url: "#hybrid-models-cnn-rnnlstm", children: [
          ]},
        ];

    </script>
    <script src="../../../../../js/base.js"></script>
      <script src="../../../../../js/google_analytics.js"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML"></script>
      <script src="https://www.googletagmanager.com/gtag/js?id=G-3F4LHCTF88"></script> 
</head>

<body>
<script>
if (is_top_frame) { $('body').addClass('wm-top-page'); }
</script>



<div class="container-fluid wm-page-content">
  <a name="_top"></a>
    

    
    
      
    

  <div class="row wm-article-nav-buttons" role="navigation" aria-label="navigation">
    
    <div class="wm-article-nav pull-right">
      <a href="../0802/" class="btn btn-xs btn-default pull-right">
        Next
        <i class="fa fa-chevron-right" aria-hidden="true"></i>
      </a>
      <a href="../0802/" class="btn btn-xs btn-link">
        신경망 아키텍처 최적화
      </a>
    </div>
    
    <div class="wm-article-nav">
      <a href="../../chapter_07/0703/" class="btn btn-xs btn-default pull-left">
        <i class="fa fa-chevron-left" aria-hidden="true"></i>
        Previous</a><a href="../../chapter_07/0703/" class="btn btn-xs btn-link">
        이벤트 기반 SLAM의 응용
      </a>
    </div>
    
  </div>

    

    <p>이벤트 카메라의 데이터는 전통적인 프레임 기반 비디오와는 완전히 다른 구조를 가지고 있다. 일반적인 카메라의 영상은 일정한 시간 간격으로 촬영된 정적인 이미지들의 연속이다. 그러나 이벤트 카메라의 경우, 픽셀 단위로 시간에 따른 밝기 변화에만 반응하여 비동기적으로 이벤트 데이터를 발생시키며, 이러한 데이터는 매우 높은 시간 해상도를 갖는다. 이 특성으로 인해 기존의 딥러닝 모델을 그대로 사용할 수 없으며, 이벤트 데이터에 맞춘 새로운 딥러닝 아키텍처가 필요하다.</p>
<h3 id="_1">이벤트 스트림의 특성과 딥러닝 모델 설계</h3>
<p>이벤트 카메라 데이터는 주로 <code>(x, y, t, p)</code>의 형식을 갖는다. 여기서 <code>x</code>와 <code>y</code>는 픽셀 좌표, <code>t</code>는 시간, <code>p</code>는 폴라리티(밝기가 증가하면 1, 감소하면 -1)이다. 이벤트 스트림은 연속적인 프레임 대신, 각 픽셀의 밝기 변화가 발생한 순간만 기록하기 때문에 매우 희소(sparse)한 정보로 이루어져 있다. 이러한 희소성은 연산을 크게 줄여주지만, 일반적인 컨볼루션 신경망(CNN)을 사용하기 어려운 문제도 발생시킨다.</p>
<p>이벤트 스트림의 시간적 연속성을 처리하기 위해 딥러닝 모델은 두 가지 접근 방식을 사용할 수 있다:</p>
<ol>
<li>
<p><strong>프레임으로 변환 후 처리</strong>: 이벤트 데이터를 일정한 시간 간격으로 프레임으로 변환하여 기존의 CNN 모델로 처리하는 방법이다. 이 방식은 기존의 딥러닝 인프라를 그대로 사용할 수 있다는 장점이 있지만, 이벤트 카메라의 고유한 시간적 해상도를 충분히 활용하지 못하는 단점이 있다.</p>
</li>
<li>
<p><strong>시계열 데이터로 직접 처리</strong>: 이벤트 데이터를 시계열 데이터로 취급하여 RNN(순환 신경망)이나 LSTM(Long Short-Term Memory)과 같은 모델로 처리하는 방식이다. 시간 정보를 포함한 이벤트 데이터를 그대로 활용할 수 있어 더 효과적인 결과를 기대할 수 있지만, 이 경우 더 복잡한 모델 설계가 필요하다.</p>
</li>
</ol>
<h3 id="_2">이벤트 데이터 전처리</h3>
<p>이벤트 데이터를 딥러닝 모델에 입력하기 전에 여러 가지 전처리 단계가 필요하다. 대표적인 전처리 단계는 다음과 같다:</p>
<ul>
<li><strong>이벤트 누적</strong>: 이벤트 카메라의 높은 시간 해상도로 인해 매우 빈번한 이벤트가 발생할 수 있다. 이를 적절히 누적하여 일정 시간 범위 내의 이벤트를 하나의 데이터로 처리할 수 있다. 이벤트 데이터를 시간 단위로 누적한 후, 누적된 데이터를 텐서로 변환하여 신경망의 입력으로 사용한다.</li>
</ul>
<div class="arithmatex">
<div class="MathJax_Preview">
\mathbf{E}_{\Delta t} = \sum_{t_0}^{t_0 + \Delta t} \mathbf{e}(x, y, t, p)
</div>
<script type="math/tex; mode=display">
\mathbf{E}_{\Delta t} = \sum_{t_0}^{t_0 + \Delta t} \mathbf{e}(x, y, t, p)
</script>
</div>
<p>여기서 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{E}_{\Delta t}</span><script type="math/tex">\mathbf{E}_{\Delta t}</script></span>는 시간 간격 <span class="arithmatex"><span class="MathJax_Preview">\Delta t</span><script type="math/tex">\Delta t</script></span> 동안의 누적된 이벤트 데이터이고, <span class="arithmatex"><span class="MathJax_Preview">\mathbf{e}(x, y, t, p)</span><script type="math/tex">\mathbf{e}(x, y, t, p)</script></span>는 각 이벤트를 나타낸다.</p>
<ul>
<li><strong>폴라리티 분리</strong>: 밝기 변화의 증가와 감소를 구분하는 폴라리티 값을 분리하여 두 개의 채널로 나누는 방식이 있다. 이는 신경망이 이벤트의 밝기 증가와 감소를 독립적으로 학습할 수 있게 한다.</li>
</ul>
<h3 id="_3">시공간 특징 추출</h3>
<p>이벤트 데이터는 공간적 정보(픽셀 좌표)와 시간적 정보(이벤트 발생 시간)를 동시에 가지고 있기 때문에, 이를 효과적으로 처리하기 위한 딥러닝 모델은 시공간 특징을 추출할 수 있어야 한다.</p>
<h4 id="3d">3D 컨볼루션 네트워크</h4>
<p>3D 컨볼루션 네트워크는 이벤트 데이터를 입력으로 받아 시간과 공간 정보를 동시에 처리할 수 있는 모델이다. 2D CNN이 공간적 정보를 처리하는 것과 달리, 3D CNN은 추가적인 시간 차원을 포함하여 시공간적 특징을 추출한다. 3D CNN의 필터는 시간 차원까지 포함된 커널을 사용하여 다음과 같은 수식으로 표현된다.</p>
<div class="arithmatex">
<div class="MathJax_Preview">
\mathbf{O}(x, y, t) = \sum_{i=1}^{N} \sum_{j=1}^{M} \sum_{k=1}^{T} \mathbf{W}(i, j, k) \cdot \mathbf{I}(x+i, y+j, t+k)
</div>
<script type="math/tex; mode=display">
\mathbf{O}(x, y, t) = \sum_{i=1}^{N} \sum_{j=1}^{M} \sum_{k=1}^{T} \mathbf{W}(i, j, k) \cdot \mathbf{I}(x+i, y+j, t+k)
</script>
</div>
<p>여기서 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{O}(x, y, t)</span><script type="math/tex">\mathbf{O}(x, y, t)</script></span>는 출력 특징 맵, <span class="arithmatex"><span class="MathJax_Preview">\mathbf{W}(i, j, k)</span><script type="math/tex">\mathbf{W}(i, j, k)</script></span>는 3D 컨볼루션 커널, <span class="arithmatex"><span class="MathJax_Preview">\mathbf{I}(x, y, t)</span><script type="math/tex">\mathbf{I}(x, y, t)</script></span>는 입력 데이터이다.</p>
<p>3D CNN은 프레임 기반 방법보다 이벤트 카메라의 고유한 시간적 정보를 더 잘 활용할 수 있지만, 연산량이 매우 크다는 단점이 있다.</p>
<h3 id="recurrent-neural-networks-rnn-lstm">Recurrent Neural Networks (RNN)과 LSTM</h3>
<p>이벤트 스트림의 시계열 특성을 더 잘 반영하기 위해 <strong>순환 신경망(RNN)</strong> 및 <strong>LSTM(Long Short-Term Memory)</strong> 같은 구조가 자주 사용된다. 이 방법은 이벤트 데이터가 비동기적으로 발생하는 특성을 모델이 학습할 수 있도록 돕는다. RNN이나 LSTM은 시간의 흐름에 따라 입력된 데이터를 반복적으로 처리하여, 이전 시간 단계의 정보를 다음 단계로 전달하며 학습한다.</p>
<p>일반적인 RNN의 수식은 다음과 같이 나타낼 수 있다:</p>
<div class="arithmatex">
<div class="MathJax_Preview">
\mathbf{h}_t = \sigma(\mathbf{W}_{h} \mathbf{h}_{t-1} + \mathbf{W}_{x} \mathbf{x}_t + \mathbf{b})
</div>
<script type="math/tex; mode=display">
\mathbf{h}_t = \sigma(\mathbf{W}_{h} \mathbf{h}_{t-1} + \mathbf{W}_{x} \mathbf{x}_t + \mathbf{b})
</script>
</div>
<p>여기서 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{h}_t</span><script type="math/tex">\mathbf{h}_t</script></span>는 현재 시점 <span class="arithmatex"><span class="MathJax_Preview">t</span><script type="math/tex">t</script></span>에서의 은닉 상태, <span class="arithmatex"><span class="MathJax_Preview">\mathbf{x}_t</span><script type="math/tex">\mathbf{x}_t</script></span>는 현재 시점에서의 입력 데이터, <span class="arithmatex"><span class="MathJax_Preview">\mathbf{W}_{h}</span><script type="math/tex">\mathbf{W}_{h}</script></span>는 은닉 상태에 대한 가중치 행렬, <span class="arithmatex"><span class="MathJax_Preview">\mathbf{W}_{x}</span><script type="math/tex">\mathbf{W}_{x}</script></span>는 입력에 대한 가중치 행렬, <span class="arithmatex"><span class="MathJax_Preview">\mathbf{b}</span><script type="math/tex">\mathbf{b}</script></span>는 편향이다.</p>
<p>LSTM은 RNN의 단점을 보완하여 긴 시간 간격의 의존성을 학습할 수 있다. LSTM의 핵심 개념은 '셀 상태'를 도입하여 정보를 유지하거나 버릴 수 있는 게이트 구조를 사용하는 것이다. LSTM의 주요 수식은 다음과 같다:</p>
<ol>
<li><strong>Forget Gate</strong>:</li>
</ol>
<p>$$
   \mathbf{f}<em>t = \sigma(\mathbf{W}_f \mathbf{h}</em>{t-1} + \mathbf{W}_{x_f} \mathbf{x}_t + \mathbf{b}_f)</p>
<p>$$</p>
<p>이 게이트는 이전 셀 상태를 얼마나 잊을지 결정한다.</p>
<ol>
<li><strong>Input Gate</strong>:</li>
</ol>
<p>$$
   \mathbf{i}<em>t = \sigma(\mathbf{W}_i \mathbf{h}</em>{t-1} + \mathbf{W}_{x_i} \mathbf{x}_t + \mathbf{b}_i)</p>
<p>$$</p>
<p>$$
   \mathbf{\tilde{C}}<em>t = \tanh(\mathbf{W}_C \mathbf{h}</em>{t-1} + \mathbf{W}_{x_C} \mathbf{x}_t + \mathbf{b}_C)</p>
<p>$$</p>
<p>이 게이트는 새로운 정보를 얼마나 업데이트할지를 결정한다.</p>
<ol>
<li><strong>Cell State Update</strong>:</li>
</ol>
<p>$$
   \mathbf{C}<em>t = \mathbf{f}_t \odot \mathbf{C}</em>{t-1} + \mathbf{i}_t \odot \mathbf{\tilde{C}}_t</p>
<p>$$</p>
<p>새로운 셀 상태는 이전 셀 상태와 현재 입력 정보를 기반으로 계산된다.</p>
<ol>
<li><strong>Output Gate</strong>:</li>
</ol>
<p>$$
   \mathbf{o}<em>t = \sigma(\mathbf{W}_o \mathbf{h}</em>{t-1} + \mathbf{W}_{x_o} \mathbf{x}_t + \mathbf{b}_o)</p>
<p>$$</p>
<p>$$
   \mathbf{h}_t = \mathbf{o}_t \odot \tanh(\mathbf{C}_t)</p>
<p>$$</p>
<p>이 게이트는 셀 상태를 기반으로 출력할 정보를 결정한다.</p>
<p>이와 같은 LSTM 모델은 이벤트 스트림과 같은 비정형 데이터를 처리하는 데 적합하며, 시간의 흐름에 따른 정보를 효과적으로 학습할 수 있다.</p>
<h3 id="spiking-neural-networks-snn">Spiking Neural Networks (SNN)</h3>
<p>이벤트 카메라는 비동기적으로 발생하는 데이터를 생성하기 때문에, <strong>스파이킹 신경망(SNN, Spiking Neural Networks)</strong>을 사용하는 방법도 고려된다. SNN은 생물학적 신경망을 모방한 모델로, 뉴런들이 특정한 임계값에 도달할 때만 스파이크를 발생시키며 정보를 전달한다. 이는 이벤트 카메라 데이터의 특성과 잘 맞아떨어진다.</p>
<p>스파이킹 뉴런의 동작은 <strong>르카 통합 및 발화 모델(LIF, Leaky Integrate and Fire)</strong>에 의해 설명될 수 있다. 뉴런의 전위는 시간에 따라 통합되며, 특정 임계값 <span class="arithmatex"><span class="MathJax_Preview">\theta</span><script type="math/tex">\theta</script></span>를 넘으면 스파이크가 발생한다. 이를 수식으로 표현하면 다음과 같다:</p>
<div class="arithmatex">
<div class="MathJax_Preview">
\tau \frac{dV(t)}{dt} = -V(t) + I(t)
</div>
<script type="math/tex; mode=display">
\tau \frac{dV(t)}{dt} = -V(t) + I(t)
</script>
</div>
<p>여기서 <span class="arithmatex"><span class="MathJax_Preview">V(t)</span><script type="math/tex">V(t)</script></span>는 시간 <span class="arithmatex"><span class="MathJax_Preview">t</span><script type="math/tex">t</script></span>에서의 뉴런의 전위, <span class="arithmatex"><span class="MathJax_Preview">I(t)</span><script type="math/tex">I(t)</script></span>는 입력 전류, <span class="arithmatex"><span class="MathJax_Preview">\tau</span><script type="math/tex">\tau</script></span>는 뉴런의 시간 상수이다. <span class="arithmatex"><span class="MathJax_Preview">V(t)</span><script type="math/tex">V(t)</script></span>가 <span class="arithmatex"><span class="MathJax_Preview">\theta</span><script type="math/tex">\theta</script></span>를 넘으면 뉴런은 스파이크를 발생시키고, 그 후 <span class="arithmatex"><span class="MathJax_Preview">V(t)</span><script type="math/tex">V(t)</script></span>는 초기값으로 리셋된다.</p>
<p>SNN은 이벤트 데이터의 시간적 특성을 효율적으로 반영할 수 있으며, 생물학적 신경망과 유사한 방식으로 작동하는 점에서 에너지 효율성도 높다. 하지만, SNN을 훈련시키는 것은 전통적인 신경망보다 더 어려운 과제이다.</p>
<h3 id="graph-neural-networks-gnn">Graph Neural Networks (GNN)</h3>
<p>이벤트 카메라에서 발생하는 데이터는 공간적으로 희소(sparse)하며, 전통적인 정규화된 이미지와는 매우 다르다. 이러한 데이터를 처리하기 위해 <strong>그래프 신경망(Graph Neural Networks, GNN)</strong>을 활용할 수 있다. 이벤트 카메라의 픽셀은 고정된 격자 구조를 가지지만, 각 이벤트는 비동기적으로 발생하며 시공간적으로 분포되어 있다. 이 특성을 반영하여 그래프 기반으로 데이터를 모델링할 수 있다.</p>
<p>GNN은 데이터의 비정형적인 구조를 처리하는 데 매우 적합한다. 이벤트 데이터를 그래프의 노드로 보고, 이벤트 간의 관계(예: 시간적 또는 공간적 근접성)를 엣지로 정의할 수 있다. GNN은 이런 그래프 구조에서 정보를 학습하여 이벤트 간의 상관관계를 파악하고 특징을 추출한다.</p>
<p>그래프에서 노드 <span class="arithmatex"><span class="MathJax_Preview">v_i</span><script type="math/tex">v_i</script></span>의 특징 벡터 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{h}_i</span><script type="math/tex">\mathbf{h}_i</script></span>는 이웃 노드들의 특징 벡터 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{h}_j</span><script type="math/tex">\mathbf{h}_j</script></span>와 함께 다음과 같은 방식으로 업데이트된다:</p>
<div class="arithmatex">
<div class="MathJax_Preview">
\mathbf{h}_i^{(k)} = \sigma \left( \mathbf{W}^{(k)} \sum_{j \in \mathcal{N}(i)} \mathbf{h}_j^{(k-1)} + \mathbf{b}^{(k)} \right)
</div>
<script type="math/tex; mode=display">
\mathbf{h}_i^{(k)} = \sigma \left( \mathbf{W}^{(k)} \sum_{j \in \mathcal{N}(i)} \mathbf{h}_j^{(k-1)} + \mathbf{b}^{(k)} \right)
</script>
</div>
<p>여기서 <span class="arithmatex"><span class="MathJax_Preview">\mathcal{N}(i)</span><script type="math/tex">\mathcal{N}(i)</script></span>는 노드 <span class="arithmatex"><span class="MathJax_Preview">i</span><script type="math/tex">i</script></span>의 이웃 노드 집합, <span class="arithmatex"><span class="MathJax_Preview">\mathbf{W}^{(k)}</span><script type="math/tex">\mathbf{W}^{(k)}</script></span>는 학습 가능한 가중치 행렬, <span class="arithmatex"><span class="MathJax_Preview">\mathbf{b}^{(k)}</span><script type="math/tex">\mathbf{b}^{(k)}</script></span>는 편향 벡터, <span class="arithmatex"><span class="MathJax_Preview">\sigma</span><script type="math/tex">\sigma</script></span>는 활성화 함수이다. 이러한 업데이트 과정을 통해 각 노드의 정보를 이웃 노드들로부터 받아 들여 더욱 풍부한 특징을 학습하게 된다.</p>
<h4 id="graph-attention-networks-gat">Graph Attention Networks (GAT)</h4>
<p><strong>그래프 어텐션 네트워크(Graph Attention Networks, GAT)</strong>는 GNN의 변형 중 하나로, 이웃 노드의 중요도에 가중치를 부여하여 각 노드의 업데이트를 수행한다. 이는 이벤트 카메라의 데이터에서 중요한 이벤트와 그렇지 않은 이벤트를 구분하는 데 효과적일 수 있다.</p>
<p>GAT에서는 어텐션 메커니즘을 사용하여 각 이웃 노드의 중요도를 계산하고, 이를 기반으로 노드 업데이트를 수행한다. 어텐션 가중치는 다음과 같이 계산된다:</p>
<div class="arithmatex">
<div class="MathJax_Preview">
e_{ij} = \text{LeakyReLU} \left( \mathbf{a}^{\top} \left[ \mathbf{W} \mathbf{h}_i \parallel \mathbf{W} \mathbf{h}_j \right] \right)
</div>
<script type="math/tex; mode=display">
e_{ij} = \text{LeakyReLU} \left( \mathbf{a}^{\top} \left[ \mathbf{W} \mathbf{h}_i \parallel \mathbf{W} \mathbf{h}_j \right] \right)
</script>
</div>
<p>여기서 <span class="arithmatex"><span class="MathJax_Preview">e_{ij}</span><script type="math/tex">e_{ij}</script></span>는 노드 <span class="arithmatex"><span class="MathJax_Preview">i</span><script type="math/tex">i</script></span>와 노드 <span class="arithmatex"><span class="MathJax_Preview">j</span><script type="math/tex">j</script></span> 간의 어텐션 점수, <span class="arithmatex"><span class="MathJax_Preview">\mathbf{a}</span><script type="math/tex">\mathbf{a}</script></span>는 학습 가능한 어텐션 벡터, <span class="arithmatex"><span class="MathJax_Preview">\parallel</span><script type="math/tex">\parallel</script></span>는 벡터의 연결(concatenation)을 의미한다. 이 어텐션 점수는 소프트맥스 함수로 정규화되어 최종 가중치로 변환된다:</p>
<div class="arithmatex">
<div class="MathJax_Preview">
\alpha_{ij} = \frac{\exp(e_{ij})}{\sum_{k \in \mathcal{N}(i)} \exp(e_{ik})}
</div>
<script type="math/tex; mode=display">
\alpha_{ij} = \frac{\exp(e_{ij})}{\sum_{k \in \mathcal{N}(i)} \exp(e_{ik})}
</script>
</div>
<p>이 가중치 <span class="arithmatex"><span class="MathJax_Preview">\alpha_{ij}</span><script type="math/tex">\alpha_{ij}</script></span>를 이용해 이웃 노드의 정보를 통합하여 노드 <span class="arithmatex"><span class="MathJax_Preview">i</span><script type="math/tex">i</script></span>의 특징 벡터를 업데이트한다.</p>
<p>GAT은 그래프에서 중요한 이웃 노드에 더 많은 가중치를 부여함으로써, 이벤트 데이터 내에서 더 중요한 이벤트에 집중하는 데 유용하다.</p>
<h3 id="4d-cnn">4D CNN</h3>
<p>이벤트 카메라 데이터는 3D 공간(픽셀 좌표 및 시간)에 폴라리티 값이 추가된 4차원 데이터로 생각할 수 있다. 이 특성을 반영하여 <strong>4D CNN</strong> 구조를 사용할 수도 있다. 4D CNN은 공간적, 시간적 정보를 동시에 고려하면서 추가적인 폴라리티 채널을 처리하는 방식이다.</p>
<p>4D CNN의 수식은 3D CNN의 수식을 확장한 형태로, 다음과 같이 나타낼 수 있다:</p>
<div class="arithmatex">
<div class="MathJax_Preview">
\mathbf{O}(x, y, t, p) = \sum_{i=1}^{N} \sum_{j=1}^{M} \sum_{k=1}^{T} \sum_{l=1}^{P} \mathbf{W}(i, j, k, l) \cdot \mathbf{I}(x+i, y+j, t+k, p+l)
</div>
<script type="math/tex; mode=display">
\mathbf{O}(x, y, t, p) = \sum_{i=1}^{N} \sum_{j=1}^{M} \sum_{k=1}^{T} \sum_{l=1}^{P} \mathbf{W}(i, j, k, l) \cdot \mathbf{I}(x+i, y+j, t+k, p+l)
</script>
</div>
<p>여기서 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{O}(x, y, t, p)</span><script type="math/tex">\mathbf{O}(x, y, t, p)</script></span>는 출력 특징 맵, <span class="arithmatex"><span class="MathJax_Preview">\mathbf{W}(i, j, k, l)</span><script type="math/tex">\mathbf{W}(i, j, k, l)</script></span>는 4D 컨볼루션 커널, <span class="arithmatex"><span class="MathJax_Preview">\mathbf{I}(x, y, t, p)</span><script type="math/tex">\mathbf{I}(x, y, t, p)</script></span>는 입력 이벤트 데이터이다. 이와 같은 구조는 공간적, 시간적, 그리고 폴라리티 정보를 모두 포함하여 이벤트 카메라의 데이터를 처리할 수 있다.</p>
<p>4D CNN은 매우 높은 차원의 데이터를 처리할 수 있지만, 연산량이 커지는 단점이 있다. 그러나 시공간적 특징을 동시에 추출하는 데 있어서 매우 강력한 성능을 발휘할 수 있다.</p>
<h3 id="event-based-transformers">Event-based Transformers</h3>
<p>최근에 주목받고 있는 딥러닝 모델 중 하나인 <strong>Transformer</strong>는 주로 자연어 처리(NLP) 분야에서 사용되지만, 이벤트 기반 데이터에도 적용될 수 있다. 이벤트 데이터의 희소성과 비동기적인 특성을 잘 처리할 수 있는 가능성이 있기 때문이다. 특히 이벤트 데이터에서 발생하는 시간적, 공간적 상호작용을 Transformer의 <strong>Self-Attention</strong> 메커니즘으로 학습할 수 있다.</p>
<h4 id="self-attention">Self-Attention 메커니즘</h4>
<p>Self-Attention은 입력 시퀀스의 각 요소가 다른 모든 요소와 상호작용할 수 있도록 도와준다. 이벤트 데이터는 시계열 특성을 가지므로, Self-Attention은 이벤트들 사이의 상관관계를 학습하는 데 적합한다.</p>
<p>Self-Attention에서 각 입력 이벤트 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{x}_i</span><script type="math/tex">\mathbf{x}_i</script></span>는 쿼리, 키, 밸류로 변환된다. 수식으로는 다음과 같이 나타난다:</p>
<div class="arithmatex">
<div class="MathJax_Preview">
\mathbf{Q} = \mathbf{X} \mathbf{W}_Q, \quad \mathbf{K} = \mathbf{X} \mathbf{W}_K, \quad \mathbf{V} = \mathbf{X} \mathbf{W}_V
</div>
<script type="math/tex; mode=display">
\mathbf{Q} = \mathbf{X} \mathbf{W}_Q, \quad \mathbf{K} = \mathbf{X} \mathbf{W}_K, \quad \mathbf{V} = \mathbf{X} \mathbf{W}_V
</script>
</div>
<p>여기서 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{Q}</span><script type="math/tex">\mathbf{Q}</script></span>, <span class="arithmatex"><span class="MathJax_Preview">\mathbf{K}</span><script type="math/tex">\mathbf{K}</script></span>, <span class="arithmatex"><span class="MathJax_Preview">\mathbf{V}</span><script type="math/tex">\mathbf{V}</script></span>는 각각 쿼리, 키, 밸류 벡터들이고, <span class="arithmatex"><span class="MathJax_Preview">\mathbf{W}_Q</span><script type="math/tex">\mathbf{W}_Q</script></span>, <span class="arithmatex"><span class="MathJax_Preview">\mathbf{W}_K</span><script type="math/tex">\mathbf{W}_K</script></span>, <span class="arithmatex"><span class="MathJax_Preview">\mathbf{W}_V</span><script type="math/tex">\mathbf{W}_V</script></span>는 학습 가능한 가중치 행렬이다.</p>
<p>이제 쿼리와 키를 사용하여 이벤트 간의 유사도를 계산한다. 유사도는 각 쿼리와 키의 내적을 통해 계산되며, 이를 소프트맥스 함수를 통해 정규화한 후, 밸류 벡터에 가중치를 적용한다:</p>
<div class="arithmatex">
<div class="MathJax_Preview">
\text{Attention}(\mathbf{Q}, \mathbf{K}, \mathbf{V}) = \text{softmax}\left( \frac{\mathbf{Q} \mathbf{K}^\top}{\sqrt{d_k}} \right) \mathbf{V}
</div>
<script type="math/tex; mode=display">
\text{Attention}(\mathbf{Q}, \mathbf{K}, \mathbf{V}) = \text{softmax}\left( \frac{\mathbf{Q} \mathbf{K}^\top}{\sqrt{d_k}} \right) \mathbf{V}
</script>
</div>
<p>여기서 <span class="arithmatex"><span class="MathJax_Preview">d_k</span><script type="math/tex">d_k</script></span>는 키 벡터의 차원이다. Self-Attention 메커니즘은 입력된 각 이벤트가 다른 이벤트와 어떤 관계가 있는지를 학습하고, 이 정보를 사용하여 중요한 특징을 추출할 수 있다.</p>
<h4 id="multi-head-attention">Multi-Head Attention</h4>
<p>Transformer에서는 Self-Attention을 여러 번 반복하여 서로 다른 부분의 정보를 학습하는 <strong>Multi-Head Attention</strong>을 사용한다. 각 헤드는 서로 다른 방식으로 데이터를 처리하며, 이 결과를 결합하여 더욱 풍부한 특징을 얻을 수 있다.</p>
<p>수식으로는 각 헤드의 결과를 연결(concatenation)한 후, 이를 다시 가중치 행렬로 변환하는 방식으로 나타낼 수 있다:</p>
<div class="arithmatex">
<div class="MathJax_Preview">
\text{MultiHead}(\mathbf{Q}, \mathbf{K}, \mathbf{V}) = \text{Concat}(\text{head}_1, \dots, \text{head}_h) \mathbf{W}_O
</div>
<script type="math/tex; mode=display">
\text{MultiHead}(\mathbf{Q}, \mathbf{K}, \mathbf{V}) = \text{Concat}(\text{head}_1, \dots, \text{head}_h) \mathbf{W}_O
</script>
</div>
<p>여기서 각 <span class="arithmatex"><span class="MathJax_Preview">\text{head}_i</span><script type="math/tex">\text{head}_i</script></span>는 Self-Attention의 결과이고, <span class="arithmatex"><span class="MathJax_Preview">\mathbf{W}_O</span><script type="math/tex">\mathbf{W}_O</script></span>는 학습 가능한 가중치 행렬이다.</p>
<h4 id="event-based-transformer">Event-based Transformer의 응용</h4>
<p>이벤트 카메라 데이터에 Transformer를 적용하는 것은 각 이벤트 간의 시간적, 공간적 관계를 깊이 있게 학습할 수 있는 가능성을 열어준다. Self-Attention 메커니즘은 비정형적인 이벤트 데이터를 잘 처리할 수 있으며, 특히 다중 이벤트 간의 상관관계나 중요한 패턴을 학습하는 데 강력한 도구가 될 수 있다. 또한 Transformer 모델은 병렬 처리가 가능하다는 장점도 가지고 있어, 이벤트 데이터의 비동기적인 특성을 효과적으로 처리할 수 있다.</p>
<h3 id="hybrid-models-cnn-rnnlstm">Hybrid Models: CNN과 RNN/LSTM의 결합</h3>
<p>이벤트 데이터를 다루기 위해 <strong>CNN과 RNN/LSTM의 결합 모델</strong>을 사용하는 경우도 많이 연구되고 있다. CNN은 이벤트 데이터의 공간적 특징을 추출하는 데 효과적이며, RNN이나 LSTM은 시간적 연속성을 학습하는 데 적합한다. 이러한 두 가지 모델을 결합함으로써, 공간적 및 시간적 정보를 동시에 활용할 수 있는 모델을 만들 수 있다.</p>
<p>결합 모델에서 CNN은 입력 이벤트 데이터를 필터링하여 공간적 특징 맵을 생성하고, 이 특징 맵을 RNN이나 LSTM에 전달하여 시간적 정보를 학습한다. 예를 들어, CNN을 사용하여 이벤트 데이터의 공간적 특징을 추출한 후, 각 시간 단계에서의 특징 맵을 LSTM에 입력하여 시간적 의존성을 학습할 수 있다. </p>
<p>하나의 가능한 모델 구조는 다음과 같이 나타낼 수 있다:</p>
<ol>
<li>CNN을 통해 각 시간 단계의 이벤트 데이터를 처리하여 특징 맵을 생성:</li>
</ol>
<p>$$
   \mathbf{F}_t = \text{CNN}(\mathbf{E}_t)</p>
<p>$$</p>
<p>여기서 <span class="arithmatex"><span class="MathJax_Preview">\mathbf{E}_t</span><script type="math/tex">\mathbf{E}_t</script></span>는 시간 <span class="arithmatex"><span class="MathJax_Preview">t</span><script type="math/tex">t</script></span>에서의 이벤트 데이터, <span class="arithmatex"><span class="MathJax_Preview">\mathbf{F}_t</span><script type="math/tex">\mathbf{F}_t</script></span>는 CNN을 통해 추출된 특징 맵이다.</p>
<ol>
<li>RNN 또는 LSTM을 통해 시간 단계별 특징 맵을 연결하여 시계열 데이터를 처리:</li>
</ol>
<p>$$
   \mathbf{h}<em>t = \text{LSTM}(\mathbf{F}_t, \mathbf{h}</em>{t-1})</p>
<p>$$</p>
<p>이와 같은 결합 모델은 이벤트 데이터의 공간적 및 시간적 패턴을 동시에 학습할 수 있어, 이벤트 기반 영상 처리에 강력한 성능을 발휘할 수 있다.</p>

  <br>
    

    
    
      
    

  <div class="row wm-article-nav-buttons" role="navigation" aria-label="navigation">
    
    <div class="wm-article-nav pull-right">
      <a href="../0802/" class="btn btn-xs btn-default pull-right">
        Next
        <i class="fa fa-chevron-right" aria-hidden="true"></i>
      </a>
      <a href="../0802/" class="btn btn-xs btn-link">
        신경망 아키텍처 최적화
      </a>
    </div>
    
    <div class="wm-article-nav">
      <a href="../../chapter_07/0703/" class="btn btn-xs btn-default pull-left">
        <i class="fa fa-chevron-left" aria-hidden="true"></i>
        Previous</a><a href="../../chapter_07/0703/" class="btn btn-xs btn-link">
        이벤트 기반 SLAM의 응용
      </a>
    </div>
    
  </div>

    <br>
</div>

<footer class="container-fluid wm-page-content">
  <p>Documentation built with <a href="https://www.mkdocs.org/">MkDocs</a> using <a href="https://github.com/gristlabs/mkdocs-windmill">Windmill</a> theme by Grist Labs.</p>
</footer>

</body>
</html>