<!DOCTYPE html>
<html lang="en">
<head>
  
  
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    
    
    <link rel="canonical" href="https://booiljung.github.io/applied_math/_optimization%20theory/CONTENTS/">
    <link rel="shortcut icon" href="../../../img/favicon.ico">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" />
    <title>최적화 이론 (Optimization Theory) - 실험 도서관</title>
    <link href="../../../css/bootstrap-3.3.7.min.css" rel="stylesheet">
    <link href="../../../css/font-awesome-4.7.0.css" rel="stylesheet">
    <link href="../../../css/base.css" rel="stylesheet">
    <link rel="stylesheet" href="../../../css/highlight.css">
    <link href="../../../css/custom.css" rel="stylesheet">
    <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.3.0/respond.min.js"></script>
    <![endif]-->

    <script src="../../../js/jquery-3.2.1.min.js"></script>
    <script src="../../../js/bootstrap-3.3.7.min.js"></script>
    <script src="../../../js/highlight.pack.js"></script>
    
    <base target="_top">
    <script>
      var base_url = '../../..';
      var is_top_frame = false;
        
        var pageToc = [
          {title: "\ucd5c\uc801\ud654 \uc774\ub860 (Optimization Theory)", url: "#_top", children: [
              {title: "\uc120\ud615 \uacc4\ud68d\ubc95 (Linear Programming)", url: "#linear-programming" },
              {title: "\uc774\ucc28 \uacc4\ud68d\ubc95 (Quadratic Programming)", url: "#quadratic-programming" },
              {title: "\ube44\uc120\ud615 \ucd5c\uc801\ud654 (Nonlinear Optimization)", url: "#nonlinear-optimization" },
              {title: "\ubcfc\ub85d \ucd5c\uc801\ud654 (Convex Optimization)", url: "#convex-optimization" },
              {title: "\uc815\uc218 \uacc4\ud68d\ubc95 (Integer Programming)", url: "#integer-programming" },
              {title: "\uc870\ud569 \ucd5c\uc801\ud654 (Combinatorial Optimization)", url: "#combinatorial-optimization" },
              {title: "\ub2e4\ubaa9\uc801 \ucd5c\uc801\ud654 (Multi-objective Optimization)", url: "#multi-objective-optimization" },
              {title: "\ub3d9\uc801 \uacc4\ud68d\ubc95 (Dynamic Programming)", url: "#dynamic-programming" },
              {title: "\uc804\uc5ed \ucd5c\uc801\ud654 (Global Optimization)", url: "#global-optimization" },
              {title: "\ud655\ub960\uc801 \ucd5c\uc801\ud654 (Stochastic Optimization)", url: "#stochastic-optimization" },
              {title: "\uba54\ud0c0\ud734\ub9ac\uc2a4\ud2f1 \uc54c\uace0\ub9ac\uc998 (Metaheuristic Algorithms)", url: "#metaheuristic-algorithms" },
              {title: "\ub85c\ubc84\uc2a4\ud2b8 \ucd5c\uc801\ud654 (Robust Optimization)", url: "#robust-optimization" },
              {title: "\uc138\ubbf8\ub370\ud53c\ub2c8\ud2b8 \ud504\ub85c\uadf8\ub798\ubc0d (Semidefinite Programming)", url: "#semidefinite-programming" },
              {title: "\uacbd\uc0ac\ud558\uac15\ubc95 (Gradient Descent)", url: "#gradient-descent" },
              {title: "\ub77c\uadf8\ub791\uc8fc \ucd5c\uc801\ud654 (Lagrangian Optimization)", url: "#lagrangian-optimization" },
              {title: "\uce74\ub8e8\uc2dc-\ucfe4-\ud130\ucee4 \uc870\uac74 (Karush-Kuhn-Tucker Conditions)", url: "#-karush-kuhn-tucker-conditions" },
              {title: "\uc870\uc815 \ucd5c\uc801\ud654 (Constrained Optimization)", url: "#constrained-optimization" },
              {title: "\ubd84\uc0b0 \ucd5c\uc801\ud654 (Distributed Optimization)", url: "#distributed-optimization" },
              {title: "\uc628\ub77c\uc778 \ucd5c\uc801\ud654 (Online Optimization)", url: "#online-optimization" },
              {title: "\uac15\ud654 \ud559\uc2b5 (Reinforcement Learning)", url: "#reinforcement-learning" },
              {title: "\ud655\ub960\uc801 \uacbd\uc0ac\ud558\uac15\ubc95 (Stochastic Gradient Descent)", url: "#stochastic-gradient-descent" },
              {title: "\ud568\uc218 \ud574\uc11d\ud559\uc801 \ucd5c\uc801\ud654 (Functional Analysis Optimization)", url: "#functional-analysis-optimization" },
              {title: "\uade0\ud615 \ucd5c\uc801\ud654 (Equilibrium Optimization)", url: "#equilibrium-optimization" },
              {title: "\uc9c0\uc218\uc801 \ucd5c\uc801\ud654 (Exponential Optimization)", url: "#exponential-optimization" },
              {title: "\ub0b4\uc0bd \ucd5c\uc801\ud654 (Interior Point Methods)", url: "#interior-point-methods" },
              {title: "\ubd80\ubd84\ud3c9\uade0\ubc95 (Subgradient Methods)", url: "#subgradient-methods" },
              {title: "\ubcd1\ub82c \ucd5c\uc801\ud654 (Parallel Optimization)", url: "#parallel-optimization" },
              {title: "\ubaa8\ub378 \uc608\uce21 \uc81c\uc5b4 (Model Predictive Control)", url: "#model-predictive-control" },
              {title: "\uc21c\ucc28\uc801 \uc774\ucc28 \uacc4\ud68d\ubc95 (Sequential Quadratic Programming)", url: "#sequential-quadratic-programming" },
              {title: "\ubcc0\ubd84\ubc95 (Calculus of Variations)", url: "#calculus-of-variations" },
          ]},
        ];

    </script>
    <script src="../../../js/base.js"></script>
      <script src="../../../js/google_analytics.js"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML"></script>
      <script src="https://www.googletagmanager.com/gtag/js?id=G-3F4LHCTF88"></script> 
</head>

<body>
<script>
if (is_top_frame) { $('body').addClass('wm-top-page'); }
</script>



<div class="container-fluid wm-page-content">
  <a name="_top"></a>
    

    

    <h1 id="optimization-theory">최적화 이론 (Optimization Theory)</h1>
<p><strong>최적화 이론</strong>은 수학과 공학에서 중요한 분야로, 주어진 제약 조건 하에서 가능한 모든 해 중에서 최적의 해를 찾는 방법을 연구합니다. 이는 자원을 효율적으로 배분하거나 시스템의 성능을 최대화 또는 최소화하는 데 사용됩니다.</p>
<h4 id="linear-programming">선형 계획법 (Linear Programming)</h4>
<p>선형 방정식과 부등식으로 구성된 제약 조건 하에서 선형 목적 함수를 최적화하는 방법입니다.</p>
<h4 id="quadratic-programming">이차 계획법 (Quadratic Programming)</h4>
<p>목적 함수가 이차 함수이며 제약 조건은 선형인 최적화 문제를 다룹니다.</p>
<h4 id="nonlinear-optimization">비선형 최적화 (Nonlinear Optimization)</h4>
<p>비선형 목적 함수나 제약 조건을 가진 최적화 문제를 해결하는 방법입니다.</p>
<h4 id="convex-optimization">볼록 최적화 (Convex Optimization)</h4>
<p>목적 함수와 제약 조건이 볼록인 경우에 전역 최적해를 효율적으로 찾는 최적화 방법입니다.</p>
<h4 id="integer-programming">정수 계획법 (Integer Programming)</h4>
<p>변수들이 정수 값을 가져야 하는 최적화 문제로, 조합론적 특성을 가집니다.</p>
<h4 id="combinatorial-optimization">조합 최적화 (Combinatorial Optimization)</h4>
<p>이산적인 조합 중에서 최적의 해를 찾는 최적화 분야로, 그래프 이론과 밀접한 관련이 있습니다.</p>
<h4 id="multi-objective-optimization">다목적 최적화 (Multi-objective Optimization)</h4>
<p>여러 개의 상충되는 목적 함수를 동시에 최적화하여 균형 있는 해를 찾는 방법입니다.</p>
<h4 id="dynamic-programming">동적 계획법 (Dynamic Programming)</h4>
<p>복잡한 문제를 더 작은 부분 문제로 분할하고 그 해를 결합하여 전체 문제를 해결하는 방법입니다.</p>
<h4 id="global-optimization">전역 최적화 (Global Optimization)</h4>
<p>여러 국소 최적해 중에서 가장 우수한 전역 최적해를 찾는 것을 목표로 합니다.</p>
<h4 id="stochastic-optimization">확률적 최적화 (Stochastic Optimization)</h4>
<p>불확실성과 확률 요소를 고려하여 최적화를 수행하는 방법입니다.</p>
<h4 id="metaheuristic-algorithms">메타휴리스틱 알고리즘 (Metaheuristic Algorithms)</h4>
<p>유전 알고리즘(Genetic Algorithm), 입자 군집 최적화(Particle Swarm Optimization) 등 자연 현상을 모방한 최적화 기법입니다.</p>
<h4 id="robust-optimization">로버스트 최적화 (Robust Optimization)</h4>
<p>데이터의 불확실성을 고려하여 최악의 상황에서도 성능이 보장되는 해를 찾는 방법입니다.</p>
<h4 id="semidefinite-programming">세미데피니트 프로그래밍 (Semidefinite Programming)</h4>
<p>반양정 정의성(Positive Semidefinite)을 가진 행렬을 이용하여 최적화하는 기법입니다.</p>
<h4 id="gradient-descent">경사하강법 (Gradient Descent)</h4>
<p>목적 함수의 기울기를 따라 가장 낮은 값을 찾는 방식으로, 기계 학습에서 많이 사용됩니다.</p>
<h4 id="lagrangian-optimization">라그랑주 최적화 (Lagrangian Optimization)</h4>
<p>라그랑주 승수(Lagrange Multipliers)를 사용하여 제약 조건이 있는 최적화 문제를 해결합니다.</p>
<h4 id="-karush-kuhn-tucker-conditions">카루시-쿤-터커 조건 (Karush-Kuhn-Tucker Conditions)</h4>
<p>비선형 제약 최적화 문제의 최적성 조건을 제공하는 이론입니다.</p>
<h4 id="constrained-optimization">조정 최적화 (Constrained Optimization)</h4>
<p>제약 조건 하에서 목적 함수를 최적화하는 일반적인 방법론입니다.</p>
<h4 id="distributed-optimization">분산 최적화 (Distributed Optimization)</h4>
<p>여러 개의 노드나 에이전트가 분산된 환경에서 협력하여 최적화를 수행하는 방법입니다.</p>
<h4 id="online-optimization">온라인 최적화 (Online Optimization)</h4>
<p>실시간으로 도착하는 데이터를 기반으로 즉각적인 최적의 결정을 내리는 방법입니다.</p>
<h4 id="reinforcement-learning">강화 학습 (Reinforcement Learning)</h4>
<p>에이전트가 환경과 상호 작용하며 보상을 최대화하도록 정책을 학습하는 기계 학습의 한 분야입니다.</p>
<h4 id="stochastic-gradient-descent">확률적 경사하강법 (Stochastic Gradient Descent)</h4>
<p>전체 데이터셋 대신 무작위로 선택된 일부 데이터를 사용하여 경사하강법을 수행하는 알고리즘입니다.</p>
<h4 id="functional-analysis-optimization">함수 해석학적 최적화 (Functional Analysis Optimization)</h4>
<p>무한 차원의 공간에서 함수의 최적화를 다루는 이론입니다.</p>
<h4 id="equilibrium-optimization">균형 최적화 (Equilibrium Optimization)</h4>
<p>게임 이론에서 각 참가자의 전략이 서로 최적화를 이루는 상태를 분석합니다.</p>
<h4 id="exponential-optimization">지수적 최적화 (Exponential Optimization)</h4>
<p>목적 함수나 제약 조건에 지수적 요소가 포함된 최적화 문제를 다룹니다.</p>
<h4 id="interior-point-methods">내삽 최적화 (Interior Point Methods)</h4>
<p>최적화 문제를 해결하기 위해 feasible region 내부를 따라가는 알고리즘입니다.</p>
<h4 id="subgradient-methods">부분평균법 (Subgradient Methods)</h4>
<p>비미분 가능 함수의 최적화를 위한 방법으로, 미분 대신 부분 기울기를 사용합니다.</p>
<h4 id="parallel-optimization">병렬 최적화 (Parallel Optimization)</h4>
<p>컴퓨팅 자원을 활용하여 최적화 알고리즘을 병렬로 실행함으로써 속도를 향상시킵니다.</p>
<h4 id="model-predictive-control">모델 예측 제어 (Model Predictive Control)</h4>
<p>동적 시스템에서 미래의 예측 정보를 사용하여 현재의 최적 제어 입력을 계산합니다.</p>
<h4 id="sequential-quadratic-programming">순차적 이차 계획법 (Sequential Quadratic Programming)</h4>
<p>비선형 최적화 문제를 일련의 이차 계획 문제로 근사하여 푸는 방법입니다.</p>
<h4 id="calculus-of-variations">변분법 (Calculus of Variations)</h4>
<p>함수의 함수인 범함수의 극값을 찾는 수학적 방법으로, 물리학과 공학에서 많이 활용됩니다.</p>

  <br>
    

    <br>
</div>

<footer class="container-fluid wm-page-content">
  <p>Documentation built with <a href="https://www.mkdocs.org/">MkDocs</a> using <a href="https://github.com/gristlabs/mkdocs-windmill">Windmill</a> theme by Grist Labs.</p>
</footer>

</body>
</html>